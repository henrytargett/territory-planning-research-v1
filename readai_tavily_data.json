{
  "query": "Read AI AI features machine learning inference API deployment model serving scale",
  "follow_up_questions": null,
  "answer": null,
  "images": [],
  "results": [
    {
      "url": "https://www.linkedin.com/posts/nileshsalpe_batch-inference-in-ai-architecture-use-activity-7389551960347041792-bXUM",
      "title": "How to scale AI predictions with batch inference",
      "content": "‚ö°Ô∏è Ray Serve: Distributed Inference for the AI Era Inference is where intelligence meets scale ‚Äî and Ray Serve is the runtime that makes large-scale AI deployment effortless, modular, and production-ready. Here are 6 core insights driving how Ray Serve redefines AI inference architecture: 1Ô∏è‚É£ Unified model serving layer ‚Äî deploy multiple LLMs, embeddings, and APIs under a single scalable endpoint. 2Ô∏è‚É£ Autoscaling in real time ‚Äî Ray Serve dynamically adjusts replicas based on live traffic and system load. 3Ô∏è‚É£ Multi-model pipelines ‚Äî chain multiple models (retrievers, rerankers, generators) within one composable graph. 4Ô∏è‚É£ Low-latency inference ‚Äî request batching and async execution maximize GPU and CPU utilization. 5Ô∏è‚É£ Stateful actors for context ‚Äî maintain memory and session data across [...] for context ‚Äî maintain memory and session data across inference calls, critical for RAG and agentic use cases. 6Ô∏è‚É£ Seamless integration ‚Äî deploy directly on Kubernetes, AWS, GCP, or on-prem, all through the same API surface. Ray Serve bridges experimentation and production ‚Äî enabling AI systems that scale with intelligence, not just compute. #Ray #RayServe #DistributedInference #AIInfrastructure #LLM #RAG #MachineLearning #ScalableAI #AIDeployment #MLOps #AIEngineering #Python #Kubernetes #CloudComputing #DeepLearning #AIStack #InferenceOptimization #ModelServing #AIOrchestration #EdgeAI #GenerativeAI #AgenticAI #DataPipelines #IntelligentSystems [...] Knowledge Distillation: Train a smaller \"student\" model to mimic a larger \"teacher\" model, achieving similar performance with fewer resources. 2Ô∏è‚É£ Infrastructure & Deployment ‚û°Ô∏è Kubernetes for Elastic Scalability: Orchestrate AI workloads with dynamic resource scaling. HPA and custom metrics ensure you pay only for peak usage, scaling down during lulls. ‚û°Ô∏è Serverless Inference: Cost-effective for sporadic or event-driven AI tasks. Abstracting infrastructure, serverless functions bill only for execution time, fitting unpredictable inference patterns. 3Ô∏è‚É£ Data Pipeline Efficiency ‚û°Ô∏è Optimized Data Loading: Critical for training and inference. Use formats like Parquet, pre-process data for faster access, and leverage distributed file systems to reduce I/O bottlenecks. ‚û°Ô∏è Batching & Caching:",
      "score": 0.6862234,
      "raw_content": "# How to scale AI predictions with batch inference\n\nThis title was summarized by AI from the post below.\n\n[Nilesh Salpe](https://www.linkedin.com/in/nileshsalpe?trk=public_post_feed-actor-name)\n\nBuilding Agentforce - AI Platform @Salesforce | Software Architect | LLM Inference | RAG\n\n* [Report this post](/uas/login?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fnileshsalpe_batch-inference-in-ai-architecture-use-activity-7389551960347041792-bXUM&trk=public_post_ellipsis-menu-semaphore-sign-in-redirect&guestReportContentType=POST&_f=guest-reporting)\n\nüí° Scaling AI Predictions with Batch Inference üí° Most AI systems make predictions one at a time ‚Äî but at enterprise scale, that‚Äôs too slow. Batch inference lets you run millions of predictions in bulk, powering daily recommendations, fraud detection, and even GenAI pipelines. In my latest blog, I break down how it works, real business use cases, architecture design, and how to optimize CPU/GPU performance for massive workloads. üìò Read more: [https://lnkd.in/gB8hcN9V](https://www.linkedin.com/redir/redirect?url=https%3A%2F%2Flnkd%2Ein%2FgB8hcN9V&urlhash=-Kw7&trk=public_post-text) [#AI](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fai&trk=public_post-text) [#MachineLearning](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fmachinelearning&trk=public_post-text) [#MLOps](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fmlops&trk=public_post-text) [#BatchInference](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fbatchinference&trk=public_post-text) [#DataEngineering](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fdataengineering&trk=public_post-text) [#GenerativeAI](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fgenerativeai&trk=public_post-text) [#Spark](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fspark&trk=public_post-text) [#Ray](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fray&trk=public_post-text) [#VertexAI](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fvertexai&trk=public_post-text) [#SageMaker](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fsagemaker&trk=public_post-text)\n\n[üß† Batch Inference in AI: Architecture, Use Cases, and Emerging Trends   medium.com](https://www.linkedin.com/redir/redirect?url=https%3A%2F%2Fmedium%2Ecom%2F%40nileshsalpe%2Fbatch-inference-in-ai-architecture-use-cases-and-emerging-trends-466f327ee409&urlhash=kuBH&trk=public_post_feed-article-content)\n\n[Like](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww%2Elinkedin%2Ecom%2Fposts%2Fnileshsalpe_batch-inference-in-ai-architecture-use-activity-7389551960347041792-bXUM&trk=public_post_like-cta)   [Comment](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww%2Elinkedin%2Ecom%2Fposts%2Fnileshsalpe_batch-inference-in-ai-architecture-use-activity-7389551960347041792-bXUM&trk=public_post_comment-cta)\n\nTo view or add a comment, [sign in](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww%2Elinkedin%2Ecom%2Fposts%2Fnileshsalpe_batch-inference-in-ai-architecture-use-activity-7389551960347041792-bXUM&trk=public_post_feed-cta-banner-cta)\n\n## More Relevant Posts\n\n* [Manish ‚Äé](https://in.linkedin.com/in/manish050?trk=public_post_feed-actor-name)\n\n  AI research and Operation intern| AI Projects | Insight-Driven Decision Maker | Real-World Problem Solver\n\n  + [Report this post](/uas/login?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fmanish050_update-ai-knowledge-activity-7394785444762157056-ewtX&trk=public_post_ellipsis-menu-semaphore-sign-in-redirect&guestReportContentType=POST&_f=guest-reporting)\n\n  Context Engineering is Eating Prompt Engineering AI agents aren't the future. They're this quarter's infrastructure problem. And most companies are building them completely wrong. Here's what changed in November 2025: We've moved from \"crafting the perfect prompt\" to context engineering, systematically feeding AI models structured information so they perform reliably at scale. The Model Context Protocol (MCP) isn't just another API standard. It's the shift from treating AI like a search engine to treating it like a deployed system that needs real infrastructure. I'm watching teams realize: Your AI strategy is now your infrastructure strategy. GPU orchestration isn't optional anymore. Kubernetes clusters that once handled stateless web apps are now juggling multi-GPU workloads that can't fit on a single accelerator. Platform teams are tuning for latency and throughput 24/7. The companies spending $3 billion on AI compute deals? They're not overpaying. They're securing capacity before everyone else figures this out. Meanwhile, most enterprises are still treating AI like a feature to \"add on.\" But AI agents need: a.Continuous monitoring (they're non-deterministic) b.Context pipelines (not prompt libraries) c.Cost optimization (GPU time is billed idle or not) d.Infrastructure that doesn't exist in your current stack The gap between \"we use AI\" and \"we built for AI\" is widening fast. Three things the winners are doing differently: 1. Building for agents, not humans: Digital ecosystems designed for autonomous systems, not just UX 2. Treating context as infrastructure: Structured data pipelines feeding models, not ad-hoc prompt. 3. Orchestrating compute like it's 2025: Dynamic GPU allocation, not hoping AWS has availability This isn't about having better AI. It's about having the architecture to run it at scale without burning cash on idle GPUs or shipping unreliable outputs. The Binary Big Bang is here. Apps are becoming agent platforms. Prompts are becoming pipelines. And infrastructure is the new competitive moat. If you're still optimizing prompts instead of engineering context, you're already behind. What's the biggest infrastructure challenge you're hitting with AI deployment right now? Drop it below. üëá [Google](https://www.linkedin.com/company/google?trk=public_post-text) [Microsoft](https://www.linkedin.com/company/microsoft?trk=public_post-text) [OpenAI](https://www.linkedin.com/company/openai?trk=public_post-text) [#update](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fupdate&trk=public_post-text) [#AI](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fai&trk=public_post-text) [#Knowledge](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fknowledge&trk=public_post-text) [#ArtificialIntelligence](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fartificialintelligence&trk=public_post-text) [#AIInfrastructure](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Faiinfrastructure&trk=public_post-text) [#MachineLearning](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fmachinelearning&trk=public_post-text) [#TechLeadership](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Ftechleadership&trk=public_post-text) [#EnterpriseAI](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fenterpriseai&trk=public_post-text)\n\n\n\n  [8](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fmanish050_update-ai-knowledge-activity-7394785444762157056-ewtX&trk=public_post_social-actions-reactions)\n\n  [Like](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fmanish050_update-ai-knowledge-activity-7394785444762157056-ewtX&trk=public_post_like-cta)   [Comment](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fmanish050_update-ai-knowledge-activity-7394785444762157056-ewtX&trk=public_post_comment-cta)\n\n  To view or add a comment, [sign in](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fmanish050_update-ai-knowledge-activity-7394785444762157056-ewtX&trk=public_post_feed-cta-banner-cta)\n* [Visweswar M.V.S](https://in.linkedin.com/in/visweswar-mvs?trk=public_post_feed-actor-name)\n\n  Automation Test Analyst @Accenture | Fitness Enthusiast\n\n  + [Report this post](/uas/login?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fvisweswar-mvs_systemdesign-softwarearchitecture-scalability-activity-7390470188044836864-SLzH&trk=public_post_ellipsis-menu-semaphore-sign-in-redirect&guestReportContentType=POST&_f=guest-reporting)\n\n  Part I: The Four Major Software Trends Reshaping Design The current technological wave is driven by four primary forces, each introducing significant complexity and demanding specialized architectural solutions. 1. Artificial Intelligence (AI) and Machine Learning (ML) üß† The shift from simple analytics to Generative AI and the integration of Large Language Models (LLMs) is transforming almost every industry. This evolution places immense pressure on traditional system architectures. System Design Implications for AI/ML: ‚Ä¢ Need for Specialized Infrastructure (Hardware/Resource Management): AI/ML requires systems designed to accommodate GPU-heavy computation for model training and inference. Unlike typical stateless web services, ML workloads are often stateful and resource-intensive. The design must incorporate mechanisms for smart load balancing across these specialized resources and guarantee elastic scalability‚Äîmeaning the system can quickly provision and de-provision expensive GPUs based on demand (often orchestrated via Kubernetes clusters optimized for accelerated computing). ‚Ä¢ Data Pipeline Complexity (MLOps): The quality of an AI model depends entirely on the data it consumes. System design now focuses heavily on establishing intricate data ingestion, transformation, and storage (ETL/ELT) pipelines. This entire lifecycle, known as MLOps, must be automated, monitored, and version-controlled. Key design requirements here include guaranteeing data lineage (tracking data origin) and ensuring data freshness for continuous model retraining. [#SystemDesign](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fsystemdesign&trk=public_post-text) [#SoftwareArchitecture](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fsoftwarearchitecture&trk=public_post-text) [#Scalability](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fscalability&trk=public_post-text) [#CloudComputing](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fcloudcomputing&trk=public_post-text) [#AI](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fai&trk=public_post-text) [#Microservices](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fmicroservices&trk=public_post-text) [#TechLeadership](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Ftechleadership&trk=public_post-text) [#DistributedSystems](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fdistributedsystems&trk=public_post-text)\n\n  [Like](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fvisweswar-mvs_systemdesign-softwarearchitecture-scalability-activity-7390470188044836864-SLzH&trk=public_post_like-cta)   [Comment](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fvisweswar-mvs_systemdesign-softwarearchitecture-scalability-activity-7390470188044836864-SLzH&trk=public_post_comment-cta)\n\n  To view or add a comment, [sign in](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fvisweswar-mvs_systemdesign-softwarearchitecture-scalability-activity-7390470188044836864-SLzH&trk=public_post_feed-cta-banner-cta)\n* [AITech365](https://ae.linkedin.com/company/aitech365?trk=public_post_feed-actor-name)\n\n  3,777 followers\n\n  + [Report this post](/uas/login?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Faitech365_aitech365-dataintensity-generativeai-activity-7389296843890790400-i2Id&trk=public_post_ellipsis-menu-semaphore-sign-in-redirect&guestReportContentType=POST&_f=guest-reporting)\n\n  ùêáùê®ùê∞ ùêÜùê®ùê®ùê†ùê•ùêû‚Äôùê¨ ùêÄùêà ùêíùê≠ùêöùêúùê§ ùêèùê®ùê∞ùêûùê´ùê¨ ùêàùêßùêßùê®ùêØùêöùê≠ùê¢ùê®ùêß ùêÄùêúùê´ùê®ùê¨ùê¨ ùêèùê´ùê®ùêùùêÆùêúùê≠ùê¨ Most enterprises began their AI journey by experimenting in silos, building small ML projects that never scaled beyond prototypes. The problem isn‚Äôt ambition, it‚Äôs architecture. Traditional IT systems were never built to handle the data intensity, compute demands, and continuous learning cycles of modern generative AI. Read Complete Article: [https://lnkd.in/d5a888Tt](https://www.linkedin.com/redir/redirect?url=https%3A%2F%2Flnkd%2Ein%2Fd5a888Tt&urlhash=ezqH&trk=public_post-text) [#AITech365](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Faitech365&trk=public_post-text) [#DataIntensity](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fdataintensity&trk=public_post-text) [#GenerativeAI](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fgenerativeai&trk=public_post-text) [#GooglesAIStack](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fgooglesaistack&trk=public_post-text) [#Hypercomputer](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fhypercomputer&trk=public_post-text) [#ITsystems](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fitsystems&trk=public_post-text) [#machinelearning](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fmachinelearning&trk=public_post-text) [#MLProjects](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fmlprojects&trk=public_post-text) [#MLOps](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fmlops&trk=public_post-text) [#VertexAI](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fvertexai&trk=public_post-text)\n\n\n\n  [1](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Faitech365_aitech365-dataintensity-generativeai-activity-7389296843890790400-i2Id&trk=public_post_social-actions-reactions)\n\n  [Like](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Faitech365_aitech365-dataintensity-generativeai-activity-7389296843890790400-i2Id&trk=public_post_like-cta)   [Comment](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Faitech365_aitech365-dataintensity-generativeai-activity-7389296843890790400-i2Id&trk=public_post_comment-cta)\n\n  To view or add a comment, [sign in](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Faitech365_aitech365-dataintensity-generativeai-activity-7389296843890790400-i2Id&trk=public_post_feed-cta-banner-cta)\n* [Divye Dwivedi](https://www.linkedin.com/in/divye-dwivedi-421bb7126?trk=public_post_feed-actor-name)\n\n  QA Leader| Transforming Testing into Strategic Business Enablers | AI, Automation ,Performance & CoE Excellence| Cyber Security\n\n  + [Report this post](/uas/login?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fdivye-dwivedi-421bb7126_the-production-generative-ai-stack-architecture-activity-7394195993413558273-0Xbl&trk=public_post_ellipsis-menu-semaphore-sign-in-redirect&guestReportContentType=POST&_f=guest-reporting)\n\n  The Production Generative AI Stack: Architecture and Components The modern AI technology stack is a convergence of infrastructure, orchestration and developer tooling that powers today's generative AI apps. The enterprise AI landscape has evolved from experimental prototypes to production-grade systems, driving the emergence of a sophisticated, multilayered technology stack. Understanding each layer and its constituent components is essential for architects building scalable AI systems. Hyperscalers ‚Äî including Amazon, Microsoft and Google ‚Äî are leading this category by delivering an end-to-end stack that spans accelerated compute to user experiences. This architecture represents the convergence of infrastructure, intelligent orchestration and developer-centric tooling that powers modern generative AI applications. [https://lnkd.in/e\\_GQqYaC](https://www.linkedin.com/redir/redirect?url=https%3A%2F%2Flnkd%2Ein%2Fe_GQqYaC&urlhash=WMKw&trk=public_post-text) Please follow [Divye Dwivedi](https://www.linkedin.com/in/divye-dwivedi-421bb7126?trk=public_post-text) for such content.¬† [#DevSecOps](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fdevsecops&trk=public_post-text),[#SecureDevOps](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fsecuredevops&trk=public_post-text),[#CyberSecurity](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fcybersecurity&trk=public_post-text),[#SecurityAutomation](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fsecurityautomation&trk=public_post-text),[#CloudSecurity](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fcloudsecurity&trk=public_post-text),[#InfrastructureSecurity](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Finfrastructuresecurity&trk=public_post-text),[#DevOpsSecurity](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fdevopssecurity&trk=public_post-text),[#ContinuousSecurity](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fcontinuoussecurity&trk=public_post-text), [#SecurityByDesign](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fsecuritybydesign&trk=public_post-text), [#SecurityAsCode](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fsecurityascode&trk=public_post-text), [#ApplicationSecurity](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fapplicationsecurity&trk=public_post-text),[#ComplianceAutomation](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fcomplianceautomation&trk=public_post-text),[#CloudSecurityPosture](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fcloudsecurityposture&trk=public_post-text), [#SecuringTheCloud](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fsecuringthecloud&trk=public_post-text),[#AI4Security](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fai4security&trk=public_post-text) [#DevOpsSecurity](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fdevopssecurity&trk=public_post-text) [#IntelligentSecurity](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fintelligentsecurity&trk=public_post-text) [#AppSecurityTesting](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fappsecuritytesting&trk=public_post-text) [#CloudSecuritySolutions](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fcloudsecuritysolutions&trk=public_post-text) [#ResilientAI](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fresilientai&trk=public_post-text) [#AdaptiveSecurity](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fadaptivesecurity&trk=public_post-text) [#SecurityFirst](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fsecurityfirst&trk=public_post-text) [#AIDrivenSecurity](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Faidrivensecurity&trk=public_post-text) [#FullStackSecurity](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Ffullstacksecurity&trk=public_post-text) [#ModernAppSecurity](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fmodernappsecurity&trk=public_post-text) [#SecurityInTheCloud](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fsecurityinthecloud&trk=public_post-text) [#EmbeddedSecurity](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fembeddedsecurity&trk=public_post-text) [#SmartCyberDefense](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fsmartcyberdefense&trk=public_post-text) [#ProactiveSecurity](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fproactivesecurity&trk=public_post-text)\n\n  [The Production Generative AI Stack: Architecture and Components   https://thenewstack.io](https://www.linkedin.com/redir/redirect?url=https%3A%2F%2Fthenewstack%2Eio%2Fthe-production-generative-ai-stack-architecture-and-components%2F&urlhash=zSFp&trk=public_post_feed-article-content)\n\n  [Like](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fdivye-dwivedi-421bb7126_the-production-generative-ai-stack-architecture-activity-7394195993413558273-0Xbl&trk=public_post_like-cta)   [Comment](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fdivye-dwivedi-421bb7126_the-production-generative-ai-stack-architecture-activity-7394195993413558273-0Xbl&trk=public_post_comment-cta)\n\n  To view or add a comment, [sign in](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fdivye-dwivedi-421bb7126_the-production-generative-ai-stack-architecture-activity-7394195993413558273-0Xbl&trk=public_post_feed-cta-banner-cta)\n* [Augusto Santos](https://br.linkedin.com/in/kleber-augusto-santos?trk=public_post_feed-actor-name)\n\n  Gen AI | LLMs | RAG | AI Solutions Architecture | MLOps & AIOps | Kotlin | Go | Flutter | .NET 8 | Java | Hexagonal Arch | gRPC | Docker | K8s | Terraform | Vertex AI | AWS | GCP | Azure | Full Cycle Engineer\n\n  + [Report this post](/uas/login?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fkleber-augusto-santos_ray-rayserve-distributedinference-activity-7387997391255142400-qqZR&trk=public_post_ellipsis-menu-semaphore-sign-in-redirect&guestReportContentType=POST&_f=guest-reporting)\n\n  ‚ö°Ô∏è Ray Serve: Distributed Inference for the AI Era Inference is where intelligence meets scale ‚Äî and Ray Serve is the runtime that makes large-scale AI deployment effortless, modular, and production-ready. Here are 6 core insights driving how Ray Serve redefines AI inference architecture: 1Ô∏è‚É£ Unified model serving layer ‚Äî deploy multiple LLMs, embeddings, and APIs under a single scalable endpoint. 2Ô∏è‚É£ Autoscaling in real time ‚Äî Ray Serve dynamically adjusts replicas based on live traffic and system load. 3Ô∏è‚É£ Multi-model pipelines ‚Äî chain multiple models (retrievers, rerankers, generators) within one composable graph. 4Ô∏è‚É£ Low-latency inference ‚Äî request batching and async execution maximize GPU and CPU utilization. 5Ô∏è‚É£ Stateful actors for context ‚Äî maintain memory and session data across inference calls, critical for RAG and agentic use cases. 6Ô∏è‚É£ Seamless integration ‚Äî deploy directly on Kubernetes, AWS, GCP, or on-prem, all through the same API surface. Ray Serve bridges experimentation and production ‚Äî enabling AI systems that scale with intelligence, not just compute. [#Ray](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fray&trk=public_post-text) [#RayServe](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Frayserve&trk=public_post-text) [#DistributedInference](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fdistributedinference&trk=public_post-text) [#AIInfrastructure](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Faiinfrastructure&trk=public_post-text) [#LLM](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fllm&trk=public_post-text) [#RAG](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Frag&trk=public_post-text) [#MachineLearning](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fmachinelearning&trk=public_post-text) [#ScalableAI](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fscalableai&trk=public_post-text) [#AIDeployment](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Faideployment&trk=public_post-text) [#MLOps](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fmlops&trk=public_post-text) [#AIEngineering](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Faiengineering&trk=public_post-text) [#Python](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fpython&trk=public_post-text) [#Kubernetes](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fkubernetes&trk=public_post-text) [#CloudComputing](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fcloudcomputing&trk=public_post-text) [#DeepLearning](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fdeeplearning&trk=public_post-text) [#AIStack](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Faistack&trk=public_post-text) [#InferenceOptimization](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Finferenceoptimization&trk=public_post-text) [#ModelServing](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fmodelserving&trk=public_post-text) [#AIOrchestration](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Faiorchestration&trk=public_post-text) [#EdgeAI](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fedgeai&trk=public_post-text) [#GenerativeAI](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fgenerativeai&trk=public_post-text) [#AgenticAI](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fagenticai&trk=public_post-text) [#DataPipelines](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fdatapipelines&trk=public_post-text) [#IntelligentSystems](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fintelligentsystems&trk=public_post-text)\n\n  [19](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fkleber-augusto-santos_ray-rayserve-distributedinference-activity-7387997391255142400-qqZR&trk=public_post_social-actions-reactions)   [5 Comments](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fkleber-augusto-santos_ray-rayserve-distributedinference-activity-7387997391255142400-qqZR&trk=public_post_social-actions-comments)\n\n  [Like](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fkleber-augusto-santos_ray-rayserve-distributedinference-activity-7387997391255142400-qqZR&trk=public_post_like-cta)   [Comment](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fkleber-augusto-santos_ray-rayserve-distributedinference-activity-7387997391255142400-qqZR&trk=public_post_comment-cta)\n\n  To view or add a comment, [sign in](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fkleber-augusto-santos_ray-rayserve-distributedinference-activity-7387997391255142400-qqZR&trk=public_post_feed-cta-banner-cta)\n* [Trikona Nagaraj](https://uk.linkedin.com/in/trikonanagaraj?trk=public_post_feed-actor-name)\n\n  Data Engineer | Turning Big Data into Actionable Insights using Microsoft Fabric, Databricks & Power BI | MSc Data Analytics\n\n  + [Report this post](/uas/login?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Ftrikonanagaraj_databricks-just-redefined-enterprise-ai-activity-7394592953618575360-WpnS&trk=public_post_ellipsis-menu-semaphore-sign-in-redirect&guestReportContentType=POST&_f=guest-reporting)\n\n  Databricks Just Redefined Enterprise AI ‚Äî But Only a Handful of Companies Are Ready Everyone is excited about Databricks‚Äô latest announcements ‚Äî Agent Bricks, ML flow 3.0, serverless GPUs, vector search, and a unified path from data ‚Üí models ‚Üí agents ‚Üí action. But here‚Äôs the uncomfortable truth: AI agents don‚Äôt magically make a company intelligent. They amplify whatever the company already is. - If your data is clean ‚Üí agents scale your impact. - If your data is chaos ‚Üí agents scale the chaos. - If governance is weak ‚Üí agents expose you. This shift is exciting ‚Äî and a little terrifying ‚Äî because the real question isn‚Äôt: ‚ÄúCan we build an AI agent?‚Äù It‚Äôs ‚ÄúAre we ready for the consequences of deploying one?‚Äù üëá I‚Äôve written a full article breaking down: ‚Ä¢ What Databricks actually changed ‚Ä¢ The hidden readiness signals of AI-mature companies ‚Ä¢ Why most organizations are not prepared ‚Ä¢ What enterprises should do right now üëâ Read the full article here: [https://lnkd.in/eCAggGnF](https://www.linkedin.com/redir/redirect?url=https%3A%2F%2Flnkd%2Ein%2FeCAggGnF&urlhash=azVu&trk=public_post-text) [#Databricks](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fdatabricks&trk=public_post-text) [#EnterpriseAI](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fenterpriseai&trk=public_post-text) [#AIAgents](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Faiagents&trk=public_post-text) [#DataEngineering](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fdataengineering&trk=public_post-text) [#MachineLearning](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fmachinelearning&trk=public_post-text) [#Lakehouse](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Flakehouse&trk=public_post-text) [#GenerativeAI](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fgenerativeai&trk=public_post-text) [#DataStrategy](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fdatastrategy&trk=public_post-text) COE ‚Äì [https://lnkd.in/gbSWWxKa](https://www.linkedin.com/redir/redirect?url=https%3A%2F%2Flnkd%2Ein%2FgbSWWxKa&urlhash=4hSv&trk=public_post-text) COE LinkedIn - [https://lnkd.in/gCfiMH\\_K](https://www.linkedin.com/redir/redirect?url=https%3A%2F%2Flnkd%2Ein%2FgCfiMH_K&urlhash=j4SI&trk=public_post-text)\n\n  [\"Databricks Just Redefined Enterprise AI ‚Äî But Only a Handful of Companies Are Ready\"   trikonanagaraj1.wixsite.com](https://www.linkedin.com/redir/redirect?url=https%3A%2F%2Ftrikonanagaraj1%2Ewixsite%2Ecom%2Fdata-engineer%2Fpost%2Fdatabricks-just-redefined-enterprise-ai-but-only-a-handful-of-companies-are-ready&urlhash=Gnaf&trk=public_post_feed-article-content)\n\n  [23](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Ftrikonanagaraj_databricks-just-redefined-enterprise-ai-activity-7394592953618575360-WpnS&trk=public_post_social-actions-reactions)\n\n  [Like](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Ftrikonanagaraj_databricks-just-redefined-enterprise-ai-activity-7394592953618575360-WpnS&trk=public_post_like-cta)   [Comment](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Ftrikonanagaraj_databricks-just-redefined-enterprise-ai-activity-7394592953618575360-WpnS&trk=public_post_comment-cta)\n\n  To view or add a comment, [sign in](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Ftrikonanagaraj_databricks-just-redefined-enterprise-ai-activity-7394592953618575360-WpnS&trk=public_post_feed-cta-banner-cta)\n* [Peter Chaianov](https://nl.linkedin.com/in/peter-hostkey?trk=public_post_feed-actor-name)\n\n  Chief Technology Officer / Co-founder @ Hostkey.com | Networking, Cloud Computing\n\n  + [Report this post](/uas/login?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fpeter-hostkey_ai-deepseek-machinelearning-activity-7388562844683825153-W4-y&trk=public_post_ellipsis-menu-semaphore-sign-in-redirect&guestReportContentType=POST&_f=guest-reporting)\n\n  HOSTKEY Launches DeepSeek-R1:70B - Enterprise-Ready Reasoning AI We've deployedDeepSeek-R1:70B on our ML platform - a breakthrough reasoning model distilled from the full DeepSeek-R1, based on Llama-3.3-70B-Instruct. The 70B parameter architecture delivers advanced chain-of-thought reasoning with transparent thinking processes visible in real-time. Key capabilities: mathematical proofs, code generation with self-debugging, complex multi-step problem solving. The model achieves 94.5% on MATH-500 and 70.0% on AIME 2024 benchmarks (86.7% with consensus) - surpassing GPT-4o and Claude-3.5-Sonnet. Built-in reasoning traces provide unprecedented explainability for critical business decisions. üöÄ Ready to integrate advanced reasoning into your workflows? HOSTKEY's implementation offers: üîπ Dedicated GPU infrastructure optimized for 70B models üîπ Supported 24/7 - we are always ready to help üîπ Full reasoning transparency - see exactly how AI reaches conclusions Get started with DeepSeek-R1:70B: [https://lnkd.in/eYYahqbT](https://www.linkedin.com/redir/redirect?url=https%3A%2F%2Flnkd%2Ein%2FeYYahqbT&urlhash=tNzj&trk=public_post-text) Other pre-installed LLMs are available here: [https://lnkd.in/e7abXAr3](https://www.linkedin.com/redir/redirect?url=https%3A%2F%2Flnkd%2Ein%2Fe7abXAr3&urlhash=6hOD&trk=public_post-text) [#AI](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fai&trk=public_post-text) [#DeepSeek](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fdeepseek&trk=public_post-text) [#MachineLearning](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fmachinelearning&trk=public_post-text) [#OpenSource](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fopensource&trk=public_post-text) [#ReasoningAI](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Freasoningai&trk=public_post-text) [#MLOps](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fmlops&trk=public_post-text)\n\n\n\n  [8](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fpeter-hostkey_ai-deepseek-machinelearning-activity-7388562844683825153-W4-y&trk=public_post_social-actions-reactions)   [2 Comments](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fpeter-hostkey_ai-deepseek-machinelearning-activity-7388562844683825153-W4-y&trk=public_post_social-actions-comments)\n\n  [Like](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fpeter-hostkey_ai-deepseek-machinelearning-activity-7388562844683825153-W4-y&trk=public_post_like-cta)   [Comment](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fpeter-hostkey_ai-deepseek-machinelearning-activity-7388562844683825153-W4-y&trk=public_post_comment-cta)\n\n  To view or add a comment, [sign in](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fpeter-hostkey_ai-deepseek-machinelearning-activity-7388562844683825153-W4-y&trk=public_post_feed-cta-banner-cta)\n* [FlowEdge Consulting](https://www.linkedin.com/company/flowedge-consulting?trk=public_post_feed-actor-name)\n\n  46 followers\n\n  + [Report this post](/uas/login?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fflowedge-consulting_ai-mlops-machinelearning-activity-7385887852481617921-ZxWq&trk=public_post_ellipsis-menu-semaphore-sign-in-redirect&guestReportContentType=POST&_f=guest-reporting)\n\n  Scaling AI Models: Tips and Tricks for Resource Optimization AI models can be resource-intensive. Learn how to optimize your models and scale them without breaking the bank. The path to production-ready AI services often faces resource constraints: GPU costs, memory, and inference latency. Unoptimized models quickly exhaust budgets and infrastructure. The solution isn't just more hardware; it's about smart architectural and engineering choices. 1Ô∏è‚É£ Model Optimization ‚û°Ô∏è Quantization & Pruning: Reduce model precision (e.g., FP32 to INT8) or remove redundant connections. This shrinks model size and speeds up inference significantly, often with minimal accuracy impact. Ideal for edge deployments or high-throughput environments. ‚û°Ô∏è Knowledge Distillation: Train a smaller \"student\" model to mimic a larger \"teacher\" model, achieving similar performance with fewer resources. 2Ô∏è‚É£ Infrastructure & Deployment ‚û°Ô∏è Kubernetes for Elastic Scalability: Orchestrate AI workloads with dynamic resource scaling. HPA and custom metrics ensure you pay only for peak usage, scaling down during lulls. ‚û°Ô∏è Serverless Inference: Cost-effective for sporadic or event-driven AI tasks. Abstracting infrastructure, serverless functions bill only for execution time, fitting unpredictable inference patterns. 3Ô∏è‚É£ Data Pipeline Efficiency ‚û°Ô∏è Optimized Data Loading: Critical for training and inference. Use formats like Parquet, pre-process data for faster access, and leverage distributed file systems to reduce I/O bottlenecks. ‚û°Ô∏è Batching & Caching: Group inference requests to maximize GPU utilization. Cache frequently accessed data or model outputs to reduce redundant computations. 4Ô∏è‚É£ Monitoring & Profiling ‚û°Ô∏è Granular Metrics: Robust monitoring of GPU usage, memory, network I/O, and inference latency is vital. Tools like Prometheus and Grafana, with profiling, pinpoint bottlenecks. Without visibility, optimization is guesswork. Scaling AI means building resilient, cost-effective systems developers can confidently manage. It blends ML expertise and robust systems engineering. By integrating these strategies, teams achieve sustainable growth and deliver impactful AI solutions without prohibitive costs. [#AI](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fai&trk=public_post-text) [#MLOps](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fmlops&trk=public_post-text) [#MachineLearning](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fmachinelearning&trk=public_post-text) [#Kubernetes](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fkubernetes&trk=public_post-text) [#ResourceOptimization](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fresourceoptimization&trk=public_post-text) [#DeepLearning](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fdeeplearning&trk=public_post-text) [#ScalableAI](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fscalableai&trk=public_post-text) [#SystemDesign](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fsystemdesign&trk=public_post-text)\n\n\n\n  [Like](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fflowedge-consulting_ai-mlops-machinelearning-activity-7385887852481617921-ZxWq&trk=public_post_like-cta)   [Comment](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fflowedge-consulting_ai-mlops-machinelearning-activity-7385887852481617921-ZxWq&trk=public_post_comment-cta)\n\n  To view or add a comment, [sign in](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fflowedge-consulting_ai-mlops-machinelearning-activity-7385887852481617921-ZxWq&trk=public_post_feed-cta-banner-cta)\n* [AI n Dot Net](https://www.linkedin.com/company/ai-n-dot-net?trk=public_post_feed-actor-name)\n\n  415 followers\n\n  + [Report this post](/uas/login?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fai-n-dot-net_ai-dotnet-azureai-activity-7395075600065126400--Nz2&trk=public_post_ellipsis-menu-semaphore-sign-in-redirect&guestReportContentType=POST&_f=guest-reporting)\n\n  Architect once ‚Äî plug in AI anywhere. The future of enterprise .NET architecture isn‚Äôt about adding AI later ‚Äî it‚Äôs about designing for AI now. In this week‚Äôs Building Enterprise Applications with AI in .NET article, we explore how to create modular, AI-ready architectures using: üîπ Azure AI for cognitive and generative intelligence üîπ [ML.NET](https://www.linkedin.com/redir/redirect?url=http%3A%2F%2FML%2ENET&urlhash=kxv8&trk=public_post-text) for predictive analytics inside your applications üîπ Semantic Kernel for connecting logic and language Learn how to design systems that evolve with intelligence ‚Äî from clean layering and domain-driven design to feedback-driven, modular connectors for future MCP endpoints. üëâ Read the full article: [https://lnkd.in/eCHNWwP8](https://www.linkedin.com/redir/redirect?url=https%3A%2F%2Flnkd%2Ein%2FeCHNWwP8&urlhash=gra8&trk=public_post-text) [#AI](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fai&trk=public_post-text) [#dotNET](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fdotnet&trk=public_post-text) [#AzureAI](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fazureai&trk=public_post-text) [#MLNET](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fmlnet&trk=public_post-text) [#SemanticKernel](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fsemantickernel&trk=public_post-text) [#AIIntegration](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Faiintegration&trk=public_post-text) [#EnterpriseArchitecture](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fenterprisearchitecture&trk=public_post-text) [#AIDevelopment](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Faidevelopment&trk=public_post-text) [#CleanArchitecture](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fcleanarchitecture&trk=public_post-text) [#AINotNet](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fainotnet&trk=public_post-text) [#AISimplified](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Faisimplified&trk=public_post-text)\n\n\n\n  [2](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fai-n-dot-net_ai-dotnet-azureai-activity-7395075600065126400--Nz2&trk=public_post_social-actions-reactions)   [1 Comment](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fai-n-dot-net_ai-dotnet-azureai-activity-7395075600065126400--Nz2&trk=public_post_social-actions-comments)\n\n  [Like](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fai-n-dot-net_ai-dotnet-azureai-activity-7395075600065126400--Nz2&trk=public_post_like-cta)   [Comment](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fai-n-dot-net_ai-dotnet-azureai-activity-7395075600065126400--Nz2&trk=public_post_comment-cta)\n\n  To view or add a comment, [sign in](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fai-n-dot-net_ai-dotnet-azureai-activity-7395075600065126400--Nz2&trk=public_post_feed-cta-banner-cta)\n* [Sai Thakshitha Vankadhara](https://in.linkedin.com/in/thakshitha-frontend?trk=public_post_feed-actor-name)\n\n  Front-End Developer | HTML5 | CSS3 | JavaScript | React | Building Responsive Web Applications\n\n  + [Report this post](/uas/login?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fthakshitha-frontend_the-production-generative-ai-stack-architecture-activity-7392451489140731904-xxkx&trk=public_post_ellipsis-menu-semaphore-sign-in-redirect&guestReportContentType=POST&_f=guest-reporting)\n\n  Enterprise AI went from lab experiments to billion-dollar infrastructure overnight. The stack that emerged has seven distinct layers. Most companies are missing three of them. The shift from prototype to production changed everything. What started as simple API calls became sophisticated multilayered architectures. Hyperscalers like Amazon, Microsoft, and Google now offer end-to-end solutions. Here's what the modern AI stack looks like: üîß Accelerated compute (GPUs, ASICs) üìö Model catalog (first-party, partner, open-weight) ‚ö° Model invocation and context management üîÑ Orchestration workflows for complex processes üë®üíª Developer tools (APIs, SDKs, CLI) üí¨ User interfaces (chatbots, agents, apps) üõ°Ô∏è Cross-cutting concerns (security, monitoring) The missing pieces? Most organizations skip the middle layers. They jump from models to user interfaces. They forget about proper orchestration, context management, and governance. This creates brittle systems that can't scale. Production-grade AI needs all seven layers working together. Each serves a specific purpose. Remove one and the whole system becomes unreliable. The companies getting this right are building modular architectures. They're investing in proper data pipelines, vector databases, and monitoring tools. They understand that moving from pilot to production isn't just about bigger servers. It's about building enterprise-grade systems from the ground up. What layer is your organization struggling with most? [#GenerativeAI](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fgenerativeai&trk=public_post-text) [#AIArchitecture](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Faiarchitecture&trk=public_post-text) [#EnterpriseAI](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fenterpriseai&trk=public_post-text) ùó¶ùóºùòÇùóøùó∞ùó≤Íûâ [https://lnkd.in/exKJXXU2](https://www.linkedin.com/redir/redirect?url=https%3A%2F%2Flnkd%2Ein%2FexKJXXU2&urlhash=43J1&trk=public_post-text)\n\n  [The Production Generative AI Stack: Architecture and Components   https://thenewstack.io](https://www.linkedin.com/redir/redirect?url=https%3A%2F%2Fthenewstack%2Eio%2Fthe-production-generative-ai-stack-architecture-and-components%2F&urlhash=zSFp&trk=public_post_feed-article-content)\n\n  [18](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fthakshitha-frontend_the-production-generative-ai-stack-architecture-activity-7392451489140731904-xxkx&trk=public_post_social-actions-reactions)   [1 Comment](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fthakshitha-frontend_the-production-generative-ai-stack-architecture-activity-7392451489140731904-xxkx&trk=public_post_social-actions-comments)\n\n  [Like](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fthakshitha-frontend_the-production-generative-ai-stack-architecture-activity-7392451489140731904-xxkx&trk=public_post_like-cta)   [Comment](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fthakshitha-frontend_the-production-generative-ai-stack-architecture-activity-7392451489140731904-xxkx&trk=public_post_comment-cta)\n\n  To view or add a comment, [sign in](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fthakshitha-frontend_the-production-generative-ai-stack-architecture-activity-7392451489140731904-xxkx&trk=public_post_feed-cta-banner-cta)\n\n2,544 followers\n\n* [116 Posts](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww%2Elinkedin%2Ecom%2Fin%2Fnileshsalpe%2Frecent-activity%2F&trk=public_post_follow-posts)\n\n[View Profile](https://www.linkedin.com/in/nileshsalpe?trk=public_post_follow-view-profile)   [Connect](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww%2Elinkedin%2Ecom%2Ffeed%2Fupdate%2Furn%3Ali%3Aactivity%3A7389551960347041792&trk=public_post_follow)\n\n## Explore content categories\n\n* [Career](https://www.linkedin.com/top-content/career/)\n* [Productivity](https://www.linkedin.com/top-content/productivity/)\n* [Finance](https://www.linkedin.com/top-content/finance/)\n* [Soft Skills & Emotional Intelligence](https://www.linkedin.com/top-content/soft-skills-emotional-intelligence/)\n* [Project Management](https://www.linkedin.com/top-content/project-management/)\n* [Education](https://www.linkedin.com/top-content/education/)\n* [Technology](https://www.linkedin.com/top-content/technology/)\n* [Leadership](https://www.linkedin.com/top-content/leadership/)\n* [Ecommerce](https://www.linkedin.com/top-content/ecommerce/)\n* [User Experience](https://www.linkedin.com/top-content/user-experience/)\n\n## Sign in to view more content\n\nCreate your free account or sign in to continue your search\n\n## Welcome back\n\nBy clicking Continue to join or sign in, you agree to LinkedIn‚Äôs [User Agreement](/legal/user-agreement?trk=public_post_contextual-sign-in-modal_sign-in-modal_auth-button_user-agreement), [Privacy Policy](/legal/privacy-policy?trk=public_post_contextual-sign-in-modal_sign-in-modal_auth-button_privacy-policy), and [Cookie Policy](/legal/cookie-policy?trk=public_post_contextual-sign-in-modal_sign-in-modal_auth-button_cookie-policy).\n\nNew to LinkedIn? [Join now](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww%2Elinkedin%2Ecom%2Fposts%2Fnileshsalpe_batch-inference-in-ai-architecture-use-activity-7389551960347041792-bXUM&trk=public_post_contextual-sign-in-modal_sign-in-modal_join-link)\n\nor\n\nNew to LinkedIn? [Join now](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww%2Elinkedin%2Ecom%2Fposts%2Fnileshsalpe_batch-inference-in-ai-architecture-use-activity-7389551960347041792-bXUM&trk=public_post_contextual-sign-in-modal_join-link)\n\nBy clicking Continue to join or sign in, you agree to LinkedIn‚Äôs [User Agreement](/legal/user-agreement?trk=linkedin-tc_auth-button_user-agreement), [Privacy Policy](/legal/privacy-policy?trk=linkedin-tc_auth-button_privacy-policy), and [Cookie Policy](/legal/cookie-policy?trk=linkedin-tc_auth-button_cookie-policy).\n\nNever miss a beat on the app\n\nDon‚Äôt have the app? Get it in the Microsoft Store.\n\n [Open the app](ms-windows-store://pdp/?ProductId=9WZDNCRFJ4Q7&mode=mini&cid=guest_desktop_upsell_post2)\n\n "
    },
    {
      "url": "https://www.linkedin.com/posts/kalaiarasan-balaraman_ai-machinelearning-mlops-activity-7381194175637217283-Izsp",
      "title": "Distributed Inference for Scalable AI: My Takeaways",
      "content": "‚ö°Ô∏è Ray Serve: Distributed Inference for the AI Era Inference is where intelligence meets scale ‚Äî and Ray Serve is the runtime that makes large-scale AI deployment effortless, modular, and production-ready. Here are 6 core insights driving how Ray Serve redefines AI inference architecture: 1Ô∏è‚É£ Unified model serving layer ‚Äî deploy multiple LLMs, embeddings, and APIs under a single scalable endpoint. 2Ô∏è‚É£ Autoscaling in real time ‚Äî Ray Serve dynamically adjusts replicas based on live traffic and system load. 3Ô∏è‚É£ Multi-model pipelines ‚Äî chain multiple models (retrievers, rerankers, generators) within one composable graph. 4Ô∏è‚É£ Low-latency inference ‚Äî request batching and async execution maximize GPU and CPU utilization. 5Ô∏è‚É£ Stateful actors for context ‚Äî maintain memory and session data across [...] for context ‚Äî maintain memory and session data across inference calls, critical for RAG and agentic use cases. 6Ô∏è‚É£ Seamless integration ‚Äî deploy directly on Kubernetes, AWS, GCP, or on-prem, all through the same API surface. Ray Serve bridges experimentation and production ‚Äî enabling AI systems that scale with intelligence, not just compute. #Ray #RayServe #DistributedInference #AIInfrastructure #LLM #RAG #MachineLearning #ScalableAI #AIDeployment #MLOps #AIEngineering #Python #Kubernetes #CloudComputing #DeepLearning #AIStack #InferenceOptimization #ModelServing #AIOrchestration #EdgeAI #GenerativeAI #AgenticAI #DataPipelines #IntelligentSystems [...] AI stack blends performance with flexibility through: 1. Containerized Deployments: Kubernetes, Docker, and Ray to scale across compute clusters. 2. Unified Feature & Embedding Stores: Combining Feast and ChromaDB for ML and LLM data workflows. 3.Hybrid Serving Architecture: Tools like KServe, Triton, and vLLM to deploy models across cloud, edge, and GPU nodes. 4. Observability & Governance Layers: Monitoring drift, hallucinations, and bias while ensuring compliance with GDPR and the EU AI Act. 5. Continuous Training & Fine-Tuning Pipelines: Automating retraining for ML and fine-tuning for LLMs under a single CI/CD framework. --- üß© The Outcome Scalable pipelines don‚Äôt just deploy models ‚Äî they operationalize intelligence. They turn experimentation into impact, enabling data teams to",
      "score": 0.66777676,
      "raw_content": "# Distributed Inference for Scalable AI: My Takeaways\n\nThis title was summarized by AI from the post below.\n\n[Kalaiarasan Balaraman](https://in.linkedin.com/in/kalaiarasan-balaraman?trk=public_post_feed-actor-name)\n\n* [Report this post](/uas/login?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fkalaiarasan-balaraman_ai-machinelearning-mlops-activity-7381194175637217283-Izsp&trk=public_post_ellipsis-menu-semaphore-sign-in-redirect&guestReportContentType=POST&_f=guest-reporting)\n\nüöÄ Exploring Distributed Inference for Scalable AI Workloads Recently, I have experimented with distributed inference solutions- KServe, LLM-D, and Dynamo. Most of these solutions leverage powerful inference engines like vLLM or TensorRT under the hood. üîß Here are my takeaways: \\* Directly using vLLM is often simpler for single node and it gives more performance with low latency, batching and so on \\* KServe stands out when it comes to managing deployments and scaling AI workloads - it significantly simplifies the deployment process of model deployments. [#AI](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fai&trk=public_post-text) [#MachineLearning](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fmachinelearning&trk=public_post-text) [#MLOps](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fmlops&trk=public_post-text) [#Inference](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Finference&trk=public_post-text) [#KServe](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fkserve&trk=public_post-text) [#vLLM](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fvllm&trk=public_post-text) [#TensorRT](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Ftensorrt&trk=public_post-text) [#Scalability](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fscalability&trk=public_post-text) [#LLM](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fllm&trk=public_post-text) [#Infrastructure](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Finfrastructure&trk=public_post-text) [#OpenSource](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fopensource&trk=public_post-text)\n\n[25](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww%2Elinkedin%2Ecom%2Fposts%2Fkalaiarasan-balaraman_ai-machinelearning-mlops-activity-7381194175637217283-Izsp&trk=public_post_social-actions-reactions)   [1 Comment](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww%2Elinkedin%2Ecom%2Fposts%2Fkalaiarasan-balaraman_ai-machinelearning-mlops-activity-7381194175637217283-Izsp&trk=public_post_social-actions-comments)\n\n[Like](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww%2Elinkedin%2Ecom%2Fposts%2Fkalaiarasan-balaraman_ai-machinelearning-mlops-activity-7381194175637217283-Izsp&trk=public_post_like-cta)   [Comment](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww%2Elinkedin%2Ecom%2Fposts%2Fkalaiarasan-balaraman_ai-machinelearning-mlops-activity-7381194175637217283-Izsp&trk=public_post_comment-cta)\n\n[Saravanan Gnanaguru](https://in.linkedin.com/in/saravanan-gnanaguru?trk=public_post_comment_actor-name)   2mo \n\n* [Report this comment](/uas/login?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fkalaiarasan-balaraman_ai-machinelearning-mlops-activity-7381194175637217283-Izsp&trk=public_post_comment_ellipsis-menu-semaphore-sign-in-redirect&guestReportContentType=COMMENT&_f=guest-reporting)\n\nGood and useful insights Kalai!\n\n[Like](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww%2Elinkedin%2Ecom%2Fposts%2Fkalaiarasan-balaraman_ai-machinelearning-mlops-activity-7381194175637217283-Izsp&trk=public_post_comment_like) [Reply](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww%2Elinkedin%2Ecom%2Fposts%2Fkalaiarasan-balaraman_ai-machinelearning-mlops-activity-7381194175637217283-Izsp&trk=public_post_comment_reply)  [1¬†Reaction](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww%2Elinkedin%2Ecom%2Fposts%2Fkalaiarasan-balaraman_ai-machinelearning-mlops-activity-7381194175637217283-Izsp&trk=public_post_comment_reactions)   2¬†Reactions\n\nTo view or add a comment, [sign in](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww%2Elinkedin%2Ecom%2Fposts%2Fkalaiarasan-balaraman_ai-machinelearning-mlops-activity-7381194175637217283-Izsp&trk=public_post_feed-cta-banner-cta)\n\n## More Relevant Posts\n\n* [AITech365](https://ae.linkedin.com/company/aitech365?trk=public_post_feed-actor-name)\n\n  3,809 followers\n\n  + [Report this post](/uas/login?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Faitech365_aitech365-dataintensity-generativeai-activity-7389296843890790400-i2Id&trk=public_post_ellipsis-menu-semaphore-sign-in-redirect&guestReportContentType=POST&_f=guest-reporting)\n\n  ùêáùê®ùê∞ ùêÜùê®ùê®ùê†ùê•ùêû‚Äôùê¨ ùêÄùêà ùêíùê≠ùêöùêúùê§ ùêèùê®ùê∞ùêûùê´ùê¨ ùêàùêßùêßùê®ùêØùêöùê≠ùê¢ùê®ùêß ùêÄùêúùê´ùê®ùê¨ùê¨ ùêèùê´ùê®ùêùùêÆùêúùê≠ùê¨ Most enterprises began their AI journey by experimenting in silos, building small ML projects that never scaled beyond prototypes. The problem isn‚Äôt ambition, it‚Äôs architecture. Traditional IT systems were never built to handle the data intensity, compute demands, and continuous learning cycles of modern generative AI. Read Complete Article: [https://lnkd.in/d5a888Tt](https://www.linkedin.com/redir/redirect?url=https%3A%2F%2Flnkd%2Ein%2Fd5a888Tt&urlhash=ezqH&trk=public_post-text) [#AITech365](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Faitech365&trk=public_post-text) [#DataIntensity](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fdataintensity&trk=public_post-text) [#GenerativeAI](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fgenerativeai&trk=public_post-text) [#GooglesAIStack](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fgooglesaistack&trk=public_post-text) [#Hypercomputer](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fhypercomputer&trk=public_post-text) [#ITsystems](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fitsystems&trk=public_post-text) [#machinelearning](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fmachinelearning&trk=public_post-text) [#MLProjects](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fmlprojects&trk=public_post-text) [#MLOps](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fmlops&trk=public_post-text) [#VertexAI](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fvertexai&trk=public_post-text)\n\n\n\n  [1](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Faitech365_aitech365-dataintensity-generativeai-activity-7389296843890790400-i2Id&trk=public_post_social-actions-reactions)\n\n  [Like](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Faitech365_aitech365-dataintensity-generativeai-activity-7389296843890790400-i2Id&trk=public_post_like-cta)   [Comment](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Faitech365_aitech365-dataintensity-generativeai-activity-7389296843890790400-i2Id&trk=public_post_comment-cta)\n\n  To view or add a comment, [sign in](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Faitech365_aitech365-dataintensity-generativeai-activity-7389296843890790400-i2Id&trk=public_post_feed-cta-banner-cta)\n* [Augusto Santos](https://br.linkedin.com/in/kleber-augusto-santos?trk=public_post_feed-actor-name)\n\n  + [Report this post](/uas/login?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fkleber-augusto-santos_ray-rayserve-distributedinference-activity-7387997391255142400-qqZR&trk=public_post_ellipsis-menu-semaphore-sign-in-redirect&guestReportContentType=POST&_f=guest-reporting)\n\n  ‚ö°Ô∏è Ray Serve: Distributed Inference for the AI Era Inference is where intelligence meets scale ‚Äî and Ray Serve is the runtime that makes large-scale AI deployment effortless, modular, and production-ready. Here are 6 core insights driving how Ray Serve redefines AI inference architecture: 1Ô∏è‚É£ Unified model serving layer ‚Äî deploy multiple LLMs, embeddings, and APIs under a single scalable endpoint. 2Ô∏è‚É£ Autoscaling in real time ‚Äî Ray Serve dynamically adjusts replicas based on live traffic and system load. 3Ô∏è‚É£ Multi-model pipelines ‚Äî chain multiple models (retrievers, rerankers, generators) within one composable graph. 4Ô∏è‚É£ Low-latency inference ‚Äî request batching and async execution maximize GPU and CPU utilization. 5Ô∏è‚É£ Stateful actors for context ‚Äî maintain memory and session data across inference calls, critical for RAG and agentic use cases. 6Ô∏è‚É£ Seamless integration ‚Äî deploy directly on Kubernetes, AWS, GCP, or on-prem, all through the same API surface. Ray Serve bridges experimentation and production ‚Äî enabling AI systems that scale with intelligence, not just compute. [#Ray](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fray&trk=public_post-text) [#RayServe](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Frayserve&trk=public_post-text) [#DistributedInference](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fdistributedinference&trk=public_post-text) [#AIInfrastructure](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Faiinfrastructure&trk=public_post-text) [#LLM](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fllm&trk=public_post-text) [#RAG](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Frag&trk=public_post-text) [#MachineLearning](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fmachinelearning&trk=public_post-text) [#ScalableAI](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fscalableai&trk=public_post-text) [#AIDeployment](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Faideployment&trk=public_post-text) [#MLOps](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fmlops&trk=public_post-text) [#AIEngineering](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Faiengineering&trk=public_post-text) [#Python](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fpython&trk=public_post-text) [#Kubernetes](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fkubernetes&trk=public_post-text) [#CloudComputing](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fcloudcomputing&trk=public_post-text) [#DeepLearning](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fdeeplearning&trk=public_post-text) [#AIStack](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Faistack&trk=public_post-text) [#InferenceOptimization](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Finferenceoptimization&trk=public_post-text) [#ModelServing](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fmodelserving&trk=public_post-text) [#AIOrchestration](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Faiorchestration&trk=public_post-text) [#EdgeAI](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fedgeai&trk=public_post-text) [#GenerativeAI](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fgenerativeai&trk=public_post-text) [#AgenticAI](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fagenticai&trk=public_post-text) [#DataPipelines](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fdatapipelines&trk=public_post-text) [#IntelligentSystems](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fintelligentsystems&trk=public_post-text)\n\n  [19](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fkleber-augusto-santos_ray-rayserve-distributedinference-activity-7387997391255142400-qqZR&trk=public_post_social-actions-reactions)   [5 Comments](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fkleber-augusto-santos_ray-rayserve-distributedinference-activity-7387997391255142400-qqZR&trk=public_post_social-actions-comments)\n\n  [Like](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fkleber-augusto-santos_ray-rayserve-distributedinference-activity-7387997391255142400-qqZR&trk=public_post_like-cta)   [Comment](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fkleber-augusto-santos_ray-rayserve-distributedinference-activity-7387997391255142400-qqZR&trk=public_post_comment-cta)\n\n  To view or add a comment, [sign in](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fkleber-augusto-santos_ray-rayserve-distributedinference-activity-7387997391255142400-qqZR&trk=public_post_feed-cta-banner-cta)\n* [Or David üëæ](https://il.linkedin.com/in/ordavid?trk=public_post_feed-actor-name)\n\n  + [Report this post](/uas/login?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fordavid_openai-datacenter-aiinfrastructure-activity-7389935672641351680-_y1D&trk=public_post_ellipsis-menu-semaphore-sign-in-redirect&guestReportContentType=POST&_f=guest-reporting)\n\n  OpenAI just dropped a massive new data center in Michigan and is beefing up its Champion Network worldwide! ü§ñ This isn‚Äôt just another server farm‚Äîit's a strategic move to turbocharge AI accessibility and speed for users everywhere. They‚Äôre leveraging cutting-edge infrastructure to slash latency and boost compute power, making GPT models run smoother and faster right where businesses need them. This means devs get real-time responses and can build AI apps that scale without breaking a sweat. üöÄ For enterprises, this could be a game-changer in deploying AI solutions closer to customers, cutting down costs and improving data sovereignty. Think faster innovation cycles and better user experiences. But here‚Äôs the kicker‚Äîhow will this shift affect your AI deployment strategies? üîó [https://lnkd.in/eEgrPknw](https://www.linkedin.com/redir/redirect?url=https%3A%2F%2Flnkd%2Ein%2FeEgrPknw&urlhash=55lF&trk=public_post-text) [#OpenAI](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fopenai&trk=public_post-text) [#DataCenter](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fdatacenter&trk=public_post-text) [#AIInfrastructure](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Faiinfrastructure&trk=public_post-text) [#EnterpriseAI](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fenterpriseai&trk=public_post-text) [#GlobalAI](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fglobalai&trk=public_post-text)\n\n  [2](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fordavid_openai-datacenter-aiinfrastructure-activity-7389935672641351680-_y1D&trk=public_post_social-actions-reactions)\n\n  [Like](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fordavid_openai-datacenter-aiinfrastructure-activity-7389935672641351680-_y1D&trk=public_post_like-cta)   [Comment](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fordavid_openai-datacenter-aiinfrastructure-activity-7389935672641351680-_y1D&trk=public_post_comment-cta)\n\n  To view or add a comment, [sign in](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fordavid_openai-datacenter-aiinfrastructure-activity-7389935672641351680-_y1D&trk=public_post_feed-cta-banner-cta)\n* [Antal Nagy](https://hu.linkedin.com/in/antal-nagy-2761518b?trk=public_post_feed-actor-name)\n\n  + [Report this post](/uas/login?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fantal-nagy-2761518b_aipipelines-aiengineering-aicostoptimization-activity-7387031957932507136-XBVt&trk=public_post_ellipsis-menu-semaphore-sign-in-redirect&guestReportContentType=POST&_f=guest-reporting)\n\n  üü¢ \"Most AI teams waste 70% of their compute on raw text - before the model even starts thinking.\" Too many AI systems send entire documents straight to large models ‚Äî no filtering, no summarization, no intelligence upfront. The result? - Wasted tokens, - Slower response times, - And growing infrastructure costs. But there‚Äôs a smarter way. Add an AI-assisted preprocessing layer, a lightweight model (like GPT-5-nano) that quickly extracts meaning, filters noise, and summarizes before the heavy model runs. This small step can cut input tokens by 80% while keeping the same accuracy. I‚Äôve built this pattern on AWS Lambda + S3 + EventBridge, where each document is processed serverlessly and in parallel - no servers, no idle cost. In one of my recent projects, this approach turned a costly bottleneck into a 8-10√ó cheaper, fully automated pipeline, a real game changer in production. It scales automatically and you pay only for what you use. ‚úÖ Simple ‚ö° Fast üí∞ Cost-efficient Here‚Äôs the core idea: Document ‚Üí Pre-Filter (lightweight model) ‚Üí Main Model ‚Üí Result It‚Äôs not always about bigger models - sometimes, the biggest improvement comes from smarter architecture. How much could your AI pipeline save if it started thinking smarter before thinking harder? [#AIPipelines](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Faipipelines&trk=public_post-text) [#AIEngineering](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Faiengineering&trk=public_post-text) [#AICostOptimization](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Faicostoptimization&trk=public_post-text) [#Serverless](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fserverless&trk=public_post-text) [#AWS](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Faws&trk=public_post-text) [#MachineLearning](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fmachinelearning&trk=public_post-text)\n\n  [4](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fantal-nagy-2761518b_aipipelines-aiengineering-aicostoptimization-activity-7387031957932507136-XBVt&trk=public_post_social-actions-reactions)   [3 Comments](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fantal-nagy-2761518b_aipipelines-aiengineering-aicostoptimization-activity-7387031957932507136-XBVt&trk=public_post_social-actions-comments)\n\n  [Like](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fantal-nagy-2761518b_aipipelines-aiengineering-aicostoptimization-activity-7387031957932507136-XBVt&trk=public_post_like-cta)   [Comment](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fantal-nagy-2761518b_aipipelines-aiengineering-aicostoptimization-activity-7387031957932507136-XBVt&trk=public_post_comment-cta)\n\n  To view or add a comment, [sign in](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fantal-nagy-2761518b_aipipelines-aiengineering-aicostoptimization-activity-7387031957932507136-XBVt&trk=public_post_feed-cta-banner-cta)\n* [Thoras.ai](https://www.linkedin.com/company/thoras?trk=public_post_feed-actor-name)\n\n  781 followers\n\n  + [Report this post](/uas/login?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fthoras_sre-devops-activity-7383962031265304576-YnfF&trk=public_post_ellipsis-menu-semaphore-sign-in-redirect&guestReportContentType=POST&_f=guest-reporting)\n\n  That ‚Äúaha‚Äù moment that started it all. While studying interactive intelligence and machine learning at Georgia Tech, our CEO [Nilo Rahmani](https://www.linkedin.com/in/nilo-devops?trk=public_post-text) realized something obvious yet overlooked: every other industry was already using ML, except reliability. That question became the foundation for [Thoras.ai](https://www.linkedin.com/redir/redirect?url=http%3A%2F%2FThoras%2Eai&urlhash=rMOQ&trk=public_post-text). Why should infrastructure be the last to get intelligence? [#sre](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fsre&trk=public_post-text) [#devops](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fdevops&trk=public_post-text)\n\n  [12](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fthoras_sre-devops-activity-7383962031265304576-YnfF&trk=public_post_social-actions-reactions)\n\n  [Like](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fthoras_sre-devops-activity-7383962031265304576-YnfF&trk=public_post_like-cta)   [Comment](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fthoras_sre-devops-activity-7383962031265304576-YnfF&trk=public_post_comment-cta)\n\n  To view or add a comment, [sign in](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fthoras_sre-devops-activity-7383962031265304576-YnfF&trk=public_post_feed-cta-banner-cta)\n* [FlowEdge Consulting](https://www.linkedin.com/company/flowedge-consulting?trk=public_post_feed-actor-name)\n\n  48 followers\n\n  + [Report this post](/uas/login?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fflowedge-consulting_aiml-mlops-scalableai-activity-7387669614983409664-XXhj&trk=public_post_ellipsis-menu-semaphore-sign-in-redirect&guestReportContentType=POST&_f=guest-reporting)\n\n  Scaling AI Models: Resource Optimization, Caching, and Modular Design Don't let resource constraints limit your AI potential ‚Äî optimize, cache, and modularize for maximum performance. Scaling AI models from proof-of-concept to production-grade services presents unique challenges. High computational demands, latency requirements, and managing operational costs can quickly become bottlenecks for even the most promising AI applications. This isn't just about throwing more hardware at the problem; it's about smart architecture. ‚û°Ô∏è Resource Optimization: This is foundational. It involves techniques like model quantization, pruning, and efficient batching to minimize compute and memory footprint without significant performance degradation. Utilizing specialized hardware (GPUs, TPUs) effectively, and implementing dynamic batching based on real-time load, ensures you're getting the most out of your infrastructure. For distributed inference, frameworks like Ray or Kubernetes-native solutions can orchestrate resource allocation seamlessly. ‚û°Ô∏è Strategic Caching: Often overlooked, caching can dramatically reduce inference load and improve response times. ‚úÖ Request Caching: For frequently identical or similar inference requests, serve pre-computed results. ‚úÖ Feature Caching: Store pre-processed features for common input patterns, avoiding redundant computation. ‚úÖ Model Caching: Keep frequently used model versions or weights in fast-access memory. This reduces redundant computations, offloading the core model from repeated, identical work. Tools like Redis or in-memory caches are invaluable here. ‚û°Ô∏è Modular Design: Breaking down monolithic AI pipelines into smaller, independently deployable services transforms scalability and maintainability. üí° Microservices for Inference: Decompose complex models into sub-models or feature extraction services. Each can be scaled, updated, and managed independently. üí° API-Driven Interfaces: Clear contracts between modules allow for independent evolution. üí° Fault Isolation: A failure in one component doesn't bring down the entire system. This approach leverages principles from distributed systems, enabling easier A/B testing, faster iterations, and more robust deployments. Think Kubeflow Pipelines or custom orchestration built on Kubernetes. Implementing these strategies requires a deep understanding of your model's behavior and your infrastructure's capabilities. It's an iterative process of profiling, re-architecting, and monitoring, ultimately leading to more resilient, cost-effective, and higher-performing AI systems. For developers and engineers, mastering these techniques is key to unlocking true AI potential at scale. [#AIML](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Faiml&trk=public_post-text) [#MLOps](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fmlops&trk=public_post-text) [#ScalableAI](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fscalableai&trk=public_post-text) [#SystemDesign](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fsystemdesign&trk=public_post-text) [#DistributedSystems](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fdistributedsystems&trk=public_post-text) [#Engineering](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fengineering&trk=public_post-text) [#CloudNative](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fcloudnative&trk=public_post-text)\n\n\n\n  [1](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fflowedge-consulting_aiml-mlops-scalableai-activity-7387669614983409664-XXhj&trk=public_post_social-actions-reactions)\n\n  [Like](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fflowedge-consulting_aiml-mlops-scalableai-activity-7387669614983409664-XXhj&trk=public_post_like-cta)   [Comment](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fflowedge-consulting_aiml-mlops-scalableai-activity-7387669614983409664-XXhj&trk=public_post_comment-cta)\n\n  To view or add a comment, [sign in](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fflowedge-consulting_aiml-mlops-scalableai-activity-7387669614983409664-XXhj&trk=public_post_feed-cta-banner-cta)\n* [Uplatz MLOps & LLMOps Studio](https://uk.linkedin.com/company/uplatz-mlops-llmops-studio?trk=public_post_feed-actor-name)\n\n  59 followers\n\n  + [Report this post](/uas/login?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fuplatz-mlops-llmops-studio_mlops-llmops-ai-activity-7390914266788315136-nUcK&trk=public_post_ellipsis-menu-semaphore-sign-in-redirect&guestReportContentType=POST&_f=guest-reporting)\n\n  üöÄ Modern AI Infrastructure: Designing Scalable Pipelines for ML and LLM Workloads The AI landscape is evolving faster than ever ‚Äî and with it, the infrastructure that powers machine learning (ML) and large language models (LLMs). Today‚Äôs enterprises need architectures that can seamlessly handle both ‚Äî predictive models that forecast and generative systems that create. --- üí° The Challenge Traditional MLOps setups were built for structured data and batch inference. But LLMs bring new complexities ‚Äî GPU orchestration, vector databases, retrieval pipelines, context windows, and prompt versioning. The result? A pressing need for hybrid AI infrastructure that unifies these two worlds. ‚öôÔ∏è The Solution: Scalable AI Pipelines A modern AI stack blends performance with flexibility through: 1. Containerized Deployments: Kubernetes, Docker, and Ray to scale across compute clusters. 2. Unified Feature & Embedding Stores: Combining Feast and ChromaDB for ML and LLM data workflows. 3.Hybrid Serving Architecture: Tools like KServe, Triton, and vLLM to deploy models across cloud, edge, and GPU nodes. 4. Observability & Governance Layers: Monitoring drift, hallucinations, and bias while ensuring compliance with GDPR and the EU AI Act. 5. Continuous Training & Fine-Tuning Pipelines: Automating retraining for ML and fine-tuning for LLMs under a single CI/CD framework. --- üß© The Outcome Scalable pipelines don‚Äôt just deploy models ‚Äî they operationalize intelligence. They turn experimentation into impact, enabling data teams to deploy, monitor, and iterate faster across every AI modality. At Uplatz MLOps & LLMOps Studio, we‚Äôre building this next-generation infrastructure ‚Äî one that unifies data, models, and governance into a seamless operational fabric. ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ üì© Contact Us Want to design next-generation MLOps & LLMOps architectures with us? Let‚Äôs connect. üìß [support@uplatz.com](https://www.linkedin.com/redir/redirect?url=mailto%3Asupport%40uplatz%2Ecom&urlhash=VkJd&trk=public_post-text) üìû +44 7459 302492 üåê [https://uplatz.ai](https://www.linkedin.com/redir/redirect?url=https%3A%2F%2Fuplatz%2Eai&urlhash=4eON&trk=public_post-text) ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ [#MLOps](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fmlops&trk=public_post-text) [#LLMOps](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fllmops&trk=public_post-text) [#AI](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fai&trk=public_post-text) [#MachineLearning](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fmachinelearning&trk=public_post-text) [#GenerativeAI](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fgenerativeai&trk=public_post-text) [#DataEngineering](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fdataengineering&trk=public_post-text) [#AIOps](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Faiops&trk=public_post-text) [#Kubernetes](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fkubernetes&trk=public_post-text) [#ModelServing](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fmodelserving&trk=public_post-text) [#VectorDB](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fvectordb&trk=public_post-text) [#Uplatz](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fuplatz&trk=public_post-text) [#CloudAI](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fcloudai&trk=public_post-text) [#Automation](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fautomation&trk=public_post-text)\n\n\n\n  [1](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fuplatz-mlops-llmops-studio_mlops-llmops-ai-activity-7390914266788315136-nUcK&trk=public_post_social-actions-reactions)\n\n  [Like](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fuplatz-mlops-llmops-studio_mlops-llmops-ai-activity-7390914266788315136-nUcK&trk=public_post_like-cta)   [Comment](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fuplatz-mlops-llmops-studio_mlops-llmops-ai-activity-7390914266788315136-nUcK&trk=public_post_comment-cta)\n\n  To view or add a comment, [sign in](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fuplatz-mlops-llmops-studio_mlops-llmops-ai-activity-7390914266788315136-nUcK&trk=public_post_feed-cta-banner-cta)\n* [Aman Pandey](https://in.linkedin.com/in/aman-pandey-9a85b1220?trk=public_post_feed-actor-name)\n\n  + [Report this post](/uas/login?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Faman-pandey-9a85b1220_pytorch-ray-aiengineering-activity-7387005664168128514-Yq7B&trk=public_post_ellipsis-menu-semaphore-sign-in-redirect&guestReportContentType=POST&_f=guest-reporting)\n\n  ùêèùê≤ùêìùê®ùê´ùêúùê° + ùêëùêöùê≤: ùêìùê°ùêû ùêÖùêÆùê≠ùêÆùê´ùêû ùê®ùêü ùêíùêúùêöùê•ùêöùêõùê•ùêû ùêÄùêà ùêëùêöùê≤ ùê°ùêöùê¨ ùê®ùêüùêüùê¢ùêúùê¢ùêöùê•ùê•ùê≤ ùê£ùê®ùê¢ùêßùêûùêù ùê≠ùê°ùêû ùêèùê≤ùêìùê®ùê´ùêúùê° ùêÖùê®ùêÆùêßùêùùêöùê≠ùê¢ùê®ùêß. This is more than a partnership ‚Äî it‚Äôs the unification of the world‚Äôs most popular deep learning framework with the leading distributed computing platform. ùêñùê°ùê≤ ùêàùê≠ ùêåùêöùê≠ùê≠ùêûùê´ùê¨ Building an AI model is easy. Getting it to train efficiently across GPUs and serve thousands of users reliably? That‚Äôs the hard part. Traditionally, scaling PyTorch models meant complex distributed scripts, resource management, and endless debugging. ùëπùíÇùíö ùíÑùíâùíÇùíèùíàùíÜùíî ùíïùíâùíÇùíï. It brings distributed computing directly into PyTorch ‚Äî no infrastructure pain, no code rewrites. Example: Training a vision transformer on millions of images used to take weeks of setup. With Ray, you scale across clusters in minutes and cut training time from days to hours. ùêÄ ùêîùêßùê¢ùêüùê¢ùêûùêù ùêíùê≠ùêöùêúùê§ ùêüùê®ùê´ ùêÄùêà ùêìùêûùêöùê¶ùê¨ Now you can: >ùêÅùêÆùê¢ùê•ùêù ùê∞ùê¢ùê≠ùê° ùêèùê≤ùêìùê®ùê´ùêúùê° ‚Üí ùêíùêúùêöùê•ùêû ùê∞ùê¢ùê≠ùê° ùêëùêöùê≤ ‚Üí ùêíùêûùê´ùêØùêû ùê∞ùê¢ùê≠ùê° ùêëùêöùê≤ ùêíùêûùê´ùêØùêû No fragile integrations. No massive DevOps teams. Just a clean, scalable, end-to-end workflow that takes you from research to production seamlessly. The gap between ‚Äúworks on my machine‚Äù and ‚Äúserves millions reliably‚Äù is closing fast. This move democratizes scalable AI infrastructure ‚Äî putting power once reserved for tech giants into every team‚Äôs hands. [#PyTorch](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fpytorch&trk=public_post-text) [#Ray](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fray&trk=public_post-text) [#AIEngineering](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Faiengineering&trk=public_post-text) [#MLOps](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fmlops&trk=public_post-text) [#DeepLearning](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fdeeplearning&trk=public_post-text) [#ScalableAI](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fscalableai&trk=public_post-text)\n\n\n\n  [16](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Faman-pandey-9a85b1220_pytorch-ray-aiengineering-activity-7387005664168128514-Yq7B&trk=public_post_social-actions-reactions)\n\n  [Like](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Faman-pandey-9a85b1220_pytorch-ray-aiengineering-activity-7387005664168128514-Yq7B&trk=public_post_like-cta)   [Comment](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Faman-pandey-9a85b1220_pytorch-ray-aiengineering-activity-7387005664168128514-Yq7B&trk=public_post_comment-cta)\n\n  To view or add a comment, [sign in](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Faman-pandey-9a85b1220_pytorch-ray-aiengineering-activity-7387005664168128514-Yq7B&trk=public_post_feed-cta-banner-cta)\n* [Biswajit Lima, MS (CS), MBA](https://www.linkedin.com/in/bklima?trk=public_post_feed-actor-name)\n\n  + [Report this post](/uas/login?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fbklima_awsoutage-multicloudstrategy-agenticai-activity-7386640576928149504-72RF&trk=public_post_ellipsis-menu-semaphore-sign-in-redirect&guestReportContentType=POST&_f=guest-reporting)\n\n  ‚òÅÔ∏è When AWS Takes a Nap: The Wake-Up Call for Multi-Cloud Mastery in AI ‚òÅÔ∏è AWS's latest siesta serves as a stark memo: Single-cloud dependency is the Achilles' heel of modern enterprises. In the high-stakes arena of Generative and Agentic AI deployment, even a single glitch can cascade into operational Armageddon. Enter multi-cloud‚Äîthe non-negotiable foundation for turbocharging performance, slashing costs, and fortifying governance. Yet, it demands ninja-level finesse to conquer orchestration tangles, observability blind spots, governance sprawl, FinOps surprises, and AI service silos. Best Practices for Agentic AI Architecture in Multi-Cloud Setup: Unified Orchestration Layer: Harmonize your AI symphony without missing a beat. Federated Governance Framework: Decentralized control, centralized sanity. Dedicated AI Observability Platform: X-ray vision for agent behaviors. Proactive AI FinOps: Predict and prune costs like a pro gardener. AI Abstraction Layer: Seamless swaps, zero vendor handcuffs. Don't let outages orchestrate your downfall‚Äîdesign for invincibility. How are you future-proofing your AI stack? Let's discuss! üí¨ [#AWSOutage](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fawsoutage&trk=public_post-text) [#MultiCloudStrategy](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fmulticloudstrategy&trk=public_post-text) [#AgenticAI](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fagenticai&trk=public_post-text) [#FinTech](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Ffintech&trk=public_post-text) [#AIArchitecture](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Faiarchitecture&trk=public_post-text) [#CapitalMarkets](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fcapitalmarkets&trk=public_post-text) [#FinancialServices](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Ffinancialservices&trk=public_post-text) [#AI](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fai&trk=public_post-text) [#EnterpriseAI](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fenterpriseai&trk=public_post-text) [#AIGovernance](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Faigovernance&trk=public_post-text) [#Innovation](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Finnovation&trk=public_post-text) [#GenAI](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fgenai&trk=public_post-text) [#InvestmentBanking](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Finvestmentbanking&trk=public_post-text)\n\n\n\n  [Like](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fbklima_awsoutage-multicloudstrategy-agenticai-activity-7386640576928149504-72RF&trk=public_post_like-cta)   [Comment](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fbklima_awsoutage-multicloudstrategy-agenticai-activity-7386640576928149504-72RF&trk=public_post_comment-cta)\n\n  To view or add a comment, [sign in](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fbklima_awsoutage-multicloudstrategy-agenticai-activity-7386640576928149504-72RF&trk=public_post_feed-cta-banner-cta)\n\n3,503 followers\n\n* [58 Posts](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww%2Elinkedin%2Ecom%2Fin%2Fkalaiarasan-balaraman%2Frecent-activity%2F&trk=public_post_follow-posts)\n\n[View Profile](https://in.linkedin.com/in/kalaiarasan-balaraman?trk=public_post_follow-view-profile)   [Follow](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww%2Elinkedin%2Ecom%2Ffeed%2Fupdate%2Furn%3Ali%3Aactivity%3A7381194175637217283&trk=public_post_follow)\n\n## Explore related topics\n\n* [Developing Scalable AI Use Cases](https://www.linkedin.com/top-content/artificial-intelligence/scaling-ai-solutions-in-enterprises/developing-scalable-ai-use-cases/)\n* [Building Scalable AI Infrastructure](https://www.linkedin.com/top-content/artificial-intelligence/scaling-ai-solutions-in-enterprises/building-scalable-ai-infrastructure/)\n* [Best Practices for Deploying LLM Systems](https://www.linkedin.com/top-content/artificial-intelligence/mlops-for-ai-development/best-practices-for-deploying-llm-systems/)\n* [Building Scalable Applications With AI Frameworks](https://www.linkedin.com/top-content/artificial-intelligence/ai-frameworks-for-software-development/building-scalable-applications-with-ai-frameworks/)\n* [Evaluating Long-Term AI Scalability](https://www.linkedin.com/top-content/artificial-intelligence/scaling-ai-solutions-in-enterprises/evaluating-long-term-ai-scalability/)\n* [How to Build Reliable LLM Systems for Production](https://www.linkedin.com/top-content/artificial-intelligence/mlops-for-ai-development/how-to-build-reliable-llm-systems-for-production/)\n\n## Explore content categories\n\n* [Career](https://www.linkedin.com/top-content/career/)\n* [Productivity](https://www.linkedin.com/top-content/productivity/)\n* [Finance](https://www.linkedin.com/top-content/finance/)\n* [Soft Skills & Emotional Intelligence](https://www.linkedin.com/top-content/soft-skills-emotional-intelligence/)\n* [Project Management](https://www.linkedin.com/top-content/project-management/)\n* [Education](https://www.linkedin.com/top-content/education/)\n* [Technology](https://www.linkedin.com/top-content/technology/)\n* [Leadership](https://www.linkedin.com/top-content/leadership/)\n* [Ecommerce](https://www.linkedin.com/top-content/ecommerce/)\n* [User Experience](https://www.linkedin.com/top-content/user-experience/)\n\n## Sign in to view more content\n\nCreate your free account or sign in to continue your search\n\n## Welcome back\n\nBy clicking Continue to join or sign in, you agree to LinkedIn‚Äôs [User Agreement](/legal/user-agreement?trk=public_post_contextual-sign-in-modal_sign-in-modal_auth-button_user-agreement), [Privacy Policy](/legal/privacy-policy?trk=public_post_contextual-sign-in-modal_sign-in-modal_auth-button_privacy-policy), and [Cookie Policy](/legal/cookie-policy?trk=public_post_contextual-sign-in-modal_sign-in-modal_auth-button_cookie-policy).\n\nNew to LinkedIn? [Join now](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww%2Elinkedin%2Ecom%2Fposts%2Fkalaiarasan-balaraman_ai-machinelearning-mlops-activity-7381194175637217283-Izsp&trk=public_post_contextual-sign-in-modal_sign-in-modal_join-link)\n\nor\n\nNew to LinkedIn? [Join now](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww%2Elinkedin%2Ecom%2Fposts%2Fkalaiarasan-balaraman_ai-machinelearning-mlops-activity-7381194175637217283-Izsp&trk=public_post_contextual-sign-in-modal_join-link)\n\nBy clicking Continue to join or sign in, you agree to LinkedIn‚Äôs [User Agreement](/legal/user-agreement?trk=linkedin-tc_auth-button_user-agreement), [Privacy Policy](/legal/privacy-policy?trk=linkedin-tc_auth-button_privacy-policy), and [Cookie Policy](/legal/cookie-policy?trk=linkedin-tc_auth-button_cookie-policy).\n\nNever miss a beat on the app\n\nDon‚Äôt have the app? Get it in the Microsoft Store.\n\n [Open the app](ms-windows-store://pdp/?ProductId=9WZDNCRFJ4Q7&mode=mini&cid=guest_desktop_upsell_post2)\n\n "
    },
    {
      "url": "https://www.linkedin.com/posts/sanjay-jha-2a425719_fastapi-machinelearning-ai-activity-7382114449446404096-DUPA",
      "title": "Why FastAPI is a Game-Changer for AI/ML Model ...",
      "content": "üöÄ Why FastAPI is a Game-Changer for AI/ML Model Deployment In AI/ML projects, building the model is just half the battle ‚Äî the real challenge starts when you need to serve predictions at scale, securely, and efficiently. That‚Äôs where FastAPI shines. ‚ö° Here‚Äôs why it‚Äôs becoming the go-to framework for AI engineers and data scientists: ‚úÖ 1. Blazing Fast Performance FastAPI is built on modern async architecture ‚Äî perfect for low-latency model inference and real-time AI apps. ‚úÖ 2. Seamless Model Serving You can wrap any ML/DL model (Scikit-learn, TensorFlow, PyTorch, or XGBoost) inside an API endpoint and deploy it using Docker & Kubernetes in minutes. ‚úÖ 3. Auto-Validation & Type Safety Using Pydantic, FastAPI automatically validates input data ‚Äî no more broken predictions due to bad JSON or [...] input data ‚Äî no more broken predictions due to bad JSON or invalid payloads. ‚úÖ 4. Built-in Swagger Docs FastAPI automatically generates beautiful, interactive documentation ‚Äî great for testing and collaboration. ‚úÖ 5. Cloud & DevOps Friendly Whether you deploy on AWS Lambda, EKS, or SageMaker, FastAPI integrates seamlessly with CI/CD pipelines, Prometheus, and Grafana for monitoring. ‚úÖ 6. Ideal for Generative AI & RAG Apps FastAPI is often used with LangChain, OpenAI, or Amazon Bedrock to build secure, high-performance GenAI APIs and multi-agent systems. üí° Example Use Cases Model serving APIs for prediction and recommendation engines Chatbots and conversational AI RAG-based enterprise assistants Computer vision and NLP microservices I recently built a production-ready FastAPI ML API [...] separate AI services, you get tight coupling, lower latency, and easier maintenance Faster deployment of intelligent features (predictions, natural language, automation) You keep control of your stack, governance, and costs If your team is curious about embedding AI in your existing .NET ecosystem ‚Äî or evaluating how to modernize your applications with intelligence ‚Äî I‚Äôd love to explore how we might help you architect, prototype, or integrate AI features. Let me know if you‚Äôd like to discuss further or see a proof-of-concept. #dotnet #csharp #AI #machinelearning #azureopenai #mlnet #softwarearchitecture #enterprisetech",
      "score": 0.6246834,
      "raw_content": "# Sanjay Jha‚Äôs Post\n\n[Sanjay Jha](https://in.linkedin.com/in/sanjay-jha-2a425719?trk=public_post_feed-actor-name)\n\nArchitect„ÄêGenAI | LLM | RAG | AI Agent | Devops ‚ôæÔ∏è | Cloud ‚òÅÔ∏è Aws/Azure Certified Architect | System Design | CI/CD | K8s | Linux üêß| Networking üåê CCNA | Security | NMS | Python | Automation | CSM¬Æ | CSPO¬Æ„Äë\n\n* [Report this post](/uas/login?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fsanjay-jha-2a425719_fastapi-machinelearning-ai-activity-7382114449446404096-DUPA&trk=public_post_ellipsis-menu-semaphore-sign-in-redirect&guestReportContentType=POST&_f=guest-reporting)\n\nüöÄ¬†Why FastAPI is a Game-Changer for AI/ML Model Deployment In AI/ML projects, building the model is just¬†half the battle¬†‚Äî the real challenge starts when you need to¬†serve predictions at scale, securely, and efficiently. That‚Äôs where¬†FastAPI¬†shines. ‚ö° Here‚Äôs why it‚Äôs becoming the go-to framework for AI engineers and data scientists: ‚úÖ¬†1. Blazing Fast Performance FastAPI is built on modern async architecture ‚Äî perfect for¬†low-latency model inference¬†and real-time AI apps. ‚úÖ¬†2. Seamless Model Serving You can wrap any ML/DL model (Scikit-learn, TensorFlow, PyTorch, or XGBoost) inside an API endpoint and deploy it using¬†Docker & Kubernetes¬†in minutes. ‚úÖ¬†3. Auto-Validation & Type Safety Using Pydantic, FastAPI automatically validates input data ‚Äî no more broken predictions due to bad JSON or invalid payloads. ‚úÖ¬†4. Built-in Swagger Docs FastAPI automatically generates beautiful, interactive documentation ‚Äî great for testing and collaboration. ‚úÖ¬†5. Cloud & DevOps Friendly Whether you deploy on¬†AWS Lambda, EKS, or SageMaker, FastAPI integrates seamlessly with CI/CD pipelines, Prometheus, and Grafana for monitoring. ‚úÖ¬†6. Ideal for Generative AI & RAG Apps FastAPI is often used with¬†LangChain, OpenAI, or Amazon Bedrock¬†to build secure, high-performance GenAI APIs and multi-agent systems. üí°¬†Example Use Cases Model serving APIs for prediction and recommendation engines Chatbots and conversational AI RAG-based enterprise assistants Computer vision and NLP microservices I recently built a¬†production-ready FastAPI ML API template¬†that includes: /predict¬†endpoint Prometheus metrics Docker support Swagger docs Auto input validation [#FastAPI](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Ffastapi&trk=public_post-text) [#MachineLearning](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fmachinelearning&trk=public_post-text) [#AI](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fai&trk=public_post-text) [#MLOps](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fmlops&trk=public_post-text) [#DevOps](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fdevops&trk=public_post-text) [#GenerativeAI](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fgenerativeai&trk=public_post-text) [#Python](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fpython&trk=public_post-text) [#DataScience](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fdatascience&trk=public_post-text) [#APIs](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fapis&trk=public_post-text) [#LangChain](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Flangchain&trk=public_post-text) [#AWS](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Faws&trk=public_post-text) [#Bedrock](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fbedrock&trk=public_post-text) [#Kubernetes](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fkubernetes&trk=public_post-text)\n\n\n\n[Like](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww%2Elinkedin%2Ecom%2Fposts%2Fsanjay-jha-2a425719_fastapi-machinelearning-ai-activity-7382114449446404096-DUPA&trk=public_post_like-cta)   [Comment](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww%2Elinkedin%2Ecom%2Fposts%2Fsanjay-jha-2a425719_fastapi-machinelearning-ai-activity-7382114449446404096-DUPA&trk=public_post_comment-cta)\n\nTo view or add a comment, [sign in](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww%2Elinkedin%2Ecom%2Fposts%2Fsanjay-jha-2a425719_fastapi-machinelearning-ai-activity-7382114449446404096-DUPA&trk=public_post_feed-cta-banner-cta)\n\n## More Relevant Posts\n\n* [Muhammad Asif Aziz](https://www.linkedin.com/in/asifaziz-datascientist?trk=public_post_feed-actor-name)\n\n  Top 2% Data Scientist | Top Rated Freelancer on Upwork | Machine Learning | Deep Learning | Gen AI | LLMS | NLP | Computer Vision | Senior Data Scientist @ Turing\n\n  + [Report this post](/uas/login?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fasifaziz-datascientist_muhammad-asif-a-activity-7376280884049588224-6fST&trk=public_post_ellipsis-menu-semaphore-sign-in-redirect&guestReportContentType=POST&_f=guest-reporting)\n\n  RAG + LLaMA is not just hype. It‚Äôs the formula turning open-source models into production-ready powerhouses. Why this matters: Many teams assume they need GPT-4 or Claude for serious apps. But with the right Retrieval-Augmented Generation (RAG) setup, LLaMA models can deliver enterprise-level performance. Here‚Äôs what makes it work: 1. Lightweight + Smart ‚Ä¢ LLaMA isn‚Äôt the biggest model. ‚Ä¢ But combined with RAG, it feels much ‚Äúsmarter.‚Äù ‚Ä¢ Retrieval fills the gaps fine-tuning can‚Äôt. 2. Cost advantage ‚Ä¢ Open-source models slash API costs. ‚Ä¢ Pairing with RAG means fewer tokens, cleaner context. ‚Ä¢ More control, less spend. 3. Flexibility wins ‚Ä¢ You can host LLaMA locally, in the cloud, or hybrid. ‚Ä¢ RAG pipelines let you control chunking, indexing, retrieval strategies. ‚Ä¢ The system bends to your data, not the other way around. 4. Evaluation matters ‚Ä¢ Don‚Äôt just trust the ‚Äúopen-source hype.‚Äù ‚Ä¢ Test retrieval relevance, latency, and hallucinations. ‚Ä¢ Small optimizations (like better chunking) ‚Üí big performance boosts. Key takeaway: LLaMA alone is good. RAG alone is powerful. But RAG + LLaMA together? That‚Äôs where open-source meets real-world impact. üí° My question for you: If you had to choose today‚Äî Would you build your next app on a closed-source giant like GPT-4, or on an open-source + RAG stack like LLaMA? [https://lnkd.in/dPRe6QNG](https://lnkd.in/dPRe6QNG?trk=public_post-text) [#AI](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fai&trk=public_post-text) [#MachineLearning](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fmachinelearning&trk=public_post-text) [#LLM](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fllm&trk=public_post-text) [#ArtificialIntelligence](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fartificialintelligence&trk=public_post-text) [#DataScience](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fdatascience&trk=public_post-text) [#GenerativeAI](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fgenerativeai&trk=public_post-text) [#LLaMA](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fllama&trk=public_post-text) [#RAG](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Frag&trk=public_post-text) [#OpenSourceAI](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fopensourceai&trk=public_post-text) [#FineTuning](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Ffinetuning&trk=public_post-text) [#VectorDatabases](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fvectordatabases&trk=public_post-text) [#MLOps](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fmlops&trk=public_post-text) [#LLMEngineering](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fllmengineering&trk=public_post-text) [#RetrievalAugmentedGeneration](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fretrievalaugmentedgeneration&trk=public_post-text) [#AIDevelopment](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Faidevelopment&trk=public_post-text) [#DeepLearning](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fdeeplearning&trk=public_post-text)\n\n  [Muhammad Asif A.   upwork.com](https://www.linkedin.com/redir/redirect?url=https%3A%2F%2Fwww%2Eupwork%2Ecom%2Ffreelancers%2F%7E016606c955bd9c1cb6&urlhash=OS0U&trk=public_post_feed-article-content)\n\n  [8](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fasifaziz-datascientist_muhammad-asif-a-activity-7376280884049588224-6fST&trk=public_post_social-actions-reactions)\n\n  [Like](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fasifaziz-datascientist_muhammad-asif-a-activity-7376280884049588224-6fST&trk=public_post_like-cta)   [Comment](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fasifaziz-datascientist_muhammad-asif-a-activity-7376280884049588224-6fST&trk=public_post_comment-cta)\n\n  To view or add a comment, [sign in](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fasifaziz-datascientist_muhammad-asif-a-activity-7376280884049588224-6fST&trk=public_post_feed-cta-banner-cta)\n* [Harikrishnan Rajaram](https://www.linkedin.com/in/harikrishnan-rajaram-b6473a137?trk=public_post_feed-actor-name)\n\n  Multi-Cloud & AI Strategist | Architecting and technically guiding the deployment of enterprise cloud & GenAI strategies on Azure, GCP, AWS‚Äîfrom vision to production for maximum impact.\n\n  + [Report this post](/uas/login?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fharikrishnan-rajaram-b6473a137_ai-llm-genai-activity-7375566496816844800--i3M&trk=public_post_ellipsis-menu-semaphore-sign-in-redirect&guestReportContentType=POST&_f=guest-reporting)\n\n  How to become an AI-first enterprise: OpenAI‚Äôs 18 steps span: How to align employees, leadership on AI strategy. How to enable and motivate teams to use AI. How to amplify AI wins and use cases across teams. How to speed up decisions to keep pace with AI. How to run lightweight guidelines for responsible AI. Master the 18 steps below to become AI-first. üëâ Save this to revisit later. [#ai](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fai&trk=public_post-text) [#llm](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fllm&trk=public_post-text) [#genai](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fgenai&trk=public_post-text) [#MachineLearning](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fmachinelearning&trk=public_post-text) [#DeepLearning](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fdeeplearning&trk=public_post-text) [#CloudComputing](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fcloudcomputing&trk=public_post-text) [#AITechnology](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Faitechnology&trk=public_post-text) [#DataScience](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fdatascience&trk=public_post-text) [#SmartSolutions](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fsmartsolutions&trk=public_post-text) #TechInnovation#AIResearch#AIForGood [#Automation](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fautomation&trk=public_post-text) [#AICommunity](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Faicommunity&trk=public_post-text) [#Python](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fpython&trk=public_post-text) [#TCS](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Ftcs&trk=public_post-text) #[#MultiAgentSystems](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fmultiagentsystems&trk=public_post-text) [#GenerativeAI](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fgenerativeai&trk=public_post-text) [#Analytics](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fanalytics&trk=public_post-text) #DataScience#EnterpriseAI [#AgenticAI](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fagenticai&trk=public_post-text)¬†[#A2A](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fa2a&trk=public_post-text) [#MCP](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fmcp&trk=public_post-text) [#AutonomousAgents](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fautonomousagents&trk=public_post-text) [#AzureAI](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fazureai&trk=public_post-text) [#AWSBedrock](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fawsbedrock&trk=public_post-text) [#Neurotechnology](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fneurotechnology&trk=public_post-text) [#VectorDatabases](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fvectordatabases&trk=public_post-text) [#RAG](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Frag&trk=public_post-text) [#SemanticSearch](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fsemanticsearch&trk=public_post-text) [#DataEngineering](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fdataengineering&trk=public_post-text) [#DataScience](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fdatascience&trk=public_post-text) [#azure](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fazure&trk=public_post-text) [#aws](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Faws&trk=public_post-text) [#Gemini](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fgemini&trk=public_post-text) [#gcp](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fgcp&trk=public_post-text) [#AITools](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Faitools&trk=public_post-text) [#FutureOfLearning](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Ffutureoflearning&trk=public_post-text) [#AIGamechanger](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Faigamechanger&trk=public_post-text) [#SmartLearning](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fsmartlearning&trk=public_post-text) [#TechWithAI](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Ftechwithai&trk=public_post-text) [#AIForEveryone](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Faiforeveryone&trk=public_post-text) [#NextGenLearning](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fnextgenlearning&trk=public_post-text) [#LearnWithAI](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Flearnwithai&trk=public_post-text) [#AIRevolution](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fairevolution&trk=public_post-text) [#Agentical](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fagentical&trk=public_post-text)\n\n\n\n  [12](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fharikrishnan-rajaram-b6473a137_ai-llm-genai-activity-7375566496816844800--i3M&trk=public_post_social-actions-reactions)\n\n  [Like](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fharikrishnan-rajaram-b6473a137_ai-llm-genai-activity-7375566496816844800--i3M&trk=public_post_like-cta)   [Comment](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fharikrishnan-rajaram-b6473a137_ai-llm-genai-activity-7375566496816844800--i3M&trk=public_post_comment-cta)\n\n  To view or add a comment, [sign in](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fharikrishnan-rajaram-b6473a137_ai-llm-genai-activity-7375566496816844800--i3M&trk=public_post_feed-cta-banner-cta)\n* [Harikrishnan Rajaram](https://www.linkedin.com/in/harikrishnan-rajaram-b6473a137?trk=public_post_feed-actor-name)\n\n  Multi-Cloud & AI Strategist | Architecting and technically guiding the deployment of enterprise cloud & GenAI strategies on Azure, GCP, AWS‚Äîfrom vision to production for maximum impact.\n\n  + [Report this post](/uas/login?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fharikrishnan-rajaram-b6473a137_building-ai-agents-with-mcp-a-practical-activity-7379701215959359488-IzVo&trk=public_post_ellipsis-menu-semaphore-sign-in-redirect&guestReportContentType=POST&_f=guest-reporting)\n\n  The Model Context Protocol is a standardized way for AI applications to interact with external tools and data sources. Think of MCP as a universal adapter that lets AI models connect to various services in a consistent way. Why MCP Matters? Before MCP, every tool integration was custom-built. If you wanted your AI to check weather, send emails, or query a database, you‚Äôd write unique code for each integration. MCP solves this by providing: - Standardized Interface: Tools expose themselves through a common protocol - Discoverability: Agents can learn what tools are available and how to use them - Modularity: Add or remove tools without changing agent code - Separation of Concerns: Tool servers handle specific tasks while agents orchestrate Know more about building AI Agents with MCP: [https://lnkd.in/gCfNd2T9](https://lnkd.in/gCfNd2T9?trk=public_post-text) [#ai](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fai&trk=public_post-text) [#llm](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fllm&trk=public_post-text) [#genai](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fgenai&trk=public_post-text) [#MachineLearning](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fmachinelearning&trk=public_post-text) [#DeepLearning](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fdeeplearning&trk=public_post-text) [#CloudComputing](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fcloudcomputing&trk=public_post-text) [#AITechnology](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Faitechnology&trk=public_post-text) [#DataScience](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fdatascience&trk=public_post-text) [#SmartSolutions](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fsmartsolutions&trk=public_post-text) #TechInnovation#AIResearch#AIForGood [#Automation](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fautomation&trk=public_post-text) [#AICommunity](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Faicommunity&trk=public_post-text) [#Python](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fpython&trk=public_post-text) [#TCS](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Ftcs&trk=public_post-text) #[#MultiAgentSystems](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fmultiagentsystems&trk=public_post-text) [#GenerativeAI](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fgenerativeai&trk=public_post-text) [#Analytics](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fanalytics&trk=public_post-text) #DataScience#EnterpriseAI [#AgenticAI](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fagenticai&trk=public_post-text)¬†[#A2A](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fa2a&trk=public_post-text) [#MCP](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fmcp&trk=public_post-text) [#AutonomousAgents](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fautonomousagents&trk=public_post-text) [#AzureAI](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fazureai&trk=public_post-text) [#AWSBedrock](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fawsbedrock&trk=public_post-text) [#Neurotechnology](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fneurotechnology&trk=public_post-text) [#VectorDatabases](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fvectordatabases&trk=public_post-text) [#RAG](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Frag&trk=public_post-text) [#SemanticSearch](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fsemanticsearch&trk=public_post-text) [#DataEngineering](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fdataengineering&trk=public_post-text) [#DataScience](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fdatascience&trk=public_post-text) [#azure](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fazure&trk=public_post-text) [#aws](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Faws&trk=public_post-text) [#Gemini](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fgemini&trk=public_post-text) [#gcp](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fgcp&trk=public_post-text) [#AITools](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Faitools&trk=public_post-text) [#FutureOfLearning](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Ffutureoflearning&trk=public_post-text) [#AIGamechanger](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Faigamechanger&trk=public_post-text) [#SmartLearning](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fsmartlearning&trk=public_post-text) [#TechWithAI](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Ftechwithai&trk=public_post-text) [#AIForEveryone](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Faiforeveryone&trk=public_post-text) [#NextGenLearning](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fnextgenlearning&trk=public_post-text) [#LearnWithAI](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Flearnwithai&trk=public_post-text) [#AIRevolution](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fairevolution&trk=public_post-text) [#Agentical](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fagentical&trk=public_post-text)\n\n  [Building AI Agents with MCP: A Practical Guide to Multi-Agent Systems   medium.com](https://www.linkedin.com/redir/redirect?url=https%3A%2F%2Fmedium%2Ecom%2F%40furkhan_suhail_%2Fbuilding-ai-agents-with-mcp-a-practical-guide-to-multi-agent-systems-a0bf15653eaf&urlhash=34tr&trk=public_post_feed-article-content)\n\n  [9](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fharikrishnan-rajaram-b6473a137_building-ai-agents-with-mcp-a-practical-activity-7379701215959359488-IzVo&trk=public_post_social-actions-reactions)\n\n  [Like](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fharikrishnan-rajaram-b6473a137_building-ai-agents-with-mcp-a-practical-activity-7379701215959359488-IzVo&trk=public_post_like-cta)   [Comment](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fharikrishnan-rajaram-b6473a137_building-ai-agents-with-mcp-a-practical-activity-7379701215959359488-IzVo&trk=public_post_comment-cta)\n\n  To view or add a comment, [sign in](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fharikrishnan-rajaram-b6473a137_building-ai-agents-with-mcp-a-practical-activity-7379701215959359488-IzVo&trk=public_post_feed-cta-banner-cta)\n* [Kuldeep Mishra](https://in.linkedin.com/in/kuldeepmishra07?trk=public_post_feed-actor-name)\n\n  Data Analyst & Scientist | Python & PySpark | AI/ML Engineer | LLM & NLP Expert | Cloud (AWS, Azure) | Scalable AI Solutions\n\n  + [Report this post](/uas/login?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fkuldeepmishra07_the-modern-aiml-roadmap-2025-if-you-activity-7376533581419950080-oKZN&trk=public_post_ellipsis-menu-semaphore-sign-in-redirect&guestReportContentType=POST&_f=guest-reporting)\n\n  üöÄ The Modern AI/ML Roadmap (2025) If you‚Äôre looking to break into or level up in AI/ML, here‚Äôs the practical path forward: üîπ Python & Software Basics ‚Äì Clean code, Git, APIs. üîπ Math Foundations ‚Äì Stats, probability, linear algebra. üîπ Data Prep & EDA ‚Äì Because clean data = smarter models. üîπ Core ML ‚Äì Classification, regression, clustering, evaluation. üîπ Deep Learning ‚Äì The foundation, not the finish line. üîπ NLP & Transformers ‚Äì BERT, GPT, attention mechanisms. üîπ LLMs & Prompting ‚Äì Working effectively with large models. üîπ RAG ‚Äì Combining LLMs with your own data. üîπ AI Agents ‚Äì Multi-agent systems, task planning, workflows. üîπ MLOps ‚Äì Docker, Kubernetes, CI/CD, monitoring. üîπ Vector Databases ‚Äì Pinecone, Chroma, Weaviate. üîπ Observability & Governance ‚Äì Fairness, compliance, LangFuse. üîπ Cloud & API Integrations ‚Äì AWS, Azure, GCP. üîπ Real Projects ‚Äì End-to-end apps that deliver real business value. üí° The key? Don‚Äôt just learn the tools‚Äîfocus on building things that solve real problems.\n\n\n\n  [4](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fkuldeepmishra07_the-modern-aiml-roadmap-2025-if-you-activity-7376533581419950080-oKZN&trk=public_post_social-actions-reactions)\n\n  [Like](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fkuldeepmishra07_the-modern-aiml-roadmap-2025-if-you-activity-7376533581419950080-oKZN&trk=public_post_like-cta)   [Comment](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fkuldeepmishra07_the-modern-aiml-roadmap-2025-if-you-activity-7376533581419950080-oKZN&trk=public_post_comment-cta)\n\n  To view or add a comment, [sign in](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fkuldeepmishra07_the-modern-aiml-roadmap-2025-if-you-activity-7376533581419950080-oKZN&trk=public_post_feed-cta-banner-cta)\n* [typedef](https://www.linkedin.com/company/typedefai?trk=public_post_feed-actor-name)\n\n  450 followers\n\n  + [Report this post](/uas/login?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Ftypedefai_typedef-project-fenic-a-dataframe-for-activity-7377020444463476736-0dih&trk=public_post_ellipsis-menu-semaphore-sign-in-redirect&guestReportContentType=POST&_f=guest-reporting)\n\n  Fenic brings the reliability of DataFrame pipelines to AI workloads‚Äîsemantic joins, markdown parsing, transcripts, and more‚Äînow strengthened with the 0.3.0 update. Dive into the latest improvements. ‚Üí [https://lnkd.in/gVYh4\\_AJ](https://lnkd.in/gVYh4_AJ?trk=public_post-text)\n\n  [Typedef project Fenic: A ‚Äòdataframe‚Äô for LLMs   techzine.eu](https://www.linkedin.com/redir/redirect?url=https%3A%2F%2Fwww%2Etechzine%2Eeu%2Fblogs%2Fdata-management%2F133979%2Ftypedef-project-fenic-a-dataframe-for-llms%2F&urlhash=_hsU&trk=public_post_feed-article-content)\n\n  [4](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Ftypedefai_typedef-project-fenic-a-dataframe-for-activity-7377020444463476736-0dih&trk=public_post_social-actions-reactions)\n\n  [Like](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Ftypedefai_typedef-project-fenic-a-dataframe-for-activity-7377020444463476736-0dih&trk=public_post_like-cta)   [Comment](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Ftypedefai_typedef-project-fenic-a-dataframe-for-activity-7377020444463476736-0dih&trk=public_post_comment-cta)\n\n  To view or add a comment, [sign in](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Ftypedefai_typedef-project-fenic-a-dataframe-for-activity-7377020444463476736-0dih&trk=public_post_feed-cta-banner-cta)\n* [ITVersity Data & AI Community](https://www.linkedin.com/company/itversity?trk=public_post_feed-actor-name)\n\n  10,167 followers\n\n  + [Report this post](/uas/login?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fitversity_itversity-ai-and-data-newsletter-edition-activity-7384113669468737536-n-8R&trk=public_post_ellipsis-menu-semaphore-sign-in-redirect&guestReportContentType=POST&_f=guest-reporting)\n\n  Generative AI is evolving ‚Äî but the real shift in 2025 is responsible AI at scale. This week‚Äôs ITVersity Tech Pulse covers: ‚ö° Global AI event trends: Generative, Responsible, and Edge AI üìä Data Science 2025: Real-time analytics and low-code AI tools ‚òÅÔ∏è Cloud: Hybrid growth and the FinOps maturity gap üíª Hands-on workshop: Build a FastAPI EMI Calculator using Cursor (AI pair-programmer) Stay sharp, stay future-ready üëâ [https://lnkd.in/g-mEfJi4](https://lnkd.in/g-mEfJi4?trk=public_post-text) [#AI](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fai&trk=public_post-text) [#DataScience](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fdatascience&trk=public_post-text) [#CloudComputing](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fcloudcomputing&trk=public_post-text) [#FastAPI](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Ffastapi&trk=public_post-text) [#Python](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fpython&trk=public_post-text) [#CursorAI](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fcursorai&trk=public_post-text) [#TechTrends](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Ftechtrends&trk=public_post-text) [#ITVersity](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fitversity&trk=public_post-text) [#AIatScale](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Faiatscale&trk=public_post-text)\n\n  [ITVersity AI and Data Newsletter - Edition - October 14, 2025   itversity.substack.com](https://www.linkedin.com/redir/redirect?url=https%3A%2F%2Fitversity%2Esubstack%2Ecom%2Fp%2Fitversity-ai-and-data-newsletter-e19&urlhash=-aT1&trk=public_post_feed-article-content)\n\n  [2](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fitversity_itversity-ai-and-data-newsletter-edition-activity-7384113669468737536-n-8R&trk=public_post_social-actions-reactions)\n\n  [Like](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fitversity_itversity-ai-and-data-newsletter-edition-activity-7384113669468737536-n-8R&trk=public_post_like-cta)   [Comment](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fitversity_itversity-ai-and-data-newsletter-edition-activity-7384113669468737536-n-8R&trk=public_post_comment-cta)\n\n  To view or add a comment, [sign in](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fitversity_itversity-ai-and-data-newsletter-edition-activity-7384113669468737536-n-8R&trk=public_post_feed-cta-banner-cta)\n* [Shaukat Hayat](https://pk.linkedin.com/in/shaukat-hayat-b96252164?trk=public_post_feed-actor-name)\n\n  Aircraft Maintenance Engineer specializing in AI Engineering\n\n  + [Report this post](/uas/login?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fshaukat-hayat-b96252164_ai-awsbedrock-claude-activity-7381969359323332608-4UMP&trk=public_post_ellipsis-menu-semaphore-sign-in-redirect&guestReportContentType=POST&_f=guest-reporting)\n\n  üöÄ Building Smarter AI Apps with AWS Bedrock + Claude If you're developing AI-powered applications‚Äîespecially chatbots, RAG pipelines, or intelligent agents‚ÄîAmazon Bedrock is a game-changer. üîπ What is AWS Bedrock? A fully managed service that gives you API access to top-tier foundation models (FMs) like Claude (Anthropic), Titan (Amazon), Jurassic (AI21), and Stability AI‚Äîwithout provisioning infrastructure or managing GPUs. üîπ Why Bedrock Stands Out -Unified API for multiple models -Serverless scalability -Enterprise-grade security (IAM, audit logging) -Seamless integration with AWS stack (Lambda, S3, SageMaker) -Support for fine-tuning, RAG, and tool use üîπ Claude + Bedrock = Conversational Intelligence Claude models (Haiku, Sonnet, Opus) shine in multi-turn dialogue, structured output, and safe reasoning. With Bedrock, you can: ‚úÖ Build chat apps with real-time Claude responses ‚úÖ Use Claude in RAG pipelines for semantic search ‚úÖ Stream responses, cache prompts, and handle tool calls ‚úÖ Return structured JSON/XML for downstream automation ‚úÖ Extend Claude with multi-tool orchestration and contextual memory üîπ Behind the Scenes of a Chat App When a user types ‚ÄúDefine quantum computing‚Äù: Your frontend sends the message to your backend Backend invokes Claude via Bedrock API Claude processes the prompt and returns a response Bedrock delivers the result, and your UI displays it All of this‚Äîwithout managing infrastructure or worrying about model deployment. üí° Whether you're developing AI-powered solutions for education, enterprise automation, customer engagement, or research‚ÄîAWS Bedrock + Claude provides a flexible, scalable foundation to build with confidence. [#AI](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fai&trk=public_post-text) [#AWSBedrock](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fawsbedrock&trk=public_post-text) [#Claude](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fclaude&trk=public_post-text) [#Anthropic](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fanthropic&trk=public_post-text) [#NLP](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fnlp&trk=public_post-text) [#RAG](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Frag&trk=public_post-text) [#Chatbots](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fchatbots&trk=public_post-text) [#IntelligentAgents](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fintelligentagents&trk=public_post-text) [#ServerlessAI](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fserverlessai&trk=public_post-text) [#WorkflowAutomation](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fworkflowautomation&trk=public_post-text) [#MultilingualAI](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fmultilingualai&trk=public_post-text) [#KnowledgeGraphs](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fknowledgegraphs&trk=public_post-text) [#TechForGood](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Ftechforgood&trk=public_post-text)\n\n  [Like](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fshaukat-hayat-b96252164_ai-awsbedrock-claude-activity-7381969359323332608-4UMP&trk=public_post_like-cta)   [Comment](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fshaukat-hayat-b96252164_ai-awsbedrock-claude-activity-7381969359323332608-4UMP&trk=public_post_comment-cta)\n\n  To view or add a comment, [sign in](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fshaukat-hayat-b96252164_ai-awsbedrock-claude-activity-7381969359323332608-4UMP&trk=public_post_feed-cta-banner-cta)\n* [Walid B.](https://fr.linkedin.com/in/walid-b-978151273?trk=public_post_feed-actor-name)\n\n  üöÄ .NET & Azure Software Development Engineer | C# & T-SQL Developer | Helping Businesses Modernize Legacy Apps and Optimize Performance | Microsoft Certified | Angular Front-End Developer\n\n  + [Report this post](/uas/login?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fwalid-b-978151273_artificial-intelligence-with-net-and-c-activity-7377743060887080960-XrP1&trk=public_post_ellipsis-menu-semaphore-sign-in-redirect&guestReportContentType=POST&_f=guest-reporting)\n\n  üöÄ Unlock AI for Your .NET / C# Projects If you‚Äôre building enterprise applications on .NET and C#, you don‚Äôt have to outsource your AI in a disconnected microservice. In my latest article, I explain how to integrate AI models directly into your .NET stack, and share best practices to do so reliably and maintainably. üîç What you‚Äôll learn Why .NET / C# is an excellent choice for embedding AI (performance, seamless integration) Using ML .NET , ONNX Runtime, Infer .NET, and more How to plug in advanced language models (e.g. via Azure OpenAI) TensorFlow .NET examples Best practices: data preprocessing, cross-validation, model monitoring, reuse of pre-trained models üëâ Read it here: [https://lnkd.in/e5VVVZC9](https://lnkd.in/e5VVVZC9?trk=public_post-text) üéØ Why this matters for your business Instead of managing separate AI services, you get tight coupling, lower latency, and easier maintenance Faster deployment of intelligent features (predictions, natural language, automation) You keep control of your stack, governance, and costs If your team is curious about embedding AI in your existing .NET ecosystem ‚Äî or evaluating how to modernize your applications with intelligence ‚Äî I‚Äôd love to explore how we might help you architect, prototype, or integrate AI features. Let me know if you‚Äôd like to discuss further or see a proof-of-concept. [#dotnet](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fdotnet&trk=public_post-text) [#csharp](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fcsharp&trk=public_post-text) [#AI](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fai&trk=public_post-text) [#machinelearning](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fmachinelearning&trk=public_post-text) [#azureopenai](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fazureopenai&trk=public_post-text) [#mlnet](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fmlnet&trk=public_post-text) [#softwarearchitecture](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fsoftwarearchitecture&trk=public_post-text) [#enterprisetech](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fenterprisetech&trk=public_post-text)\n\n  [Artificial Intelligence with .NET and C# ‚Äî Integration and Best Practices   wbhtechblogs.medium.com](https://www.linkedin.com/redir/redirect?url=https%3A%2F%2Fwbhtechblogs%2Emedium%2Ecom%2Fartificial-intelligence-with-net-and-c-integration-and-best-practices-9ec3b9a8e851&urlhash=AqZB&trk=public_post_feed-article-content)\n\n  [2](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fwalid-b-978151273_artificial-intelligence-with-net-and-c-activity-7377743060887080960-XrP1&trk=public_post_social-actions-reactions)\n\n  [Like](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fwalid-b-978151273_artificial-intelligence-with-net-and-c-activity-7377743060887080960-XrP1&trk=public_post_like-cta)   [Comment](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fwalid-b-978151273_artificial-intelligence-with-net-and-c-activity-7377743060887080960-XrP1&trk=public_post_comment-cta)\n\n  To view or add a comment, [sign in](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fwalid-b-978151273_artificial-intelligence-with-net-and-c-activity-7377743060887080960-XrP1&trk=public_post_feed-cta-banner-cta)\n* [Muhammad Awais](https://pk.linkedin.com/in/awais705?trk=public_post_feed-actor-name)\n\n  Founder | Software Engineer | AI Explorer\n\n  + [Report this post](/uas/login?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fawais705_docker-model-runner-general-availability-activity-7380814073828978688-h4M1&trk=public_post_ellipsis-menu-semaphore-sign-in-redirect&guestReportContentType=POST&_f=guest-reporting)\n\n  Ever struggle with deploying AI models consistently across environments? Docker Model Runner (DMR) is a game-changer! üöÄ It containerizes your models, making deployment predictable and scalable. Think less 'it works on my machine' and more 'it works everywhere'! DMR simplifies MLOps, boosting efficiency for developers and data scientists alike. What are your thoughts on containerizing AI workloads? üëá [#Docker](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fdocker&trk=public_post-text) [#AI](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fai&trk=public_post-text) [#MLOps](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fmlops&trk=public_post-text) [#MachineLearning](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fmachinelearning&trk=public_post-text) [#TechTrends](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Ftechtrends&trk=public_post-text) [#DataScience](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fdatascience&trk=public_post-text) Learn more: [https://lnkd.in/dfVMjsck](https://lnkd.in/dfVMjsck?trk=public_post-text)\n\n  [Docker Model Runner General Availability   https://www.docker.com](https://www.linkedin.com/redir/redirect?url=https%3A%2F%2Fwww%2Edocker%2Ecom%2Fblog%2Fannouncing-docker-model-runner-ga%2F&urlhash=EAil&trk=public_post_feed-article-content)\n\n  [2](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fawais705_docker-model-runner-general-availability-activity-7380814073828978688-h4M1&trk=public_post_social-actions-reactions)\n\n  [Like](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fawais705_docker-model-runner-general-availability-activity-7380814073828978688-h4M1&trk=public_post_like-cta)   [Comment](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fawais705_docker-model-runner-general-availability-activity-7380814073828978688-h4M1&trk=public_post_comment-cta)\n\n  To view or add a comment, [sign in](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fawais705_docker-model-runner-general-availability-activity-7380814073828978688-h4M1&trk=public_post_feed-cta-banner-cta)\n* [Prashant Lakhera](https://www.linkedin.com/in/prashant-lakhera-696119b?trk=public_post_feed-actor-name)\n\n  EB1-A Recipient | Founder & CTO | DevOps AI Innovator: SLM | Agents | LLM Dashboards, Innovating at the Intersection of GenAI & DevOps | Author of 4 Books | Blogger | YouTuber | Kubestronaut | Ex-Salesforce, Red Hat\n\n  + [Report this post](/uas/login?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fprashant-lakhera-696119b_tinyllms-devops-slm-activity-7376465438618292224-x48Q&trk=public_post_ellipsis-menu-semaphore-sign-in-redirect&guestReportContentType=POST&_f=guest-reporting)\n\n  üî• How to Get Started with Building Small Language Models from Scratch One of the most common questions I get is: Where do I even begin if I want to build my own Small Language Model(SLM)? Over the past few months, I‚Äôve created four small language models from scratch, and I‚Äôm open-sourcing them so others can learn and build their own. üß† Here are the models I‚Äôve built so far: üîó GPT-2: [https://lnkd.in/gymQ4wPN](https://lnkd.in/gymQ4wPN?trk=public_post-text) üîó DeepSeek: [https://lnkd.in/gjsJ\\_KqZ](https://lnkd.in/gjsJ_KqZ?trk=public_post-text) üîó Qwen 3: [https://lnkd.in/dnXqYJum](https://lnkd.in/dnXqYJum?trk=public_post-text) üîó GPT-OSS (WIP): [https://lnkd.in/gbmzunGb](https://lnkd.in/gbmzunGb?trk=public_post-text) Each repo includes full training code, tokenizer setup, config details, and the reasoning behind the architecture. If you find them useful, please don‚Äôt forget to ‚≠ê the repo! ‚öôÔ∏è Bonus: DevOps-Specific Qwen Model I trained and fine-tuned Qwen for DevOps use cases and built a lightweight SLM interface: üîó DevOps SLM Chat UI: [https://lnkd.in/gyt9GHFT](https://lnkd.in/gyt9GHFT?trk=public_post-text) üîóInference Endpoint: [https://lnkd.in/g3dsbu-i](https://lnkd.in/g3dsbu-i?trk=public_post-text) üîóGoogle Colab Notebook (Full Code + Explanation): [https://lnkd.in/gh6kfTGG](https://lnkd.in/gh6kfTGG?trk=public_post-text) This is just the beginning, I‚Äôm committed to making small, focused LLMs that solve real problems.If you're curious, passionate, or just exploring, I‚Äôd love for you to check it out, contribute, or share feedback. Let‚Äôs build together. If you‚Äôre working on: ‚úÖ Small language models for DevOps ‚úÖ AI agents that support DevOps engineers Then this is for you. üëâ Let‚Äôs connect on LinkedIn and build the future of DevOps + AI together. üí° Also, join the AI Hackathon and help shape the future of DevOps + AI! If you haven‚Äôt registered yet, here‚Äôs the announcement: Hackathon Details: [https://lnkd.in/gA6thmjc](https://lnkd.in/gA6thmjc?trk=public_post-text) [#TinyLLMs](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Ftinyllms&trk=public_post-text) [#DevOps](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fdevops&trk=public_post-text) [#SLM](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fslm&trk=public_post-text) [#BuildInPublic](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fbuildinpublic&trk=public_post-text) [#Qwen3](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fqwen3&trk=public_post-text) [#GPT2](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fgpt2&trk=public_post-text) [#DeepSeek](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fdeepseek&trk=public_post-text) [#GPTOSS](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fgptoss&trk=public_post-text) [#OpenSourceLLMs](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fopensourcellms&trk=public_post-text) [#IdeaWeaver](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fideaweaver&trk=public_post-text) [#GenerativeAI](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fgenerativeai&trk=public_post-text) [#LLMFromScratch](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fllmfromscratch&trk=public_post-text) [#MLOps](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fmlops&trk=public_post-text) [#HuggingFace](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fhuggingface&trk=public_post-text) [#AIForDevOps](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Faifordevops&trk=public_post-text)\n\n\n\n  [121](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fprashant-lakhera-696119b_tinyllms-devops-slm-activity-7376465438618292224-x48Q&trk=public_post_social-actions-reactions)   [3 Comments](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fprashant-lakhera-696119b_tinyllms-devops-slm-activity-7376465438618292224-x48Q&trk=public_post_social-actions-comments)\n\n  [Like](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fprashant-lakhera-696119b_tinyllms-devops-slm-activity-7376465438618292224-x48Q&trk=public_post_like-cta)   [Comment](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fprashant-lakhera-696119b_tinyllms-devops-slm-activity-7376465438618292224-x48Q&trk=public_post_comment-cta)\n\n  To view or add a comment, [sign in](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fprashant-lakhera-696119b_tinyllms-devops-slm-activity-7376465438618292224-x48Q&trk=public_post_feed-cta-banner-cta)\n\n17,233 followers\n\n* [357 Posts](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww%2Elinkedin%2Ecom%2Fin%2Fsanjay-jha-2a425719%2Frecent-activity%2F&trk=public_post_follow-posts)\n* [1 Article](https://www.linkedin.com/today/author/sanjay-jha-2a425719?trk=public_post_follow-articles)\n\n[View Profile](https://in.linkedin.com/in/sanjay-jha-2a425719?trk=public_post_follow-view-profile)   [Connect](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww%2Elinkedin%2Ecom%2Ffeed%2Fupdate%2Furn%3Ali%3Aactivity%3A7382114449446404096&trk=public_post_follow)\n\n## More from this author\n\n* [### Agent AI: Moving Beyond Chatbots to Autonomous Intelligence\n\n  Sanjay Jha   1mo](https://www.linkedin.com/pulse/agent-ai-moving-beyond-chatbots-autonomous-intelligence-sanjay-jha-zqmrc?trk=public_post)\n\n## Explore content categories\n\n* [Career](https://www.linkedin.com/top-content/career/)\n* [Productivity](https://www.linkedin.com/top-content/productivity/)\n* [Finance](https://www.linkedin.com/top-content/finance/)\n* [Soft Skills & Emotional Intelligence](https://www.linkedin.com/top-content/soft-skills-emotional-intelligence/)\n* [Project Management](https://www.linkedin.com/top-content/project-management/)\n* [Education](https://www.linkedin.com/top-content/education/)\n* [Technology](https://www.linkedin.com/top-content/technology/)\n* [Leadership](https://www.linkedin.com/top-content/leadership/)\n* [Ecommerce](https://www.linkedin.com/top-content/ecommerce/)\n* [User Experience](https://www.linkedin.com/top-content/user-experience/)\n\n## Sign in to view more content\n\nCreate your free account or sign in to continue your search\n\n## Welcome back\n\nBy clicking Continue to join or sign in, you agree to LinkedIn‚Äôs [User Agreement](/legal/user-agreement?trk=public_post_contextual-sign-in-modal_sign-in-modal_auth-button_user-agreement), [Privacy Policy](/legal/privacy-policy?trk=public_post_contextual-sign-in-modal_sign-in-modal_auth-button_privacy-policy), and [Cookie Policy](/legal/cookie-policy?trk=public_post_contextual-sign-in-modal_sign-in-modal_auth-button_cookie-policy).\n\nNew to LinkedIn? [Join now](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww%2Elinkedin%2Ecom%2Fposts%2Fsanjay-jha-2a425719_fastapi-machinelearning-ai-activity-7382114449446404096-DUPA&trk=public_post_contextual-sign-in-modal_sign-in-modal_join-link)\n\nor\n\nBy clicking Continue to join or sign in, you agree to LinkedIn‚Äôs [User Agreement](/legal/user-agreement?trk=public_post_auth-button_user-agreement), [Privacy Policy](/legal/privacy-policy?trk=public_post_auth-button_privacy-policy), and [Cookie Policy](/legal/cookie-policy?trk=public_post_auth-button_cookie-policy).\n\nNew to LinkedIn? [Join now](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww%2Elinkedin%2Ecom%2Fposts%2Fsanjay-jha-2a425719_fastapi-machinelearning-ai-activity-7382114449446404096-DUPA&trk=public_post_contextual-sign-in-modal_join-link)\n\nNever miss a beat on the app\n\nDon‚Äôt have the app? Get it in the Microsoft Store.\n\n [Open the app](ms-windows-store://pdp/?ProductId=9WZDNCRFJ4Q7&mode=mini&cid=guest_desktop_upsell_post2)\n\n "
    },
    {
      "url": "https://www.linkedin.com/posts/nasdag_scaling-large-scale-model-training-on-cpus-activity-7335095630316400640--VJF",
      "title": "Scaling Deep Learning on a Laptop with Ray and Databricks",
      "content": "batches. Standard autoscaling reacts too slowly and lacks awareness of queued requests. 3. Complex Lifecycle Management: Distributed training jobs require coordinated startup/shutdown. Model deployments need graceful draining and version transitions. These patterns exceed Deployments and StatefulSets capabilities. Case Study: ScaleML's Multi-Tenant AI Platform Background: ScaleML operated a Kubernetes-based AIaaS platform serving hundreds of data science teams. They hosted everything from real-time inference APIs to large-scale distributed training jobs. The Problem: Their platform was plagued by three issues: 1. GPU Fragmentation: The cluster had mixed GPU types, causing scheduling failures despite available resources. 2. Training Job Starvation: Long-running training jobs would [...] it on a specialized ML platform, such as Hugging Face, Paperspace, or other similar platforms. These platforms handle the provisioning of specialized hardware (GPUs) and often include optimized LLM serving frameworks. üí° Still simple and fast deployment with minimum configuration, but with dedicated GPU performance for specialized inference. Option 3: Enterprise grade models If you need to manage the full machine learning lifecycle (MLOps), including model monitoring, A/B testing, and high-volume scaling, the choice is to look at Vertex AI (Google) or SageMaker (AWS). Also consider Bedrock (AWS) or Azure OpenAI Service, which are 'Foundation Model as a Service' options. These simplify deployment by offering API access to pre-trained models, and could even be moved closer to Option 2 in",
      "score": 0.50388235,
      "raw_content": "# Scaling Deep Learning on a Laptop with Ray and Databricks\n\nThis title was summarized by AI from the post below.\n\n[Philippe DAGHER](https://uk.linkedin.com/in/nasdag?trk=public_post_feed-actor-name)\n\n* [Report this post](/uas/login?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fnasdag_scaling-large-scale-model-training-on-cpus-activity-7335095630316400640--VJF&trk=public_post_ellipsis-menu-semaphore-sign-in-redirect&guestReportContentType=POST&_f=guest-reporting)\n\nüöÄ Scaling Deep Learning Without GPUs ‚Äì and Without Losing Your Mind Ever tried training a large model on 100M+ rows without access to GPUs, a DevOps team, or the luxury of moving data out of a secure cloud lake? I recently faced that exact challenge ‚Äì as a solo ML engineer, I needed a way to: ‚úÖ Train at scale ‚úÖ Keep the data governed and in-place ‚úÖ Stay productive from my local notebook ‚úÖ Avoid becoming a distributed systems engineer overnight üí° Enter the Clean Pattern: using Ray + Databricks Connect to trigger distributed, CPU-only model training directly where the data lives ‚Äì without maintaining a driver connection. üîó In this blogpost, I share the architecture, patterns, trade-offs (Ray vs PyTorch DDP vs Vertex AI), and how I turned my laptop into a launchpad for cluster-scale training jobs. If you're a solo full-stack data scientist or a lean ML team looking to scale responsibly, this one‚Äôs for you. üëâ Read the full story: [https://lnkd.in/eXUPqtPN](https://www.linkedin.com/redir/redirect?url=https%3A%2F%2Flnkd%2Ein%2FeXUPqtPN&urlhash=iO-V&trk=public_post-text) üñºÔ∏è Bonus: includes a visual summary + benchmarks + practical lessons from the field.\n\n[Scaling Large-Scale Model Training on CPUs with Ray + Databricks: The Clean Pattern   medium.com](https://www.linkedin.com/redir/redirect?url=https%3A%2F%2Fmedium%2Ecom%2F%40nasdag%2Fscaling-large-scale-model-training-on-cpus-with-ray-databricks-the-clean-pattern-577871a1a0d3&urlhash=1klt&trk=public_post_feed-article-content)\n\n[Like](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww%2Elinkedin%2Ecom%2Fposts%2Fnasdag_scaling-large-scale-model-training-on-cpus-activity-7335095630316400640--VJF&trk=public_post_like-cta)   [Comment](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww%2Elinkedin%2Ecom%2Fposts%2Fnasdag_scaling-large-scale-model-training-on-cpus-activity-7335095630316400640--VJF&trk=public_post_comment-cta)\n\nTo view or add a comment, [sign in](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww%2Elinkedin%2Ecom%2Fposts%2Fnasdag_scaling-large-scale-model-training-on-cpus-activity-7335095630316400640--VJF&trk=public_post_feed-cta-banner-cta)\n\n## More Relevant Posts\n\n* [Haris Berkovac, PhD](https://ba.linkedin.com/in/haris-berkovac?trk=public_post_feed-actor-name)\n\n  + [Report this post](/uas/login?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fharis-berkovac_aiaas-on-kubernetes-custom-schedulers-operators-activity-7381346916237803522-D-Zy&trk=public_post_ellipsis-menu-semaphore-sign-in-redirect&guestReportContentType=POST&_f=guest-reporting)\n\n  AIaaS on Kubernetes: Custom Schedulers, Operators, and Autoscalers for Bursty, Heterogeneous AI Workloads Introduction: The Kubernetes Conundrum for AI Workloads Kubernetes has emerged as the dominant orchestration platform for modern applications, and AI-as-a-Service (AIaaS) is no exception. However, the inherent characteristics of AI workloads-extreme burstiness, heterogeneous resource requirements (CPUs, GPUs, specialized accelerators), and diverse lifecycles (from milliseconds-long inference to days-long training)-push vanilla Kubernetes to its limits. The default scheduler, designed for relatively predictable web services, struggles with the dynamic nature of AI. Advanced Kubernetes orchestration for AIaaS requires custom schedulers, specialized operators, and intelligent autoscaling that understand the unique semantics of AI workloads, transforming Kubernetes from a generic platform into an AI-native operating system. The Special Demands of AI on K8s AI workloads on Kubernetes present three fundamental challenges that standard components cannot adequately address: 1. Resource Heterogeneity: Not all GPUs are equal. Workloads may require specific GPU types (A100 vs H100), memory configurations, or even multiple GPUs with fast interconnoutes (NVLink). The default scheduler treats GPUs as a generic resource. 2. Burstiness and Queue-Awareness: Inference traffic can spike by orders of magnitude in seconds. Training jobs may be submitted in batches. Standard autoscaling reacts too slowly and lacks awareness of queued requests. 3. Complex Lifecycle Management: Distributed training jobs require coordinated startup/shutdown. Model deployments need graceful draining and version transitions. These patterns exceed Deployments and StatefulSets capabilities. Case Study: ScaleML's Multi-Tenant AI Platform Background: ScaleML operated a Kubernetes-based AIaaS platform serving hundreds of data science teams. They hosted everything from real-time inference APIs to large-scale distributed training jobs. The Problem: Their platform was plagued by three issues: 1. GPU Fragmentation: The cluster had mixed GPU types, causing scheduling failures despite available resources. 2. Training Job Starvation: Long-running training jobs would monopolize high-end GPUs, while inference services suffered from resource scarcity during peaks. 3. Slow Scaling: The Horizontal Pod Autoscaler (HPA) would take 3-5 minutes to respond to inference spikes, causing request queuing and timeouts. The Solution - AI-Native Kubernetes Stack: ScaleML implemented a comprehensive AI-aware orchestration layer: Article will continue in comments\n\n  [5 Comments](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fharis-berkovac_aiaas-on-kubernetes-custom-schedulers-operators-activity-7381346916237803522-D-Zy&trk=public_post_social-actions-comments)\n\n  [Like](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fharis-berkovac_aiaas-on-kubernetes-custom-schedulers-operators-activity-7381346916237803522-D-Zy&trk=public_post_like-cta)   [Comment](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fharis-berkovac_aiaas-on-kubernetes-custom-schedulers-operators-activity-7381346916237803522-D-Zy&trk=public_post_comment-cta)\n\n  To view or add a comment, [sign in](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fharis-berkovac_aiaas-on-kubernetes-custom-schedulers-operators-activity-7381346916237803522-D-Zy&trk=public_post_feed-cta-banner-cta)\n* [Arpit Nigam](https://in.linkedin.com/in/arpit-nigam-689651113?trk=public_post_feed-actor-name)\n\n  + [Report this post](/uas/login?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Farpit-nigam-689651113_aws-inferentia-trainium-activity-7385879557142339585-gLd-&trk=public_post_ellipsis-menu-semaphore-sign-in-redirect&guestReportContentType=POST&_f=guest-reporting)\n\n  Lately, I‚Äôve been exploring how to make large-scale inference truly scalable without burning through GPU costs. That‚Äôs where AWS‚Äôs Inferentia and Trainium chips come into play. While GPUs have been the default for both training and inference, they‚Äôre not always cost-efficient once models move to production. AWS built these two accelerators with very specific goals: ‚Ä¢ Trainium ‚Üí for training large models efficiently. ‚Ä¢ Inferentia ‚Üí for running inference at scale with low latency and cost. Both run on the same Neuron SDK, so the workflow remains unified ‚Äî you train on Trainium, compile with Neuron, and deploy on Inferentia. It‚Äôs a smooth transition from experimentation to production. The results are quite impressive ‚Äî ‚Ä¢ Up to ~70% reduction in inference cost compared to GPUs. ‚Ä¢ Seamless scaling using EKS or SageMaker. ‚Ä¢ Native support for PyTorch, TensorFlow, and Hugging Face models. As AI workloads continue to grow, optimizing for inference isn‚Äôt just about performance anymore ‚Äî it‚Äôs about architecture, efficiency, and sustainability. I‚Äôm currently testing Inferentia with EKS autoscaling and Neuron SDK performance tuning to see how it performs under real workloads. If you‚Äôve tried similar setups, I‚Äôd love to exchange notes and learn from your experience. [#AWS](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Faws&trk=public_post-text) [#Inferentia](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Finferentia&trk=public_post-text) [#Trainium](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Ftrainium&trk=public_post-text) [#MLOps](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fmlops&trk=public_post-text) [#DevOps](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fdevops&trk=public_post-text) [#CloudArchitecture](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fcloudarchitecture&trk=public_post-text) [#NeuronSDK](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fneuronsdk&trk=public_post-text) [#EKS](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Feks&trk=public_post-text) [#SageMaker](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fsagemaker&trk=public_post-text) [#AIInfrastructure](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Faiinfrastructure&trk=public_post-text)\n\n  [4](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Farpit-nigam-689651113_aws-inferentia-trainium-activity-7385879557142339585-gLd-&trk=public_post_social-actions-reactions)\n\n  [Like](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Farpit-nigam-689651113_aws-inferentia-trainium-activity-7385879557142339585-gLd-&trk=public_post_like-cta)   [Comment](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Farpit-nigam-689651113_aws-inferentia-trainium-activity-7385879557142339585-gLd-&trk=public_post_comment-cta)\n\n  To view or add a comment, [sign in](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Farpit-nigam-689651113_aws-inferentia-trainium-activity-7385879557142339585-gLd-&trk=public_post_feed-cta-banner-cta)\n* [Felipe Lopez](https://www.linkedin.com/in/felipelopez?trk=public_post_feed-actor-name)\n\n  + [Report this post](/uas/login?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Ffelipelopez_configure-and-verify-a-distributed-training-activity-7384340618795237376-ZvTU&trk=public_post_ellipsis-menu-semaphore-sign-in-redirect&guestReportContentType=POST&_f=guest-reporting)\n\n  üöÄ New ML blog post by [Meryem Ozcelik](https://www.linkedin.com/in/meryemozcelik/en?trk=public_post-text), [Pratik Yeole](https://www.linkedin.com/in/pratikyeole?trk=public_post-text), [Sirut Buasai](https://www.linkedin.com/in/sirut-buasai?trk=public_post-text), and Jinyan Li! Setting up and verifying distributed GPU clusters is one of the biggest pain points for ML teams, from driver configs to EFA, NCCL, and networking. This new AWS blog explains how to configure and validate a distributed training cluster using AWS Deep Learning Containers on Amazon EKS, step by step. üí° You‚Äôll learn how to: ‚úÖ Launch GPU-ready EKS clusters with AWS Deep Learning Containers ‚úÖ Install essential plugins such as NVIDIA, EFA, storage, and training operators ‚úÖ Run validation checks to ensure your setup is production ready Whether you are running large language models or computer vision workloads, this guide helps you build reliable, scalable, and high-performance training environments with confidence. üîó Read the post: [https://lnkd.in/geCppQWK](https://www.linkedin.com/redir/redirect?url=https%3A%2F%2Flnkd%2Ein%2FgeCppQWK&urlhash=BqOG&trk=public_post-text) [#aws](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Faws&trk=public_post-text) [#ml](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fml&trk=public_post-text) [#eks](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Feks&trk=public_post-text)\n\n  [Configure and verify a distributed training cluster with AWS Deep Learning Containers on Amazon EKS | Amazon Web Services   aws.amazon.com](https://www.linkedin.com/redir/redirect?url=https%3A%2F%2Faws%2Eamazon%2Ecom%2Fblogs%2Fmachine-learning%2Fconfigure-and-verify-a-distributed-training-cluster-with-aws-deep-learning-containers-on-amazon-eks%2F&urlhash=9rlB&trk=public_post_feed-article-content)\n\n  [41](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Ffelipelopez_configure-and-verify-a-distributed-training-activity-7384340618795237376-ZvTU&trk=public_post_social-actions-reactions)\n\n  [Like](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Ffelipelopez_configure-and-verify-a-distributed-training-activity-7384340618795237376-ZvTU&trk=public_post_like-cta)   [Comment](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Ffelipelopez_configure-and-verify-a-distributed-training-activity-7384340618795237376-ZvTU&trk=public_post_comment-cta)\n\n  To view or add a comment, [sign in](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Ffelipelopez_configure-and-verify-a-distributed-training-activity-7384340618795237376-ZvTU&trk=public_post_feed-cta-banner-cta)\n* [Dhanushkumar R](https://in.linkedin.com/in/dhanushkumar-r-datascience?trk=public_post_feed-actor-name)\n\n  + [Report this post](/uas/login?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fdhanushkumar-r-datascience_tinker-api-overview-activity-7386765477244706816-gsEd&trk=public_post_ellipsis-menu-semaphore-sign-in-redirect&guestReportContentType=POST&_f=guest-reporting)\n\n  Tinker¬†is a managed training service by [Thinking Machines Lab](https://www.linkedin.com/company/thinkingmachinesai?trk=public_post-text) that lets researchers fine-tune large language models via simple API [calls.You](https://www.linkedin.com/redir/redirect?url=http%3A%2F%2Fcalls%2EYou&urlhash=Zf22&trk=public_post-text) write a Python loop on your CPU (defining data, environment, and loss), then use Tinker‚Äôs functions to distribute the exact same computations on GPUs in the cloud.Unlike black-box services, Tinker exposes low-level primitives (e.g.¬†forward\\_backward,¬†optim\\_step,¬†sample) so you retain full control over the training algorithm.Under the hood, Tinker handles multi-node scheduling, GPU resource allocation, and fault tolerance, enabling you to run small or large training jobs without managing infrastructure.Crucially, Tinker¬†uses LoRA fine-tuning¬†(low-rank adapters) instead of full-weight updates, which allows many training runs to share the same GPU memory pool and greatly reduces cost.\n\n  [Tinker API Overview   medium.com](https://www.linkedin.com/redir/redirect?url=https%3A%2F%2Fmedium%2Ecom%2F%40danushidk507%2Ftinker-api-overview-ceed8208383e&urlhash=NCWO&trk=public_post_feed-article-content)\n\n  [23](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fdhanushkumar-r-datascience_tinker-api-overview-activity-7386765477244706816-gsEd&trk=public_post_social-actions-reactions)\n\n  [Like](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fdhanushkumar-r-datascience_tinker-api-overview-activity-7386765477244706816-gsEd&trk=public_post_like-cta)   [Comment](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fdhanushkumar-r-datascience_tinker-api-overview-activity-7386765477244706816-gsEd&trk=public_post_comment-cta)\n\n  To view or add a comment, [sign in](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fdhanushkumar-r-datascience_tinker-api-overview-activity-7386765477244706816-gsEd&trk=public_post_feed-cta-banner-cta)\n* [Enigma Security](https://cl.linkedin.com/company/enigma-security?trk=public_post_feed-actor-name)\n\n  636 followers\n\n  + [Report this post](/uas/login?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fenigma-security_kubernetes-machinelearning-cloudcomputing-activity-7385284408297308160-g5iS&trk=public_post_ellipsis-menu-semaphore-sign-in-redirect&guestReportContentType=POST&_f=guest-reporting)\n\n  üöÄ Discovering the Power of Kubernetes in the Cloud for Machine Learning In the current world of AI and data processing, implementing scalable clusters is key to success. Recently, I explored a detailed guide on how to build a Kubernetes cluster optimized for machine learning tasks in cloud environments. This approach not only accelerates development but also ensures efficiency and scalability in intensive operations. üîß Essential Steps for Initial Configuration - Prepare the base infrastructure in a reliable cloud provider, selecting nodes with GPUs to accelerate model training. - Install Kubernetes using tools like kubeadm or Helm, configuring the master and worker clusters for high availability. - Integrate persistent storage with CSI volumes to handle large datasets without interruptions. üìä Optimizing the Environment for ML - Deploy pods with frameworks like TensorFlow or PyTorch, using Kubernetes operators to automate horizontal scaling. - Monitor resources with Prometheus and Grafana, adjusting CPU and memory limits to avoid bottlenecks in distributed training. - Implement security with RBAC and Network Policies, protecting the flow of sensitive data in the cluster. ‚ö° Benefits and Best Practices This setup allows processing massive volumes of data efficiently, reducing compute times by 40-50% compared to on-premise solutions. I recommend testing in staging environments before production to validate performance. For more information visit: [https://enigmasecurity.cl](https://www.linkedin.com/redir/redirect?url=https%3A%2F%2Fenigmasecurity%2Ecl&urlhash=b8IS&trk=public_post-text) [#Kubernetes](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fkubernetes&trk=public_post-text) [#MachineLearning](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fmachinelearning&trk=public_post-text) [#CloudComputing](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fcloudcomputing&trk=public_post-text) [#DevOps](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fdevops&trk=public_post-text) [#AI](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fai&trk=public_post-text) If you're passionate about cybersecurity and tech, consider donating to the Enigma Security community for more news: [https://lnkd.in/evtXjJTA](https://www.linkedin.com/redir/redirect?url=https%3A%2F%2Flnkd%2Ein%2FevtXjJTA&urlhash=bzt-&trk=public_post-text) Connect with me on LinkedIn to discuss more about these topics: [https://lnkd.in/eqqNANrk](https://www.linkedin.com/redir/redirect?url=https%3A%2F%2Flnkd%2Ein%2FeqqNANrk&urlhash=aZPK&trk=public_post-text) üìÖ Sat, 18 Oct 2025 12:00:29 GMT üîóSubscribe to the Membership: [https://lnkd.in/eh\\_rNRyt](https://www.linkedin.com/redir/redirect?url=https%3A%2F%2Flnkd%2Ein%2Feh_rNRyt&urlhash=dYl4&trk=public_post-text)\n\n\n\n  [2](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fenigma-security_kubernetes-machinelearning-cloudcomputing-activity-7385284408297308160-g5iS&trk=public_post_social-actions-reactions)   [1 Comment](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fenigma-security_kubernetes-machinelearning-cloudcomputing-activity-7385284408297308160-g5iS&trk=public_post_social-actions-comments)\n\n  [Like](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fenigma-security_kubernetes-machinelearning-cloudcomputing-activity-7385284408297308160-g5iS&trk=public_post_like-cta)   [Comment](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fenigma-security_kubernetes-machinelearning-cloudcomputing-activity-7385284408297308160-g5iS&trk=public_post_comment-cta)\n\n  To view or add a comment, [sign in](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fenigma-security_kubernetes-machinelearning-cloudcomputing-activity-7385284408297308160-g5iS&trk=public_post_feed-cta-banner-cta)\n* [Luis Oria Seidel](https://cl.linkedin.com/in/luis-oria-seidel-%F0%9F%87%BB%F0%9F%87%AA-301a758a/en?trk=public_post_feed-actor-name)\n\n  | IT Manager & Cybersecurity Architect | Automation with N8N and Make | Artificial Intelligence | Fortinet¬Æ NSE 3 & FCAC¬Æ | ISO/IEC 27001 ‚Ñ¢ | CAPC‚Ñ¢ | Cloud | CSFPC‚Ñ¢ | SODFC‚Ñ¢ | FBE‚Ñ¢ | RWVCPC‚Ñ¢ | NIST | ITIL | FCP | CobiT |\n\n  + [Report this post](/uas/login?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fluis-oria-seidel-%25F0%259F%2587%25BB%25F0%259F%2587%25AA-301a758a_kubernetes-machinelearning-cloudcomputing-activity-7385284400055209985-9cB9&trk=public_post_ellipsis-menu-semaphore-sign-in-redirect&guestReportContentType=POST&_f=guest-reporting)\n\n  üöÄ Discovering the Power of Kubernetes in the Cloud for Machine Learning In the current world of AI and data processing, implementing scalable clusters is key to success. Recently, I explored a detailed guide on how to build a Kubernetes cluster optimized for machine learning tasks in cloud environments. This approach not only accelerates development but also ensures efficiency and scalability in intensive operations. üîß Essential Steps for Initial Configuration - Prepare the base infrastructure in a reliable cloud provider, selecting nodes with GPUs to accelerate model training. - Install Kubernetes using tools like kubeadm or Helm, configuring the master and worker clusters for high availability. - Integrate persistent storage with CSI volumes to handle large datasets without interruptions. üìä Optimizing the Environment for ML - Deploy pods with frameworks like TensorFlow or PyTorch, using Kubernetes operators to automate horizontal scaling. - Monitor resources with Prometheus and Grafana, adjusting CPU and memory limits to avoid bottlenecks in distributed training. - Implement security with RBAC and Network Policies, protecting the flow of sensitive data in the cluster. ‚ö° Benefits and Best Practices This setup allows processing massive volumes of data efficiently, reducing compute times by 40-50% compared to on-premise solutions. I recommend testing in staging environments before production to validate performance. For more information visit: [https://enigmasecurity.cl](https://www.linkedin.com/redir/redirect?url=https%3A%2F%2Fenigmasecurity%2Ecl&urlhash=b8IS&trk=public_post-text) [#Kubernetes](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fkubernetes&trk=public_post-text) [#MachineLearning](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fmachinelearning&trk=public_post-text) [#CloudComputing](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fcloudcomputing&trk=public_post-text) [#DevOps](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fdevops&trk=public_post-text) [#AI](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fai&trk=public_post-text) If you're passionate about cybersecurity and tech, consider donating to the Enigma Security community for more news: [https://lnkd.in/er\\_qUAQh](https://www.linkedin.com/redir/redirect?url=https%3A%2F%2Flnkd%2Ein%2Fer_qUAQh&urlhash=fRvR&trk=public_post-text) Connect with me on LinkedIn to discuss more about these topics: [https://lnkd.in/eMjz8bpJ](https://www.linkedin.com/redir/redirect?url=https%3A%2F%2Flnkd%2Ein%2FeMjz8bpJ&urlhash=7sKa&trk=public_post-text) üìÖ Sat, 18 Oct 2025 12:00:29 GMT üîóSubscribe to the Membership: [https://lnkd.in/eh\\_rNRyt](https://www.linkedin.com/redir/redirect?url=https%3A%2F%2Flnkd%2Ein%2Feh_rNRyt&urlhash=dYl4&trk=public_post-text)\n\n\n\n  [3](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fluis-oria-seidel-%25F0%259F%2587%25BB%25F0%259F%2587%25AA-301a758a_kubernetes-machinelearning-cloudcomputing-activity-7385284400055209985-9cB9&trk=public_post_social-actions-reactions)   [1 Comment](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fluis-oria-seidel-%25F0%259F%2587%25BB%25F0%259F%2587%25AA-301a758a_kubernetes-machinelearning-cloudcomputing-activity-7385284400055209985-9cB9&trk=public_post_social-actions-comments)\n\n  [Like](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fluis-oria-seidel-%25F0%259F%2587%25BB%25F0%259F%2587%25AA-301a758a_kubernetes-machinelearning-cloudcomputing-activity-7385284400055209985-9cB9&trk=public_post_like-cta)   [Comment](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fluis-oria-seidel-%25F0%259F%2587%25BB%25F0%259F%2587%25AA-301a758a_kubernetes-machinelearning-cloudcomputing-activity-7385284400055209985-9cB9&trk=public_post_comment-cta)\n\n  To view or add a comment, [sign in](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fluis-oria-seidel-%25F0%259F%2587%25BB%25F0%259F%2587%25AA-301a758a_kubernetes-machinelearning-cloudcomputing-activity-7385284400055209985-9cB9&trk=public_post_feed-cta-banner-cta)\n* [Neural Nugget](https://www.linkedin.com/company/neural-nugget?trk=public_post_feed-actor-name)\n\n  10 followers\n\n  + [Report this post](/uas/login?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fneural-nugget_former-openai-chief-technology-officer-mira-activity-7380524596036386816-WLF8&trk=public_post_ellipsis-menu-semaphore-sign-in-redirect&guestReportContentType=POST&_f=guest-reporting)\n\n  Former OpenAI chief technology officer Mira Murati's new startup just launched Tinker, a tool that lets developers fine-tune massive AI models from their laptop. Write Python training loops on your computer whilst the heavy computing runs on distributed graphics processing units in the cloud. \\*\\*So what?\\*\\* Custom AI models become accessible without needing a supercomputer budget. Try Tinker ‚Üí [thinkingmachines.ai](https://www.linkedin.com/redir/redirect?url=http%3A%2F%2Fthinkingmachines%2Eai&urlhash=pnDJ&trk=public_post-text)\n\n  [2](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fneural-nugget_former-openai-chief-technology-officer-mira-activity-7380524596036386816-WLF8&trk=public_post_social-actions-reactions)\n\n  [Like](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fneural-nugget_former-openai-chief-technology-officer-mira-activity-7380524596036386816-WLF8&trk=public_post_like-cta)   [Comment](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fneural-nugget_former-openai-chief-technology-officer-mira-activity-7380524596036386816-WLF8&trk=public_post_comment-cta)\n\n  To view or add a comment, [sign in](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fneural-nugget_former-openai-chief-technology-officer-mira-activity-7380524596036386816-WLF8&trk=public_post_feed-cta-banner-cta)\n* [Alex Tumanov](https://www.linkedin.com/in/oleksii-tumanov?trk=public_post_feed-actor-name)\n\n  + [Report this post](/uas/login?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Foleksii-tumanov_llm-ai-deployment-activity-7382369392879370240-VxJS&trk=public_post_ellipsis-menu-semaphore-sign-in-redirect&guestReportContentType=POST&_f=guest-reporting)\n\n  LLM Deployment: Part 3. You‚Äôve built your custom model‚Äînow, how do you go live? The choice depends on your model's size and resource needs: Option 1: Small, CPU friendly models If your model is small, highly optimized, and friendly to a CPU, deploy it as a separate Docker service. For example, on platforms like Railway or a serverless container environment like Cloud Run/AWS Fargate. üí° Simple, fast deployment. Your main API communicates with the model over internal networking. Great for an MVP or a presentation. This is ideal for high-throughput, low-latency applications where cost efficiency is key. Option 2: Larger, GPU required models If your model is large (like Llama, Mistral, etc.) and demands dedicated GPUs, deploy it on a specialized ML platform, such as Hugging Face, Paperspace, or other similar platforms. These platforms handle the provisioning of specialized hardware (GPUs) and often include optimized LLM serving frameworks. üí° Still simple and fast deployment with minimum configuration, but with dedicated GPU performance for specialized inference. Option 3: Enterprise grade models If you need to manage the full machine learning lifecycle (MLOps), including model monitoring, A/B testing, and high-volume scaling, the choice is to look at Vertex AI (Google) or SageMaker (AWS). Also consider Bedrock (AWS) or Azure OpenAI Service, which are 'Foundation Model as a Service' options. These simplify deployment by offering API access to pre-trained models, and could even be moved closer to Option 2 in terms of operational complexity. üí° Great for governance, customization, and a fully managed end-to-end MLOps process. There are plenty of other options on the market. Define your performance goals (latency and throughput) first to choose the right place for your app's brain. üß† [#LLM](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fllm&trk=public_post-text) [#AI](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fai&trk=public_post-text) [#Deployment](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fdeployment&trk=public_post-text) [#Railway](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Frailway&trk=public_post-text) [#HuggingFace](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fhuggingface&trk=public_post-text) [#Python](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fpython&trk=public_post-text) [#MLOps](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fmlops&trk=public_post-text)\n\n\n\n  [2](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Foleksii-tumanov_llm-ai-deployment-activity-7382369392879370240-VxJS&trk=public_post_social-actions-reactions)\n\n  [Like](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Foleksii-tumanov_llm-ai-deployment-activity-7382369392879370240-VxJS&trk=public_post_like-cta)   [Comment](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Foleksii-tumanov_llm-ai-deployment-activity-7382369392879370240-VxJS&trk=public_post_comment-cta)\n\n  To view or add a comment, [sign in](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Foleksii-tumanov_llm-ai-deployment-activity-7382369392879370240-VxJS&trk=public_post_feed-cta-banner-cta)\n* [Dileep Sathyan](https://ca.linkedin.com/in/dileep-sathyan?trk=public_post_feed-actor-name)\n\n  + [Report this post](/uas/login?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fdileep-sathyan_azureml-machinelearning-cloudcompute-activity-7381799303901769728-pTu2&trk=public_post_ellipsis-menu-semaphore-sign-in-redirect&guestReportContentType=POST&_f=guest-reporting)\n\n  Successfully moving a Machine Learning model from research to production hinges on selecting the optimal Azure Machine Learning Compute Target at every stage. Inefficient resource allocation is a major drain on MLOps budgets. Here is a clear strategy for professional compute selection: 1. Azure ML Compute Instance: Dedicated, stateful environment for tasks like notebook development, data exploration, and debugging. Treat the Compute Instance as a personal development machine; it provides consistency but must be stopped manually or via a schedule when not in use to control costs. 2. Azure ML Compute Cluster or Serverless Compute: Highly scalable, on-demand compute for scheduled, large-scale, and repetitive jobs. These clusters are designed to auto-scale to zero after a job completes. Always favor these for production workflows to ensure you only pay for the compute time used. The Golden Rule: Choose targets that stay running (Compute Instances) only for interactive, continuous work. For all scheduled or batch workloads, select scalable, on-demand clusters that automatically terminate. Budget efficiency starts here. [#AzureML](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fazureml&trk=public_post-text) [#MachineLearning](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fmachinelearning&trk=public_post-text) [#CloudCompute](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fcloudcompute&trk=public_post-text) [#DataScience](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fdatascience&trk=public_post-text) [#MLOps](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fmlops&trk=public_post-text) [#MLflow](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fmlflow&trk=public_post-text)\n\n\n\n  [9](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fdileep-sathyan_azureml-machinelearning-cloudcompute-activity-7381799303901769728-pTu2&trk=public_post_social-actions-reactions)\n\n  [Like](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fdileep-sathyan_azureml-machinelearning-cloudcompute-activity-7381799303901769728-pTu2&trk=public_post_like-cta)   [Comment](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fdileep-sathyan_azureml-machinelearning-cloudcompute-activity-7381799303901769728-pTu2&trk=public_post_comment-cta)\n\n  To view or add a comment, [sign in](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fdileep-sathyan_azureml-machinelearning-cloudcompute-activity-7381799303901769728-pTu2&trk=public_post_feed-cta-banner-cta)\n\n9,415 followers\n\n* [851 Posts](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww%2Elinkedin%2Ecom%2Fin%2Fnasdag%2Frecent-activity%2F&trk=public_post_follow-posts)\n* [6 Articles](https://www.linkedin.com/today/author/nasdag?trk=public_post_follow-articles)\n\n[View Profile](https://uk.linkedin.com/in/nasdag?trk=public_post_follow-view-profile)   [Connect](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww%2Elinkedin%2Ecom%2Ffeed%2Fupdate%2Furn%3Ali%3Aactivity%3A7335095630316400640&trk=public_post_follow)\n\n## More from this author\n\n* [### Riding the Vibecoding Wave: How I Shipped a 12-Million-Customer ML Engine (and Kept My Sanity)\n\n  Philippe DAGHER   4mo](https://www.linkedin.com/pulse/riding-vibecoding-wave-how-i-shipped-ml-engine-kept-my-dagher-ur0qe?trk=public_post)\n* [### Embodied Intelligence, Everyday Agents, and the Architecture of AI: What Day 3 of EmTechAI 2025 Revealed\n\n  Philippe DAGHER   6mo](https://www.linkedin.com/pulse/embodied-intelligence-everyday-agents-architecture-ai-philippe-dagher-mv5me?trk=public_post)\n* [### üß† Day 2 at EmTechAI 2025: From Foundation Models to Foundational Shifts\n\n  Philippe DAGHER   7mo](https://www.linkedin.com/pulse/day-2-emtechai-2025-from-foundation-models-shifts-philippe-dagher-vqdwc?trk=public_post)\n\n## Explore content categories\n\n* [Career](https://www.linkedin.com/top-content/career/)\n* [Productivity](https://www.linkedin.com/top-content/productivity/)\n* [Finance](https://www.linkedin.com/top-content/finance/)\n* [Soft Skills & Emotional Intelligence](https://www.linkedin.com/top-content/soft-skills-emotional-intelligence/)\n* [Project Management](https://www.linkedin.com/top-content/project-management/)\n* [Education](https://www.linkedin.com/top-content/education/)\n* [Technology](https://www.linkedin.com/top-content/technology/)\n* [Leadership](https://www.linkedin.com/top-content/leadership/)\n* [Ecommerce](https://www.linkedin.com/top-content/ecommerce/)\n* [User Experience](https://www.linkedin.com/top-content/user-experience/)\n\n## Sign in to view more content\n\nCreate your free account or sign in to continue your search\n\n## Welcome back\n\nBy clicking Continue to join or sign in, you agree to LinkedIn‚Äôs [User Agreement](/legal/user-agreement?trk=public_post_contextual-sign-in-modal_sign-in-modal_auth-button_user-agreement), [Privacy Policy](/legal/privacy-policy?trk=public_post_contextual-sign-in-modal_sign-in-modal_auth-button_privacy-policy), and [Cookie Policy](/legal/cookie-policy?trk=public_post_contextual-sign-in-modal_sign-in-modal_auth-button_cookie-policy).\n\nNew to LinkedIn? [Join now](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww%2Elinkedin%2Ecom%2Fposts%2Fnasdag_scaling-large-scale-model-training-on-cpus-activity-7335095630316400640--VJF&trk=public_post_contextual-sign-in-modal_sign-in-modal_join-link)\n\nor\n\nNew to LinkedIn? [Join now](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww%2Elinkedin%2Ecom%2Fposts%2Fnasdag_scaling-large-scale-model-training-on-cpus-activity-7335095630316400640--VJF&trk=public_post_contextual-sign-in-modal_join-link)\n\nBy clicking Continue to join or sign in, you agree to LinkedIn‚Äôs [User Agreement](/legal/user-agreement?trk=linkedin-tc_auth-button_user-agreement), [Privacy Policy](/legal/privacy-policy?trk=linkedin-tc_auth-button_privacy-policy), and [Cookie Policy](/legal/cookie-policy?trk=linkedin-tc_auth-button_cookie-policy).\n\nNever miss a beat on the app\n\nDon‚Äôt have the app? Get it in the Microsoft Store.\n\n [Open the app](ms-windows-store://pdp/?ProductId=9WZDNCRFJ4Q7&mode=mini&cid=guest_desktop_upsell_post2)\n\n "
    },
    {
      "url": "https://www.linkedin.com/pulse/llm-everywhere-my-journey-lmm-inference-service-part-fadi-zaboura-qj1uf",
      "title": "LLM Everywhere! My Journey into LMM and Inference as a ...",
      "content": "KServe is an open-source project that simplifies the deployment of machine learning models on Kubernetes. KServe is a standard, cloud agnostic Model Inference Platform for serving predictive and generative AI models on Kubernetes, built for highly scalable use cases, it Supports modern serverless inference workloads with request-based autoscaling including scale-to-zero on CPU and GPU.\n\nEnvoy is a high-performance, open-source edge, and service proxy designed for cloud-native applications. It provides robust load balancing, service discovery, and observability features.\n\nHere‚Äôs how we can leverage KServe and Envoy for dynamic provisioning in the inference world:\n\nAuto-Scaling with KServe: [...] Auto-Scaling with KServe:\n\n Setup: KServe allows you to deploy and manage ML models as Kubernetes services. You can define a deployment configuration that includes auto-scaling policies.\n Auto-Scaling: KServe supports horizontal pod autoscaling, which automatically adjusts the number of pod replicas based on CPU and memory usage or custom metrics like request latency.\n Inference Workloads: By setting up auto-scaling, you ensure that your inference service can handle varying loads efficiently, scaling up during peak times and scaling down when demand is low.\n\nLoad Balancing with Envoy [...] Combining KServe and Envoy\n\n Integration: By integrating KServe with Envoy, you can create a robust, scalable, and efficient inference service. KServe handles the deployment and scaling of ML models, while Envoy manages the traffic routing and load balancing.\n Benefits: This combination ensures that your inference service can dynamically adjust to varying loads, provide fast and reliable responses, and maintain high availability.\n\n### Networking and Security\n\nWhile my focus is on dynamic provisioning and scaling, networking and security are also critical components:",
      "score": 0.50241756,
      "raw_content": "## Sign in to view more content\n\nCreate your free account or sign in to continue your search\n\n## Welcome back\n\nBy clicking Continue to join or sign in, you agree to LinkedIn‚Äôs [User Agreement](/legal/user-agreement?trk=pulse-article_contextual-sign-in-modal_sign-in-modal_auth-button_user-agreement), [Privacy Policy](/legal/privacy-policy?trk=pulse-article_contextual-sign-in-modal_sign-in-modal_auth-button_privacy-policy), and [Cookie Policy](/legal/cookie-policy?trk=pulse-article_contextual-sign-in-modal_sign-in-modal_auth-button_cookie-policy).\n\nNew to LinkedIn? [Join now](https://www.linkedin.com/signup/cold-join?session_redirect=%2Fpulse%2Fllm-everywhere-my-journey-lmm-inference-service-part-fadi-zaboura-qj1uf&trk=pulse-article_contextual-sign-in-modal_sign-in-modal_join-link)\n\nor\n\nNew to LinkedIn? [Join now](https://www.linkedin.com/signup/cold-join?session_redirect=%2Fpulse%2Fllm-everywhere-my-journey-lmm-inference-service-part-fadi-zaboura-qj1uf&trk=pulse-article_contextual-sign-in-modal_join-link)\n\nBy clicking Continue to join or sign in, you agree to LinkedIn‚Äôs [User Agreement](/legal/user-agreement?trk=linkedin-tc_auth-button_user-agreement), [Privacy Policy](/legal/privacy-policy?trk=linkedin-tc_auth-button_privacy-policy), and [Cookie Policy](/legal/cookie-policy?trk=linkedin-tc_auth-button_cookie-policy).\n\nLinkedIn is better on the app\n\nDon‚Äôt have the app? Get it in the Microsoft Store.\n\n [Open the app](ms-windows-store://pdp/?ProductId=9WZDNCRFJ4Q7&mode=mini&cid=guest_desktop_upsell)\n\n\n\n\n8 min read\n\n# LLM Everywhere! My Journey into LMM and Inference as a Service - Part Œô\n\n* [Report this article](/uas/login?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fpulse%2Fllm-everywhere-my-journey-lmm-inference-service-part-fadi-zaboura-qj1uf&trk=article-ssr-frontend-pulse_ellipsis-menu-semaphore-sign-in-redirect&guestReportContentType=PONCHO_ARTICLE&_f=guest-reporting)\n\n[Fadi Zaboura](https://il.linkedin.com/in/fadi-zaboura-ba2a24115) \n\n### Fadi Zaboura\n\nPublished May 15, 2024\n\n[+ Follow](https://www.linkedin.com/signup/cold-join?session_redirect=%2Fpulse%2Fllm-everywhere-my-journey-lmm-inference-service-part-fadi-zaboura-qj1uf&trk=article-ssr-frontend-pulse_publisher-author-card)\n\nDo you also hear buzzwords like LLMs and inferences and feel left out of the conversation because you don't fully understand what they mean? I recently found myself in the same boat while being part of an exciting new project. Although I had a basic understanding of Large Language Models, the concept of Inference as a Service was completely new to me. Everyone‚Äôs been throwing around AI buzzwords and LLMs like wildfire, but what does it all mean?\n\n### What‚Äôs the Big Deal with LLMs?\n\nIn the world of AI, LLMs, or Large Language Models have gained a lot of attention for their ability to understand and generate human-like text. These models, such as GPT-3 developed by OpenAI, are trained on vast amounts of text data and can be used for various natural language processing tasks such as language translation, text summarization, and question answering. Inference as a Service refers to the ability to access and use these pre-trained models through an API, allowing developers to integrate the power of LLMs into their own applications without having to train and maintain the models themselves.\n\n### The Buzz About Inferences\n\nBut what about this \"Inference as a Service\" thing? In simple terms, inference is the process where these models generate responses or predictions based on the input they get. Imagine you ask an LLM to write a short story about a cat who becomes a superhero. The process of coming up with that story is called inference. ( speaking of cats, try out [https://http.cat/](https://www.linkedin.com/redir/redirect?url=https%3A%2F%2Fhttp%2Ecat%2F&urlhash=Lr0D&trk=article-ssr-frontend-pulse_little-text-block) üò∫ )\n\nUsing IaaS, developers can leverage the capabilities of LLMs to enhance the natural language processing capabilities of their own applications, leading to more human-like and contextually relevant interactions with users. This streamlined access to powerful language models has the potential to revolutionize the way we interact with AI systems, making them more versatile and adaptable to a wide range of tasks.\n\n### The Relationship Between LLM and Inference\n\nSo, how exactly are LLMs and inferences related? Think of an LLM as a super-intelligent brain. This brain has been trained on a vast amount of data and can understand and generate human-like text. Inference is the process where this brain gets to work. It takes your input (a question, a prompt, a command) and processes it to generate a meaningful response.\n\nHere's a simple analogy: if the LLM is a well-read author, inference is the act of writing a new piece based on what the author has learned. Every time you ask an LLM to do something (generate text, answer a question, translate language), you're triggering an inference.\n\n### Why Should We Care?\n\nHere‚Äôs where it gets exciting. Inference as a Service means providing this smart, predictive power as a service over the internet. Just like you use cloud services for storage or computing, you can now tap into AI models to generate text, answer questions, or even translate languages, all on demand.\n\n### Cool Real-Life Applications\n\n1. Fake News Detection: Imagine an app that can instantly analyze news articles or social media posts and determine their authenticity. An LLM can cross-reference facts, check for biases, and even highlight suspicious sources, helping users discern fake news from real news.\n2. Personalized Learning: In education, LLMs can be used to create personalized learning experiences. An AI tutor can generate custom exercises, provide instant feedback, and even adapt lessons based on a student‚Äôs progress. This makes learning more engaging and effective.\n\n### Evolution of LLMs: From Early Models to LLaMA2 and LLaMA3\n\nThe journey of Large Language Models (LLMs) has been marked by rapid advancements and significant milestones. Before diving into LLaMA2 and LLaMA3, let's take a brief look at the evolution of LLMs and how we got here.\n\n### Early LLMs\n\nThe first generation of LLMs, like GPT-2, were groundbreaking in their ability to generate coherent text based on large-scale data training. These models demonstrated the potential of using deep learning to understand and generate human language, but they had limitations in terms of accuracy, efficiency, and handling of complex queries.\n\n### Advancements with GPT-3\n\nGPT-3 represented a significant leap forward. With 175 billion parameters, it was able to understand and generate more nuanced and contextually relevant text. However, it still faced challenges like biases in responses and the need for fine-tuning for specific tasks. This laid the groundwork for further improvements and more specialized models.\n\n### Now, let‚Äôs talk about some specific models: LLaMA2 and LLaMA3. These are advanced versions of LLMs developed to be even more efficient and powerful.\n\n* LLaMA2: Known for its improved accuracy and efficiency, LLaMA2 can handle more complex queries and provide more relevant responses. It's like upgrading your AI assistant to a version that‚Äôs faster and smarter. This model benefits from enhanced training techniques and a larger dataset, making it more reliable for a wider range of applications.\n* LLaMA3: The latest in the series, LLaMA3 brings even more capabilities to the table, including better contextual understanding and reduced biases. It‚Äôs designed to be more aligned with human values and can adapt to a wider range of applications. This model incorporates advanced algorithms to minimize biases and improve the quality of interactions, ensuring responses are more aligned with user expectations.\n\nThese models show just how rapidly AI technology is evolving, making it even more accessible and useful for everyday tasks. With each iteration, LLMs become more capable of understanding and generating human-like text, providing more accurate and contextually appropriate responses.\n\n### Steps to Get an LLM Working\n\nIf you're curious about how to set up an LLM for your own projects, here are the steps to get it up and running:\n\n### 1. Model Selection and Preparation\n\n* Research and Selection: Begin by researching available LLMs to find the one that best suits your needs. Consider factors like model size, pre-training data, and performance benchmarks.\n* Preprocessing: Prepare your data for training or fine-tuning. This involves cleaning, tokenizing, and structuring the data in a format that the model can understand.\n\n### 2. Environment Setup\n\n* Infrastructure: Set up your computational environment. This includes provisioning cloud instances or setting up on-premise servers with sufficient CPU, GPU, and memory resources.\n* Dependencies: Install necessary software dependencies. This includes deep learning frameworks (like TensorFlow or PyTorch), model libraries, and any other required tools.\n\n### 3. Model Deployment\n\n* Loading the Model: Load the pre-trained model into your environment. This might involve downloading the model weights and configuration files.\n* Inference Pipeline: Develop an inference pipeline that prepares incoming data, runs it through the model, and processes the output.\n\n### 4. Creating an API\n\n* API Development: Create an API using frameworks like FastAPI to expose your model's inference capabilities. This allows users to send requests and receive responses over HTTP.\n* Endpoint Design: Design endpoints that accept input data, trigger the inference process, and return results.\n\n### 5. Deployment and Monitoring\n\n* Deployment: Deploy your API on a cloud platform like AWS, GCP, or Azure. Use orchestration platforms like Kubernetes to manage your deployment.\n* Monitoring and Logging: Implement monitoring and logging to track the performance of your inference service.\n\n### Getting Inference Working: focusing on dynamic provisioning, Let's make it technical!\n\n### Dynamic Provisioning with KServe and Envoy\n\nDynamic provisioning ensures that the system automatically adjusts resources based on demand. Two essential tools for this are KServe and Envoy.\n\n[KServe](https://www.linkedin.com/redir/redirect?url=https%3A%2F%2Fgithub%2Ecom%2Fkserve%2Fkserve&urlhash=c7WJ&trk=article-ssr-frontend-pulse_little-text-block) is an open-source project that simplifies the deployment of machine learning models on Kubernetes. KServe is a standard, cloud agnostic Model Inference Platform for serving predictive and generative AI models on Kubernetes, built for highly scalable use cases, it Supports modern serverless inference workloads with request-based autoscaling including scale-to-zero on CPU and GPU.\n\n[Envoy](https://www.linkedin.com/redir/redirect?url=https%3A%2F%2Fwww%2Eenvoyproxy%2Eio%2F&urlhash=cecN&trk=article-ssr-frontend-pulse_little-text-block) is a high-performance, open-source edge, and service proxy designed for cloud-native applications. It provides robust load balancing, service discovery, and observability features.\n\nHere‚Äôs how we can leverage KServe and Envoy for dynamic provisioning in the inference world:\n\nAuto-Scaling with KServe:\n\n* Setup: KServe allows you to deploy and manage ML models as Kubernetes services. You can define a deployment configuration that includes auto-scaling policies.\n* Auto-Scaling: KServe supports horizontal pod autoscaling, which automatically adjusts the number of pod replicas based on CPU and memory usage or custom metrics like request latency.\n* Inference Workloads: By setting up auto-scaling, you ensure that your inference service can handle varying loads efficiently, scaling up during peak times and scaling down when demand is low.\n\nLoad Balancing with Envoy\n\n* Setup: Envoy can be deployed as a sidecar proxy in your Kubernetes pods or as a standalone gateway. It handles incoming requests and distributes them across multiple instances of your inference service.\n* Service Discovery: Envoy integrates with Kubernetes service discovery mechanisms to automatically detect and route traffic to healthy instances.\n* Advanced Features: Envoy offers advanced load balancing algorithms, retries, timeouts, and circuit breaking to ensure the high availability and reliability of your inference service.\n\nCombining KServe and Envoy\n\n* Integration: By integrating KServe with Envoy, you can create a robust, scalable, and efficient inference service. KServe handles the deployment and scaling of ML models, while Envoy manages the traffic routing and load balancing.\n* Benefits: This combination ensures that your inference service can dynamically adjust to varying loads, provide fast and reliable responses, and maintain high availability.\n\n### Networking and Security\n\nWhile my focus is on dynamic provisioning and scaling, networking and security are also critical components:\n\n* Networking: Ensure smooth communication between components by setting up VPCs, subnets, and routing tables. Implementing service discovery with Kubernetes DNS or Consul allows services to find and communicate with each other seamlessly.\n* Security: Protect your inference service by encrypting data in transit and at rest, implementing robust user authentication and authorization, and using firewalls and VPNs to secure your network.\n\n### Wrapping Up\n\nIn just a short period, I went from ‚ÄúWhat‚Äôs an inference?‚Äù to exploring the potential of setting up a service that could transform how businesses use AI. The next time you hear someone casually dropping AI and LLM into a conversation, you‚Äôll know there‚Äôs some serious tech behind those words.\n\nI will be sharing some more in-depth technical details soon about how to implement it, so stay tuned for part ŒôŒô.\n\nBefore I sign off, a shoutout to [cnvrg.io](https://www.linkedin.com/redir/redirect?url=http%3A%2F%2Fcnvrg%2Eio&urlhash=_Wb-&trk=article-ssr-frontend-pulse_little-text-block), where I work. We‚Äôre a full-stack machine learning operating system acquired by Intel. At [cnvrg.io](https://www.linkedin.com/redir/redirect?url=http%3A%2F%2Fcnvrg%2Eio&urlhash=_Wb-&trk=article-ssr-frontend-pulse_little-text-block), we provide the best ML infrastructure on demand, allowing you to run ML jobs cheaper and faster. Our platform lets you mix and match infrastructure for your end-to-end flow, maximizing workload performance and speed with the agility to run on any compute and storage. Connect your storage and compute to launch any AI workload on demand. It‚Äôs a game-changer in the world of AI and ML\n\nFeel free to share your thoughts or ask questions in the comments.\n\n#AI #MachineLearning #LLM #Inference #cnvrg.io\n\n[Like](https://www.linkedin.com/signup/cold-join?session_redirect=%2Fpulse%2Fllm-everywhere-my-journey-lmm-inference-service-part-fadi-zaboura-qj1uf&trk=article-ssr-frontend-pulse_x-social-details_like-toggle_like-cta)\n\nLike\n\nCelebrate\n\nSupport\n\nLove\n\nInsightful\n\nFunny\n\n[Comment](https://www.linkedin.com/signup/cold-join?session_redirect=%2Fpulse%2Fllm-everywhere-my-journey-lmm-inference-service-part-fadi-zaboura-qj1uf&trk=article-ssr-frontend-pulse_comment-cta)\n\n[42](https://www.linkedin.com/signup/cold-join?session_redirect=%2Fpulse%2Fllm-everywhere-my-journey-lmm-inference-service-part-fadi-zaboura-qj1uf&trk=article-ssr-frontend-pulse_x-social-details_likes-count_social-actions-reactions)   [7 Comments](https://www.linkedin.com/signup/cold-join?session_redirect=%2Fpulse%2Fllm-everywhere-my-journey-lmm-inference-service-part-fadi-zaboura-qj1uf&trk=article-ssr-frontend-pulse_x-social-details_likes-count_social-actions-comments)\n\n[Svetlana Ratnikova](https://ca.linkedin.com/in/svetlanaratnikova?trk=article-ssr-frontend-pulse_x-social-details_comments-action_comment_actor-name)   1y \n\n* [Report this comment](/uas/login?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fpulse%2Fllm-everywhere-my-journey-lmm-inference-service-part-fadi-zaboura-qj1uf&trk=article-ssr-frontend-pulse_x-social-details_comments-action_comment_ellipsis-menu-semaphore-sign-in-redirect&guestReportContentType=COMMENT&_f=guest-reporting)\n\n◊™◊ï◊ì◊î ◊®◊ë◊î ◊ú◊ö ◊¢◊ú ◊î◊©◊ô◊™◊ï◊£üôÇ ◊ê◊†◊ô ◊û◊ñ◊û◊ô◊†◊î ◊ê◊ï◊™◊ö ◊ú◊ß◊ë◊ï◊¶◊î ◊©◊ú◊ô: ◊î◊ß◊ë◊ï◊¶◊î ◊û◊ó◊ë◊®◊™ ◊ë◊ô◊ü ◊¢◊°◊ß◊ô◊ù ◊ï◊ô◊ñ◊û◊ô◊ù ◊ë◊û◊í◊ï◊ï◊ü ◊™◊ó◊ï◊û◊ô◊ù. ◊î◊ß◊ë◊ï◊¶◊î ◊û◊ô◊ô◊¶◊®◊™ ◊©◊ô◊™◊ï◊§◊ô ◊§◊¢◊ï◊ú◊î,◊ê◊ô◊®◊ï◊¢◊ô◊ù ◊û◊©◊ï◊™◊§◊ô◊ù ◊ï◊ú◊ß◊ï◊ó◊ï◊™: [https://chat.whatsapp.com/BubG8iFDe2bHHWkNYiboeU](https://chat.whatsapp.com/BubG8iFDe2bHHWkNYiboeU?trk=article-ssr-frontend-pulse_x-social-details_comments-action_comment-text)\n\n[Like](https://www.linkedin.com/signup/cold-join?session_redirect=%2Fpulse%2Fllm-everywhere-my-journey-lmm-inference-service-part-fadi-zaboura-qj1uf&trk=article-ssr-frontend-pulse_x-social-details_comments-action_comment_like) [Reply](https://www.linkedin.com/signup/cold-join?session_redirect=%2Fpulse%2Fllm-everywhere-my-journey-lmm-inference-service-part-fadi-zaboura-qj1uf&trk=article-ssr-frontend-pulse_x-social-details_comments-action_comment_reply)  1¬†Reaction\n\n[Yossi Kessler](https://il.linkedin.com/in/yossi-kessler-5234a321b?trk=article-ssr-frontend-pulse_x-social-details_comments-action_comment_actor-name)   1y \n\n* [Report this comment](/uas/login?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fpulse%2Fllm-everywhere-my-journey-lmm-inference-service-part-fadi-zaboura-qj1uf&trk=article-ssr-frontend-pulse_x-social-details_comments-action_comment_ellipsis-menu-semaphore-sign-in-redirect&guestReportContentType=COMMENT&_f=guest-reporting)\n\n◊™◊ï◊ì◊î ◊®◊ë◊î ◊ú◊ö ◊¢◊ú ◊î◊©◊ô◊™◊ï◊£üôÇ ◊§◊ô◊®◊°◊û◊™◊ô ◊ê◊™ ◊î◊§◊ï◊°◊ò ◊©◊ú◊ö ◊ë◊ß◊ë◊ï◊¶◊î ◊ë◊ï◊ï◊¶◊ê◊§: [https://chat.whatsapp.com/HWWA9nLQYhW9DH97x227hJ](https://chat.whatsapp.com/HWWA9nLQYhW9DH97x227hJ?trk=article-ssr-frontend-pulse_x-social-details_comments-action_comment-text)\n\n[Like](https://www.linkedin.com/signup/cold-join?session_redirect=%2Fpulse%2Fllm-everywhere-my-journey-lmm-inference-service-part-fadi-zaboura-qj1uf&trk=article-ssr-frontend-pulse_x-social-details_comments-action_comment_like) [Reply](https://www.linkedin.com/signup/cold-join?session_redirect=%2Fpulse%2Fllm-everywhere-my-journey-lmm-inference-service-part-fadi-zaboura-qj1uf&trk=article-ssr-frontend-pulse_x-social-details_comments-action_comment_reply)  1¬†Reaction\n\n[Butros Spanioly](https://il.linkedin.com/in/butros-spanioly-372058b9?trk=article-ssr-frontend-pulse_x-social-details_comments-action_comment_actor-name)   1y \n\n* [Report this comment](/uas/login?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fpulse%2Fllm-everywhere-my-journey-lmm-inference-service-part-fadi-zaboura-qj1uf&trk=article-ssr-frontend-pulse_x-social-details_comments-action_comment_ellipsis-menu-semaphore-sign-in-redirect&guestReportContentType=COMMENT&_f=guest-reporting)\n\nWell done, very interesting üí™\n\n[Like](https://www.linkedin.com/signup/cold-join?session_redirect=%2Fpulse%2Fllm-everywhere-my-journey-lmm-inference-service-part-fadi-zaboura-qj1uf&trk=article-ssr-frontend-pulse_x-social-details_comments-action_comment_like) [Reply](https://www.linkedin.com/signup/cold-join?session_redirect=%2Fpulse%2Fllm-everywhere-my-journey-lmm-inference-service-part-fadi-zaboura-qj1uf&trk=article-ssr-frontend-pulse_x-social-details_comments-action_comment_reply)  [1¬†Reaction](https://www.linkedin.com/signup/cold-join?session_redirect=%2Fpulse%2Fllm-everywhere-my-journey-lmm-inference-service-part-fadi-zaboura-qj1uf&trk=article-ssr-frontend-pulse_x-social-details_comments-action_comment_reactions)   2¬†Reactions\n\n[Marwan B.](https://www.linkedin.com/in/marwan-bshara?trk=article-ssr-frontend-pulse_x-social-details_comments-action_comment_actor-name)   1y \n\n* [Report this comment](/uas/login?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fpulse%2Fllm-everywhere-my-journey-lmm-inference-service-part-fadi-zaboura-qj1uf&trk=article-ssr-frontend-pulse_x-social-details_comments-action_comment_ellipsis-menu-semaphore-sign-in-redirect&guestReportContentType=COMMENT&_f=guest-reporting)\n\nWell done, keep up the good work !!\n\n[Like](https://www.linkedin.com/signup/cold-join?session_redirect=%2Fpulse%2Fllm-everywhere-my-journey-lmm-inference-service-part-fadi-zaboura-qj1uf&trk=article-ssr-frontend-pulse_x-social-details_comments-action_comment_like) [Reply](https://www.linkedin.com/signup/cold-join?session_redirect=%2Fpulse%2Fllm-everywhere-my-journey-lmm-inference-service-part-fadi-zaboura-qj1uf&trk=article-ssr-frontend-pulse_x-social-details_comments-action_comment_reply)  [1¬†Reaction](https://www.linkedin.com/signup/cold-join?session_redirect=%2Fpulse%2Fllm-everywhere-my-journey-lmm-inference-service-part-fadi-zaboura-qj1uf&trk=article-ssr-frontend-pulse_x-social-details_comments-action_comment_reactions)   2¬†Reactions\n\n[See more comments](https://www.linkedin.com/signup/cold-join?session_redirect=%2Fpulse%2Fllm-everywhere-my-journey-lmm-inference-service-part-fadi-zaboura-qj1uf&trk=article-ssr-frontend-pulse_x-social-details_comments_comment-see-more)\n\nTo view or add a comment, [sign in](https://www.linkedin.com/signup/cold-join?session_redirect=%2Fpulse%2Fllm-everywhere-my-journey-lmm-inference-service-part-fadi-zaboura-qj1uf&trk=article-ssr-frontend-pulse_x-social-details_feed-cta-banner-cta)\n\n## More articles by Fadi Zaboura\n\n* [Mastering Concurrency: Goroutines, Python Coroutines, ASGI vs. WASGI, ASGI Server Workers, and Demystifying Concurrency, Threads, and Parallelism](https://www.linkedin.com/pulse/mastering-concurrency-goroutines-python-coroutines-asgi-fadi-zaboura) \n\n  Aug 12, 2023\n\n  ### Mastering Concurrency: Goroutines, Python Coroutines, ASGI vs. WASGI, ASGI Server Workers, and Demystifying Concurrency, Threads, and Parallelism\n\n  Introduction: Efficiently managing concurrency is the cornerstone of modern software development, underpinning the‚Ä¶\n\n  5 Comments\n* [A Comprehensive Comparison between HashiCorp Nomad and Kubernetes: Understanding the Right Tool for Your Infrastructure Orchestration Needs](https://www.linkedin.com/pulse/comprehensive-comparison-between-hashicorp-nomad-right-fadi-zaboura) \n\n  Jul 29, 2023\n\n  ### A Comprehensive Comparison between HashiCorp Nomad and Kubernetes: Understanding the Right Tool for Your Infrastructure Orchestration Needs\n\n  In the ever-evolving landscape of container orchestration and workload management, HashiCorp Nomad and Kubernetes stand‚Ä¶\n\n  11 Comments\n* [Automation Best Strategies and ROI](https://www.linkedin.com/pulse/automation-best-strategies-roi-fadi-zaboura) \n\n  Sep 25, 2018\n\n  ### Automation Best Strategies and ROI\n\n  Automated software testing has long been considered critical for big software development organizations, but is often‚Ä¶\n* [Desiging and Building Automation Infrastructure from scratch in a young startup](https://www.linkedin.com/pulse/desiging-building-automation-infrastructure-from-scratch-fadi-zaboura) \n\n  Aug 5, 2018\n\n  ### Desiging and Building Automation Infrastructure from scratch in a young startup\n\n  I recently joined a very cool young startup, called Xsites, located in Tel-Aviv, check out the website ->‚Ä¶\n\n## Explore content categories\n\n* [Career](https://www.linkedin.com/top-content/career/)\n* [Productivity](https://www.linkedin.com/top-content/productivity/)\n* [Finance](https://www.linkedin.com/top-content/finance/)\n* [Soft Skills & Emotional Intelligence](https://www.linkedin.com/top-content/soft-skills-emotional-intelligence/)\n* [Project Management](https://www.linkedin.com/top-content/project-management/)\n* [Education](https://www.linkedin.com/top-content/education/)\n* [Technology](https://www.linkedin.com/top-content/technology/)\n* [Leadership](https://www.linkedin.com/top-content/leadership/)\n* [Ecommerce](https://www.linkedin.com/top-content/ecommerce/)\n* [User Experience](https://www.linkedin.com/top-content/user-experience/)\n* [Recruitment & HR](https://www.linkedin.com/top-content/recruitment-hr/)\n* [Customer Experience](https://www.linkedin.com/top-content/customer-experience/)\n* [Real Estate](https://www.linkedin.com/top-content/real-estate/)\n* [Marketing](https://www.linkedin.com/top-content/marketing/)\n* [Sales](https://www.linkedin.com/top-content/sales/)\n* [Retail & Merchandising](https://www.linkedin.com/top-content/retail-merchandising/)\n* [Science](https://www.linkedin.com/top-content/science/)\n* [Supply Chain Management](https://www.linkedin.com/top-content/supply-chain-management/)\n* [Future Of Work](https://www.linkedin.com/top-content/future-of-work/)\n* [Consulting](https://www.linkedin.com/top-content/consulting/)\n* [Writing](https://www.linkedin.com/top-content/writing/)\n* [Economics](https://www.linkedin.com/top-content/economics/)\n* [Artificial Intelligence](https://www.linkedin.com/top-content/artificial-intelligence/)\n* [Employee Experience](https://www.linkedin.com/top-content/employee-experience/)\n* [Workplace Trends](https://www.linkedin.com/top-content/workplace-trends/)\n* [Fundraising](https://www.linkedin.com/top-content/fundraising/)\n* [Networking](https://www.linkedin.com/top-content/networking/)\n* [Corporate Social Responsibility](https://www.linkedin.com/top-content/corporate-social-responsibility/)\n* [Negotiation](https://www.linkedin.com/top-content/negotiation/)\n* [Communication](https://www.linkedin.com/top-content/communication/)\n* [Engineering](https://www.linkedin.com/top-content/engineering/)\n* [Hospitality & Tourism](https://www.linkedin.com/top-content/hospitality-tourism/)\n* [Business Strategy](https://www.linkedin.com/top-content/business-strategy/)\n* [Change Management](https://www.linkedin.com/top-content/change-management/)\n* [Organizational Culture](https://www.linkedin.com/top-content/organizational-culture/)\n* [Design](https://www.linkedin.com/top-content/design/)\n* [Innovation](https://www.linkedin.com/top-content/innovation/)\n* [Event Planning](https://www.linkedin.com/top-content/event-planning/)\n* [Training & Development](https://www.linkedin.com/top-content/training-development/)\n\n "
    },
    {
      "url": "https://www.linkedin.com/posts/seroter_daily-reading-list-september-10-2025-activity-7371677225806385152-z8aQ",
      "title": "How to automate app deployments, scale AI inference, and what ...",
      "content": "into a feature creep‚Ä¶ you'll probably relate. Read here: [...] AI for APIs: Integrating Services Without Wasting Hours APIs are the glue of modern applications. Reading endless documentation Writing boilerplate for authentication Handling errors the hard way With AI, I‚Äôve been able to cut API integration time drastically ‚Äî turning what used to take hours into a process of minutes. Here‚Äôs how I use AI to make API work painless. 1Ô∏è‚É£ Get Authentication Right the First Time The hardest part of any API is usually authentication. Instead of piecing it together from docs, I let AI generate a working template. üí° Prompt Example: ‚ÄúWrite Python code to connect to the Twitter API using OAuth 2.0. Include token refresh and error handling.‚Äù 2Ô∏è‚É£ Generate Request Templates Every API call has its quirks. AI can draft the request format so you‚Äôre not guessing [...] AI for APIs: Integrating Services Without Wasting Hours APIs are the glue of modern applications. Reading endless documentation Writing boilerplate for authentication Handling errors the hard way With AI, I‚Äôve been able to cut API integration time drastically ‚Äî turning what used to take hours into a process of minutes. Here‚Äôs how I use AI to make API work painless. 1Ô∏è‚É£ Get Authentication Right the First Time The hardest part of any API is usually authentication. Instead of piecing it together from docs, I let AI generate a working template. üí° Prompt Example: ‚ÄúWrite Python code to connect to the Twitter API using OAuth 2.0. Include token refresh and error handling.‚Äù 2Ô∏è‚É£ Generate Request Templates Every API call has its quirks. AI can draft the request format so you‚Äôre not guessing",
      "score": 0.43223172,
      "raw_content": "# How to automate app deployments, scale AI inference, and what skills AI can't automate.\n\nThis title was summarized by AI from the post below.\n\n[Richard Seroter](https://www.linkedin.com/in/seroter?trk=public_post_feed-actor-name)\n\n* [Report this post](/uas/login?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fseroter_daily-reading-list-september-10-2025-activity-7371677225806385152-z8aQ&trk=public_post_ellipsis-menu-semaphore-sign-in-redirect&guestReportContentType=POST&_f=guest-reporting)\n\nToday's links look at automating app deployments with the Gemini CLI, how to scale AI inference cost-effectively, and which skills AI can't automate.\n\n[Daily Reading List ‚Äì September 10, 2025¬†(#625)   http://seroter.com](https://www.linkedin.com/redir/redirect?url=http%3A%2F%2Fseroter%2Ecom%2F2025%2F09%2F10%2Fdaily-reading-list-september-10-2025-625%2F&urlhash=z4dh&trk=public_post_feed-article-content)\n\n[Like](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww%2Elinkedin%2Ecom%2Fposts%2Fseroter_daily-reading-list-september-10-2025-activity-7371677225806385152-z8aQ&trk=public_post_like-cta)   [Comment](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww%2Elinkedin%2Ecom%2Fposts%2Fseroter_daily-reading-list-september-10-2025-activity-7371677225806385152-z8aQ&trk=public_post_comment-cta)\n\nTo view or add a comment, [sign in](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww%2Elinkedin%2Ecom%2Fposts%2Fseroter_daily-reading-list-september-10-2025-activity-7371677225806385152-z8aQ&trk=public_post_feed-cta-banner-cta)\n\n## More Relevant Posts\n\n* [Software Engineering AI](https://www.linkedin.com/showcase/software-engineering-ai/?trk=public_post_feed-actor-name)\n\n  358 followers\n\n  + [Report this post](/uas/login?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fsoftware-engineering-ai_ai-artificialintelligence-ainews-activity-7374038175867932672-Z8hg&trk=public_post_ellipsis-menu-semaphore-sign-in-redirect&guestReportContentType=POST&_f=guest-reporting)\n\n  [LambdaTest](https://www.linkedin.com/company/lambdatest?trk=public_post-text) has launched KaneAI, an AI-powered test automation solution. KaneAI aims to make AI-native test automation accessible to users worldwide without a paid subscription. It allows users to create, authorize, and evolve tests using natural language. The platform supports web and mobile app testing, offering 300 minutes of HyperExecute for efficient test execution. It currently supports Selenium with Python for web tests and Appium with Python for mobile tests. [Asad Khan](https://www.linkedin.com/in/asad0801?trk=public_post-text), CEO and co-founder of LambdaTest, said the mission is to democratize quality engineering and make AI accessible to everyone involved. Read more: [https://lnkd.in/eUf\\_bWeV](https://www.linkedin.com/redir/redirect?url=https%3A%2F%2Flnkd%2Ein%2FeUf_bWeV&urlhash=ZklR&trk=public_post-text) üì∞ Subscribe to the weekly AI Programming Weekly: [https://lnkd.in/eUQ-KTc2](https://www.linkedin.com/redir/redirect?url=https%3A%2F%2Flnkd%2Ein%2FeUQ-KTc2&urlhash=RCjy&trk=public_post-text) [#ai](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fai&trk=public_post-text) [#artificialintelligence](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fartificialintelligence&trk=public_post-text) [#ainews](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fainews&trk=public_post-text)\n\n\n\n  [2](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fsoftware-engineering-ai_ai-artificialintelligence-ainews-activity-7374038175867932672-Z8hg&trk=public_post_social-actions-reactions)\n\n  [Like](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fsoftware-engineering-ai_ai-artificialintelligence-ainews-activity-7374038175867932672-Z8hg&trk=public_post_like-cta)   [Comment](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fsoftware-engineering-ai_ai-artificialintelligence-ainews-activity-7374038175867932672-Z8hg&trk=public_post_comment-cta)\n\n  To view or add a comment, [sign in](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fsoftware-engineering-ai_ai-artificialintelligence-ainews-activity-7374038175867932672-Z8hg&trk=public_post_feed-cta-banner-cta)\n* [Parker Dorris](https://www.linkedin.com/in/parkerdorris?trk=public_post_feed-actor-name)\n\n  + [Report this post](/uas/login?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fparkerdorris_feature-creeps-and-web-scrapers-activity-7372629798071783424-xTUA&trk=public_post_ellipsis-menu-semaphore-sign-in-redirect&guestReportContentType=POST&_f=guest-reporting)\n\n  AI code assistance in project creation gives developers more time to focus on architecture. Lately I've been wrestling with a fundamental architectural decision: Should my system store a curated dataset locally, or simply access the web on demand with an LLM agent? In this post I discuss: - Why ChatGPT's \"hidden\" web tool isn't available through the API, and how to recreate it in a Python script - The legal and practical guardrails of web scraping ([robots.txt](http://robots.txt?trk=public_post-text), Terms of Service) - The tradeoffs between local databases (fast, reproducible, but stale) versus live web access (fresh, flexible, but costly) - How \"context anxiety\" impacts decisions here If you've ever abandoned an AI side project to the digital basement after it spiraled into a feature creep‚Ä¶ you'll probably relate. Read here:¬†[https://lnkd.in/gj3uDBqk](https://www.linkedin.com/redir/redirect?url=https%3A%2F%2Flnkd%2Ein%2Fgj3uDBqk&urlhash=hEzh&trk=public_post-text)\n\n  [Feature creeps and web scrapers   switchingcontext.com](https://www.linkedin.com/redir/redirect?url=https%3A%2F%2Fwww%2Eswitchingcontext%2Ecom%2Fp%2Ffeature-creeps-and-web-scrapers&urlhash=4T7D&trk=public_post_feed-article-content)\n\n  [6](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fparkerdorris_feature-creeps-and-web-scrapers-activity-7372629798071783424-xTUA&trk=public_post_social-actions-reactions)   [1 Comment](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fparkerdorris_feature-creeps-and-web-scrapers-activity-7372629798071783424-xTUA&trk=public_post_social-actions-comments)\n\n  [Like](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fparkerdorris_feature-creeps-and-web-scrapers-activity-7372629798071783424-xTUA&trk=public_post_like-cta)   [Comment](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fparkerdorris_feature-creeps-and-web-scrapers-activity-7372629798071783424-xTUA&trk=public_post_comment-cta)\n\n  To view or add a comment, [sign in](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fparkerdorris_feature-creeps-and-web-scrapers-activity-7372629798071783424-xTUA&trk=public_post_feed-cta-banner-cta)\n* [GyaanSetu WebDev](https://www.linkedin.com/company/gyaansetu-webdev?trk=public_post_feed-actor-name)\n\n  292 followers\n\n  + [Report this post](/uas/login?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fgyaansetu-webdev_ai-for-apis-integrating-services-without-activity-7379672742066958336-esol&trk=public_post_ellipsis-menu-semaphore-sign-in-redirect&guestReportContentType=POST&_f=guest-reporting)\n\n  AI for APIs: Integrating Services Without Wasting Hours APIs are the glue of modern applications. Reading endless documentation Writing boilerplate for authentication Handling errors the hard way With AI, I‚Äôve been able to cut API integration time drastically ‚Äî turning what used to take hours into a process of minutes. Here‚Äôs how I use AI to make API work painless. 1Ô∏è‚É£ Get Authentication Right the First Time The hardest part of any API is usually authentication. Instead of piecing it together from docs, I let AI generate a working template. üí° Prompt Example: ‚ÄúWrite Python code to connect to the Twitter API using OAuth 2.0. Include token refresh and error handling.‚Äù 2Ô∏è‚É£ Generate Request Templates Every API call has its quirks. AI can draft the request format so you‚Äôre not guessing headers or parameters. üí° Prompt Example: ‚ÄúGenerate a GET request in [Node.js](http://Node.js?trk=public_post-text) (using Axios) to fetch the latest 50 issues from GitHub. Include headers for authentication.‚Äù 3Ô∏è‚É£ Build Wrappers for Reuse Instead of calling APIs directly everywhere, I ask AI to create [https://lnkd.in/gavr4ha2](https://www.linkedin.com/redir/redirect?url=https%3A%2F%2Flnkd%2Ein%2Fgavr4ha2&urlhash=6371&trk=public_post-text)\n\n  [Like](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fgyaansetu-webdev_ai-for-apis-integrating-services-without-activity-7379672742066958336-esol&trk=public_post_like-cta)   [Comment](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fgyaansetu-webdev_ai-for-apis-integrating-services-without-activity-7379672742066958336-esol&trk=public_post_comment-cta)\n\n  To view or add a comment, [sign in](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fgyaansetu-webdev_ai-for-apis-integrating-services-without-activity-7379672742066958336-esol&trk=public_post_feed-cta-banner-cta)\n* [GyaanSetu AI (Artificial Intelligence)](https://www.linkedin.com/company/gyaansetu-ai?trk=public_post_feed-actor-name)\n\n  441 followers\n\n  + [Report this post](/uas/login?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fgyaansetu-ai_ai-for-apis-integrating-services-without-activity-7379672858618167296-53Tw&trk=public_post_ellipsis-menu-semaphore-sign-in-redirect&guestReportContentType=POST&_f=guest-reporting)\n\n  AI for APIs: Integrating Services Without Wasting Hours APIs are the glue of modern applications. Reading endless documentation Writing boilerplate for authentication Handling errors the hard way With AI, I‚Äôve been able to cut API integration time drastically ‚Äî turning what used to take hours into a process of minutes. Here‚Äôs how I use AI to make API work painless. 1Ô∏è‚É£ Get Authentication Right the First Time The hardest part of any API is usually authentication. Instead of piecing it together from docs, I let AI generate a working template. üí° Prompt Example: ‚ÄúWrite Python code to connect to the Twitter API using OAuth 2.0. Include token refresh and error handling.‚Äù 2Ô∏è‚É£ Generate Request Templates Every API call has its quirks. AI can draft the request format so you‚Äôre not guessing headers or parameters. üí° Prompt Example: ‚ÄúGenerate a GET request in [Node.js](http://Node.js?trk=public_post-text) (using Axios) to fetch the latest 50 issues from GitHub. Include headers for authentication.‚Äù 3Ô∏è‚É£ Build Wrappers for Reuse Instead of calling APIs directly everywhere, I ask AI to create [https://lnkd.in/gavr4ha2](https://www.linkedin.com/redir/redirect?url=https%3A%2F%2Flnkd%2Ein%2Fgavr4ha2&urlhash=6371&trk=public_post-text)\n\n  [Like](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fgyaansetu-ai_ai-for-apis-integrating-services-without-activity-7379672858618167296-53Tw&trk=public_post_like-cta)   [Comment](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fgyaansetu-ai_ai-for-apis-integrating-services-without-activity-7379672858618167296-53Tw&trk=public_post_comment-cta)\n\n  To view or add a comment, [sign in](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fgyaansetu-ai_ai-for-apis-integrating-services-without-activity-7379672858618167296-53Tw&trk=public_post_feed-cta-banner-cta)\n* [The Curious Cast - Podcast](https://in.linkedin.com/company/the-curious-cast?trk=public_post_feed-actor-name)\n\n  1 follower\n\n  + [Report this post](/uas/login?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fthe-curious-cast_ai-for-apis-integrating-services-without-activity-7379673691091238912-tkwC&trk=public_post_ellipsis-menu-semaphore-sign-in-redirect&guestReportContentType=POST&_f=guest-reporting)\n\n  AI for APIs: Integrating Services Without Wasting Hours APIs are the glue of modern applications. Reading endless documentation Writing boilerplate for authentication Handling errors the hard way With AI, I‚Äôve been able to cut API integration time drastically ‚Äî turning what used to take hours into a process of minutes. Here‚Äôs how I use AI to make API work painless. 1Ô∏è‚É£ Get Authentication Right the First Time The hardest part of any API is usually authentication. Instead of piecing it together from docs, I let AI generate a working template. üí° Prompt Example: ‚ÄúWrite Python code to connect to the Twitter API using OAuth 2.0. Include token refresh and error handling.‚Äù 2Ô∏è‚É£ Generate Request Templates Every API call has its quirks. AI can draft the request format so you‚Äôre not guessing headers or parameters. üí° Prompt Example: ‚ÄúGenerate a GET request in [Node.js](http://Node.js?trk=public_post-text) (using Axios) to fetch the latest 50 issues from GitHub. Include headers for authentication.‚Äù 3Ô∏è‚É£ Build Wrappers for Reuse Instead of calling APIs directly everywhere, I ask AI to create [https://lnkd.in/gavr4ha2](https://www.linkedin.com/redir/redirect?url=https%3A%2F%2Flnkd%2Ein%2Fgavr4ha2&urlhash=6371&trk=public_post-text)\n\n  [Like](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fthe-curious-cast_ai-for-apis-integrating-services-without-activity-7379673691091238912-tkwC&trk=public_post_like-cta)   [Comment](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fthe-curious-cast_ai-for-apis-integrating-services-without-activity-7379673691091238912-tkwC&trk=public_post_comment-cta)\n\n  To view or add a comment, [sign in](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fthe-curious-cast_ai-for-apis-integrating-services-without-activity-7379673691091238912-tkwC&trk=public_post_feed-cta-banner-cta)\n* [Sahdev Garg](https://in.linkedin.com/in/sahdev-garg-9961b0b4?trk=public_post_feed-actor-name)\n\n  + [Report this post](/uas/login?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fsahdev-garg-9961b0b4_building-ai-applications-with-google-genkit-activity-7373036648445571072-jj6x&trk=public_post_ellipsis-menu-semaphore-sign-in-redirect&guestReportContentType=POST&_f=guest-reporting)\n\n  üöÄ Just dropped my latest article: \"ùóïùòÇùó∂ùóπùó±ùó∂ùóªùó¥ ùóîùóú ùóîùóΩùóΩùóπùó∂ùó∞ùóÆùòÅùó∂ùóºùóªùòÄ ùòÑùó∂ùòÅùóµ ùóöùóºùóºùó¥ùóπùó≤ ùóöùó≤ùóªùó∏ùó∂ùòÅ: ùóßùóµùó≤ ùóôùòÇùòÅùòÇùóøùó≤ ùóºùó≥ ùóüùóüùó† ùóôùóøùóÆùó∫ùó≤ùòÑùóºùóøùó∏.\" üöÄ Tired of juggling tools for AI development? Google Genkit is a game-changer! This open-source framework offers a unified, production-ready approach to building, deploying, and monitoring AI apps. ùó™ùóµùóÆùòÅ ùó∫ùóÆùó∏ùó≤ùòÄ ùó∂ùòÅ ùòÄùòÅùóÆùóªùó± ùóºùòÇùòÅ? ¬†‚Ä¢ ùóôùóπùó≤ùòÖùó∂ùóØùó∂ùóπùó∂ùòÅùòÜ: Supports [Node.js](http://Node.js?trk=public_post-text), Go, Python, and connects to any model (Google, OpenAI, Anthropic, Ollama). ¬†‚Ä¢ \"ùóôùóπùóºùòÑ\" ùóîùóøùó∞ùóµùó∂ùòÅùó≤ùó∞ùòÅùòÇùóøùó≤: Simplifies complex AI workflows. ¬†‚Ä¢ ùóôùòÇùóπùóπ ùóóùó≤ùòÉ ùóòùòÖùóΩùó≤ùóøùó∂ùó≤ùóªùó∞ùó≤: Local Dev UI, CLI, and production monitoring built-in. ¬†‚Ä¢ ùóóùó≤ùóΩùóπùóºùòÜ ùóîùóªùòÜùòÑùóµùó≤ùóøùó≤: Seamless full-stack integration for web and mobile. I've included a ùòÑùóºùóøùó∏ùó∂ùóªùó¥ ùóöùóº ùó≤ùòÖùóÆùó∫ùóΩùóπùó≤ ‚Äì a Smart Travel Assistant ‚Äì to show Genkit in action! Discover how Genkit empowers rapid, production-ready AI development. Read the full guide: [https://lnkd.in/gf2vSaQ8](https://www.linkedin.com/redir/redirect?url=https%3A%2F%2Flnkd%2Ein%2Fgf2vSaQ8&urlhash=Xp27&trk=public_post-text) [#GoogleGenkit](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fgooglegenkit&trk=public_post-text) [#LLMFramework](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fllmframework&trk=public_post-text) [#AIdevelopment](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Faidevelopment&trk=public_post-text) [#GoLang](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fgolang&trk=public_post-text) [#OpenSource](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fopensource&trk=public_post-text) [#Tech](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Ftech&trk=public_post-text) [#AIAgents](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Faiagents&trk=public_post-text)\n\n  [Building AI Applications with Google Genkit: The Future of LLM Framework   medium.com](https://www.linkedin.com/redir/redirect?url=https%3A%2F%2Fmedium%2Ecom%2F%40sahdevgarg%2Fbuilding-ai-applications-with-google-genkit-the-future-of-llm-framework-7da0b4b9f1ea&urlhash=EjDb&trk=public_post_feed-article-content)\n\n  [18](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fsahdev-garg-9961b0b4_building-ai-applications-with-google-genkit-activity-7373036648445571072-jj6x&trk=public_post_social-actions-reactions)\n\n  [Like](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fsahdev-garg-9961b0b4_building-ai-applications-with-google-genkit-activity-7373036648445571072-jj6x&trk=public_post_like-cta)   [Comment](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fsahdev-garg-9961b0b4_building-ai-applications-with-google-genkit-activity-7373036648445571072-jj6x&trk=public_post_comment-cta)\n\n  To view or add a comment, [sign in](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fsahdev-garg-9961b0b4_building-ai-applications-with-google-genkit-activity-7373036648445571072-jj6x&trk=public_post_feed-cta-banner-cta)\n* [QA Ducker](https://www.linkedin.com/company/qa-ducker?trk=public_post_feed-actor-name)\n\n  2,607 followers\n\n  + [Report this post](/uas/login?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fqa-ducker_ai-chrome-devtools-mcp-trace-analyse-activity-7379094499727278080-PKj9&trk=public_post_ellipsis-menu-semaphore-sign-in-redirect&guestReportContentType=POST&_f=guest-reporting)\n\n  üöÄ Chrome DevTools just got smarter with MCP (Model Context Protocol) ‚Üí [https://lnkd.in/dpxGypFg](https://www.linkedin.com/redir/redirect?url=https%3A%2F%2Flnkd%2Ein%2FdpxGypFg&urlhash=j2SF&trk=public_post-text) article Article by [Slawomir Radzyminski](https://pl.linkedin.com/in/slawekradzyminski/en?trk=public_post-text) A big step for debugging and testing üëå [#Chrome](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fchrome&trk=public_post-text) [#DevTools](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fdevtools&trk=public_post-text) [#QA](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fqa&trk=public_post-text) [#Testing](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Ftesting&trk=public_post-text) [#AI](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fai&trk=public_post-text)\n\n  [AI + Chrome DevTools MCP: Trace, Analyse, Fix Performance   awesome-testing.com](https://www.linkedin.com/redir/redirect?url=https%3A%2F%2Fwww%2Eawesome-testing%2Ecom%2F2025%2F09%2Fchrome-dev-tools-mcp&urlhash=3h2l&trk=public_post_feed-article-content)\n\n  [15](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fqa-ducker_ai-chrome-devtools-mcp-trace-analyse-activity-7379094499727278080-PKj9&trk=public_post_social-actions-reactions)\n\n  [Like](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fqa-ducker_ai-chrome-devtools-mcp-trace-analyse-activity-7379094499727278080-PKj9&trk=public_post_like-cta)   [Comment](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fqa-ducker_ai-chrome-devtools-mcp-trace-analyse-activity-7379094499727278080-PKj9&trk=public_post_comment-cta)\n\n  To view or add a comment, [sign in](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fqa-ducker_ai-chrome-devtools-mcp-trace-analyse-activity-7379094499727278080-PKj9&trk=public_post_feed-cta-banner-cta)\n* [Duany Bar√≥ Men√©ndez](https://uy.linkedin.com/in/duany-baro-menendez?trk=public_post_feed-actor-name)\n\n  + [Report this post](/uas/login?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fduany-baro-menendez_get-started-with-genkit-activity-7372068280015974400-RIdV&trk=public_post_ellipsis-menu-semaphore-sign-in-redirect&guestReportContentType=POST&_f=guest-reporting)\n\n  üöÄ Genkit Go 1.0 is now ready for production! The day before yesterday, Google released the first stable version of its open-source AI development framework for Go developers. Why this is exciting: ¬†‚úÖ Go's reliability guarantees support for stable production ¬†‚úÖ A single interface for many AI providers, such as Google AI, OpenAI, Anthropic, and Ollama ¬†‚úÖ Flows that are safe to type and have built-in observability ¬†‚úÖ The new genkit init:ai-tools command makes AI-assisted development even better. This is a great time for Go developers who want to add AI to their apps. Go's speed and well-developed AI tools make it a strong choice. üëâ Read the full announcement at [https://lnkd.in/dDR-4n4C](https://www.linkedin.com/redir/redirect?url=https%3A%2F%2Flnkd%2Ein%2FdDR-4n4C&urlhash=yzD4&trk=public_post-text) ¬†üëâ To get started, go to [https://lnkd.in/dGyHC9DN](https://www.linkedin.com/redir/redirect?url=https%3A%2F%2Flnkd%2Ein%2FdGyHC9DN&urlhash=2Ono&trk=public_post-text). üí° What AI projects are you most excited to work on with Go? I'd like to know what you think about how this fits into the growing Go AI ecosystem. [#Go](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fgo&trk=public_post-text) [#AI](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fai&trk=public_post-text) [#GoogleCloud](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fgooglecloud&trk=public_post-text) [#OpenSource](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fopensource&trk=public_post-text) [#MachineLearning](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fmachinelearning&trk=public_post-text) [#DevTools](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fdevtools&trk=public_post-text)\n\n  [Get started with Genkit   genkit.dev](https://www.linkedin.com/redir/redirect?url=https%3A%2F%2Fgenkit%2Edev%2Fdocs%2Fget-started%2F&urlhash=hGua&trk=public_post_feed-article-content)\n\n  [8](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fduany-baro-menendez_get-started-with-genkit-activity-7372068280015974400-RIdV&trk=public_post_social-actions-reactions)\n\n  [Like](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fduany-baro-menendez_get-started-with-genkit-activity-7372068280015974400-RIdV&trk=public_post_like-cta)   [Comment](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fduany-baro-menendez_get-started-with-genkit-activity-7372068280015974400-RIdV&trk=public_post_comment-cta)\n\n  To view or add a comment, [sign in](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fduany-baro-menendez_get-started-with-genkit-activity-7372068280015974400-RIdV&trk=public_post_feed-cta-banner-cta)\n* [Karan Singh Rathore](https://in.linkedin.com/in/karansingh7773?trk=public_post_feed-actor-name)\n\n  + [Report this post](/uas/login?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fkaransingh7773_ai-fastapi-python-activity-7372313053897424896-8tqN&trk=public_post_ellipsis-menu-semaphore-sign-in-redirect&guestReportContentType=POST&_f=guest-reporting)\n\n  üöÄ I just built my own AI Chatbot ‚Äì ‚ÄúKaran‚Äôs AI Chatbot‚Äù! ü§ñ After weeks of learning and experimenting, I‚Äôm excited to share a project that combines a FastAPI backend with a sleek, responsive frontend built in HTML/CSS. ‚ú® Key Highlights FastAPI Backend: Handles chat requests, maintains conversation history, and integrates securely with a language model API for real-time responses. Interactive Frontend: A modern, mobile-friendly interface with smooth animations and a clean dark theme for an enjoyable chat experience. Live Conversation Flow: Maintains context across multiple user messages for more natural, human-like interactions. Utility Features: Includes a ‚ÄúClear Chat‚Äù function and test endpoints for quick debugging and maintenance. This project taught me: How to connect a Python backend to a third-party AI API. Managing asynchronous requests and error handling gracefully. Designing an engaging user experience with HTML/CSS. I‚Äôve kept my API keys and sensitive configuration private, but I‚Äôd love to hear your feedback on the overall architecture and design. üí° Tech Stack: Python, FastAPI, HTML, CSS Building this chatbot was both challenging and rewarding, and it‚Äôs just the start‚ÄîI‚Äôm already thinking of new features like voice input and deployment to the cloud. [#AI](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fai&trk=public_post-text) [#FastAPI](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Ffastapi&trk=public_post-text) [#Python](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fpython&trk=public_post-text) [#WebDevelopment](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fwebdevelopment&trk=public_post-text) [#Chatbot](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fchatbot&trk=public_post-text) [#OpenSource](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fopensource&trk=public_post-text) [#LearningByBuilding](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Flearningbybuilding&trk=public_post-text)\n\n  [11](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fkaransingh7773_ai-fastapi-python-activity-7372313053897424896-8tqN&trk=public_post_social-actions-reactions)   [1 Comment](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fkaransingh7773_ai-fastapi-python-activity-7372313053897424896-8tqN&trk=public_post_social-actions-comments)\n\n  [Like](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fkaransingh7773_ai-fastapi-python-activity-7372313053897424896-8tqN&trk=public_post_like-cta)   [Comment](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fkaransingh7773_ai-fastapi-python-activity-7372313053897424896-8tqN&trk=public_post_comment-cta)\n\n  To view or add a comment, [sign in](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fkaransingh7773_ai-fastapi-python-activity-7372313053897424896-8tqN&trk=public_post_feed-cta-banner-cta)\n* [Kevin Montano](https://www.linkedin.com/in/kevin-montano?trk=public_post_feed-actor-name)\n\n  + [Report this post](/uas/login?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fkevin-montano_ai-code-review-now-in-beta-break-production-activity-7376295696527900672-W7WE&trk=public_post_ellipsis-menu-semaphore-sign-in-redirect&guestReportContentType=POST&_f=guest-reporting)\n\n  ‚ö° üöÄ [Sentry](https://www.linkedin.com/company/getsentry?trk=public_post-text)'s new AI Code Review feature in beta! This isn't just another automated linter‚Äîit's a game-changer. üöÄ ‚ö° By using historical data to predict and prevent production-breaking bugs right within the pull request workflow, Sentry helps teams ship code faster and with fewer headaches. It's about proactive prevention, not just reactive fixes. A huge step forward in building more resilient software! [#AI](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fai&trk=public_post-text) [#DeveloperTools](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fdevelopertools&trk=public_post-text) [#SoftwareDevelopment](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fsoftwaredevelopment&trk=public_post-text) [#Sentry](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fsentry&trk=public_post-text) [https://lnkd.in/gUEpVu3M](https://www.linkedin.com/redir/redirect?url=https%3A%2F%2Flnkd%2Ein%2FgUEpVu3M&urlhash=yU6K&trk=public_post-text)\n\n  [AI code review, now in beta: break production less   blog.sentry.io](https://www.linkedin.com/redir/redirect?url=https%3A%2F%2Fblog%2Esentry%2Eio%2Fsentry-ai-code-review-now-in-beta-break-production-less%2F&urlhash=Q17N&trk=public_post_feed-article-content)\n\n  [5](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fkevin-montano_ai-code-review-now-in-beta-break-production-activity-7376295696527900672-W7WE&trk=public_post_social-actions-reactions)\n\n  [Like](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fkevin-montano_ai-code-review-now-in-beta-break-production-activity-7376295696527900672-W7WE&trk=public_post_like-cta)   [Comment](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fkevin-montano_ai-code-review-now-in-beta-break-production-activity-7376295696527900672-W7WE&trk=public_post_comment-cta)\n\n  To view or add a comment, [sign in](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fkevin-montano_ai-code-review-now-in-beta-break-production-activity-7376295696527900672-W7WE&trk=public_post_feed-cta-banner-cta)\n\n16,927 followers\n\n* [3000+ Posts](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww%2Elinkedin%2Ecom%2Fin%2Fseroter%2Frecent-activity%2F&trk=public_post_follow-posts)\n* [3 Articles](https://www.linkedin.com/today/author/seroter?trk=public_post_follow-articles)\n\n[View Profile](https://www.linkedin.com/in/seroter?trk=public_post_follow-view-profile)   [Connect](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww%2Elinkedin%2Ecom%2Ffeed%2Fupdate%2Furn%3Ali%3Aactivity%3A7371677225806385152&trk=public_post_follow)\n\n## More from this author\n\n* [### You're a software architect looking to attend SpringOne Platform? Don't miss these six talks.\n\n  Richard Seroter   7y](https://www.linkedin.com/pulse/youre-software-architect-looking-attend-springone-platform-seroter?trk=public_post)\n* [### SpringOne Platform Day 2: Leaders stare down the hard things\n\n  Richard Seroter   8y](https://www.linkedin.com/pulse/springone-platform-day-2-leaders-stare-down-hard-things-seroter?trk=public_post)\n* [### SpringOne Platform Day 1 - It's about learning\n\n  Richard Seroter   8y](https://www.linkedin.com/pulse/springone-platform-day-1-its-learning-richard-seroter?trk=public_post)\n\n## Explore related topics\n\n* [Tools For Managing Enterprise AI Deployments](https://www.linkedin.com/top-content/artificial-intelligence/scaling-ai-solutions-in-enterprises/tools-for-managing-enterprise-ai-deployments/)\n* [Building Scalable Applications With AI Frameworks](https://www.linkedin.com/top-content/artificial-intelligence/ai-frameworks-for-software-development/building-scalable-applications-with-ai-frameworks/)\n* [How to Use AI Instead of Traditional Coding Skills](https://www.linkedin.com/top-content/artificial-intelligence/ai-in-coding-and-development/how-to-use-ai-instead-of-traditional-coding-skills/)\n\n## Explore content categories\n\n* [Career](https://www.linkedin.com/top-content/career/)\n* [Productivity](https://www.linkedin.com/top-content/productivity/)\n* [Finance](https://www.linkedin.com/top-content/finance/)\n* [Soft Skills & Emotional Intelligence](https://www.linkedin.com/top-content/soft-skills-emotional-intelligence/)\n* [Project Management](https://www.linkedin.com/top-content/project-management/)\n* [Education](https://www.linkedin.com/top-content/education/)\n* [Technology](https://www.linkedin.com/top-content/technology/)\n* [Leadership](https://www.linkedin.com/top-content/leadership/)\n* [Ecommerce](https://www.linkedin.com/top-content/ecommerce/)\n* [User Experience](https://www.linkedin.com/top-content/user-experience/)\n\n## Sign in to view more content\n\nCreate your free account or sign in to continue your search\n\n## Welcome back\n\nBy clicking Continue to join or sign in, you agree to LinkedIn‚Äôs [User Agreement](/legal/user-agreement?trk=public_post_contextual-sign-in-modal_sign-in-modal_auth-button_user-agreement), [Privacy Policy](/legal/privacy-policy?trk=public_post_contextual-sign-in-modal_sign-in-modal_auth-button_privacy-policy), and [Cookie Policy](/legal/cookie-policy?trk=public_post_contextual-sign-in-modal_sign-in-modal_auth-button_cookie-policy).\n\nNew to LinkedIn? [Join now](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww%2Elinkedin%2Ecom%2Fposts%2Fseroter_daily-reading-list-september-10-2025-activity-7371677225806385152-z8aQ&trk=public_post_contextual-sign-in-modal_sign-in-modal_join-link)\n\nor\n\nNew to LinkedIn? [Join now](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww%2Elinkedin%2Ecom%2Fposts%2Fseroter_daily-reading-list-september-10-2025-activity-7371677225806385152-z8aQ&trk=public_post_contextual-sign-in-modal_join-link)\n\nBy clicking Continue to join or sign in, you agree to LinkedIn‚Äôs [User Agreement](/legal/user-agreement?trk=linkedin-tc_auth-button_user-agreement), [Privacy Policy](/legal/privacy-policy?trk=linkedin-tc_auth-button_privacy-policy), and [Cookie Policy](/legal/cookie-policy?trk=linkedin-tc_auth-button_cookie-policy).\n\nNever miss a beat on the app\n\nDon‚Äôt have the app? Get it in the Microsoft Store.\n\n [Open the app](ms-windows-store://pdp/?ProductId=9WZDNCRFJ4Q7&mode=mini&cid=guest_desktop_upsell_post2)\n\n "
    },
    {
      "url": "https://www.linkedin.com/posts/lucashendrich_ai-machinelearning-databricks-activity-7301298120733196290-wB_s",
      "title": "How to optimize AI solutions with model training and ...",
      "content": "a feature, think of it as as a part part of that model that you're training initially and the model training phase. Um, so the workflows are different, right? So the training uses heavy duty clusters with experiment tracking, while inference really optimizes for speed or for throughput. For training, you're going to configure your clusters with sufficient memory and GPUs, organize your ML code with notebooks or repositories and leverage auto scaling. And that's going to get essentially allow you to, to work with those massive datasets in the training phase. For inference, you're going to register your model and model registry. Deploy the model using model serving for real time applications so that's the low latency case. Or create batch inference jobs for high volume of predictions. Um, [...] it learned in the training phase with new data that it's interacting with in production or let's say in a production environment. And data data bricks, for example, handles this in two different ways. You can use model serving. That uses a serverless infrastructure with REST API endpoints and that allows you to automatically scale and really handle low latency responses. And then there's there's batch processing where you can use Spark or Databricks. Essentially uses Spark to generate predictions and large datasets which could be scheduled or triggered when new data arrives. Both approaches benefit from a feature store, which means that you're you're consistent with your feature computation. Between training and production. So a feature, think of it as as a part part of that model that",
      "score": 0.4221955,
      "raw_content": "## LinkedIn respects your privacy\n\nLinkedIn and 3rd parties use essential and non-essential cookies to provide, secure, analyze and improve our Services, and to show you relevant ads (including **professional and job ads**) on and off LinkedIn. Learn more in our [Cookie Policy](https://www.linkedin.com/legal/cookie-policy).\n\nSelect Accept to consent or Reject to decline non-essential cookies for this use. You can update your choices at any time in your [settings](https://www.linkedin.com/mypreferences/g/guest-cookies).\n\n\n\n\n[Lucas Hendrich](https://www.linkedin.com/in/lucashendrich?trk=public_post_feed-actor-name)\n\nChief Technology Officer @ Forte Group | Private Equity Advisor | Board Advisor. Driving business results and enabling growth through technology leadership.\n\n* [Report this post](/uas/login?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Flucashendrich_ai-machinelearning-databricks-activity-7301298120733196290-wB_s&trk=public_post_ellipsis-menu-semaphore-sign-in-redirect&guestReportContentType=POST&_f=guest-reporting)\n\nModel training and inference are two distinct phases‚Äîto business users, this may seem like a single process for implementing an AI solution. ‚úÖ Model training is the high-compute, GPU-intensive phase where we refine a model using vast amounts of data. ‚úÖ Inference is the real-time or batch process where a trained model applies its knowledge to new data. Whether optimizing for performance or scale, understanding the difference between training and inference is key. [#AI](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fai&trk=public_post-text) [#MachineLearning](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fmachinelearning&trk=public_post-text) [#Databricks](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fdatabricks&trk=public_post-text) [#ModelTraining](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fmodeltraining&trk=public_post-text) [#Inference](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Finference&trk=public_post-text)\n\n[39](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww%2Elinkedin%2Ecom%2Fposts%2Flucashendrich_ai-machinelearning-databricks-activity-7301298120733196290-wB_s&trk=public_post_social-actions-reactions)   [1 Comment](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww%2Elinkedin%2Ecom%2Fposts%2Flucashendrich_ai-machinelearning-databricks-activity-7301298120733196290-wB_s&trk=public_post_social-actions-comments)\n\n[Like](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww%2Elinkedin%2Ecom%2Fposts%2Flucashendrich_ai-machinelearning-databricks-activity-7301298120733196290-wB_s&trk=public_post_like-cta)   [Comment](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww%2Elinkedin%2Ecom%2Fposts%2Flucashendrich_ai-machinelearning-databricks-activity-7301298120733196290-wB_s&trk=public_post_comment-cta) \n\n##### **Transcript**\n\nSo, umm, one thing I'd like to talk about today is the difference between model training and inference. To anyone who hasn't really implemented AI in a production environment before. And when I see a I, you know, I could be talking about classical AI models or large language models. Sometimes, you know, people might think of this as one big thing. You, you train the model, you put it out there, people use it, you retrain it, you put it out there. And really there's two distinct phases and I think it's useful to decouple them in our minds. It just. Helps think about how does this all work, and then I'm going to connect this to how this works with a modern data analytics platform like Databricks that we'll use as an example. It's a tool that we tend to use quite a bit, so the model training. Really is. It's very compute heavy. It's where you use compute clusters and data bricks, use ML flow to track experiments and model versions. You use Delta Lake to manage your training datasets and use workflow jobs to automate pipelines. And because Databricks has a distributed architecture, you can you can really work with massive data sets sets, but think about this as the high compute phase. And and that's really what you're focused on is, is the GPU acceleration. And and that that's, you know, those are the tools that you would use in this phase. Once you train your model, you move to the inference phase. And what inference means basically is applying what it learned in the training phase with new data that it's interacting with in production or let's say in a production environment. And data data bricks, for example, handles this in two different ways. You can use model serving. That uses a serverless infrastructure with REST API endpoints and that allows you to automatically scale and really handle low latency responses. And then there's there's batch processing where you can use Spark or Databricks. Essentially uses Spark to generate predictions and large datasets which could be scheduled or triggered when new data arrives. Both approaches benefit from a feature store, which means that you're you're consistent with your feature computation. Between training and production. So a feature, think of it as as a part part of that model that you're training initially and the model training phase. Um, so the workflows are different, right? So the training uses heavy duty clusters with experiment tracking, while inference really optimizes for speed or for throughput. For training, you're going to configure your clusters with sufficient memory and GPUs, organize your ML code with notebooks or repositories and leverage auto scaling. And that's going to get essentially allow you to, to work with those massive datasets in the training phase. For inference, you're going to register your model and model registry. Deploy the model using model serving for real time applications so that's the low latency case. Or create batch inference jobs for high volume of predictions. Um, so again, just wanted to, to, to, to help people with that distinction between the model training phase and the inference phase, the certain implications in terms of, you know, what you're looking for and for performance, whether it's it's high compute or low latency processing. And I hope that helps us think about this in, in a, in a, in a way in which we, we understand the end to end process. And finally, I used data bricks in this example. Just because it's a tool that that that we use a lot and it helps kind of, you know, think about that end to end training to deployment in one platform.\n\n[Juanca Tomadin](https://ar.linkedin.com/in/juanca-tomadin-28a6b180?trk=public_post_comment_actor-name) \n\nGerente en Banco Santander Rio\n\n 8mo \n\n* [Report this comment](/uas/login?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Flucashendrich_ai-machinelearning-databricks-activity-7301298120733196290-wB_s&trk=public_post_comment_ellipsis-menu-semaphore-sign-in-redirect&guestReportContentType=COMMENT&_f=guest-reporting)\n\nMuy did√°ctico\n\n[Like](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww%2Elinkedin%2Ecom%2Fposts%2Flucashendrich_ai-machinelearning-databricks-activity-7301298120733196290-wB_s&trk=public_post_comment_like) [Reply](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww%2Elinkedin%2Ecom%2Fposts%2Flucashendrich_ai-machinelearning-databricks-activity-7301298120733196290-wB_s&trk=public_post_comment_reply)  1¬†Reaction\n\nTo view or add a comment, [sign in](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww%2Elinkedin%2Ecom%2Fposts%2Flucashendrich_ai-machinelearning-databricks-activity-7301298120733196290-wB_s&trk=public_post_feed-cta-banner-cta)\n\n## More Relevant Posts\n\n* [Ajeet Yadav](https://in.linkedin.com/in/ajeet-yadav-tech?trk=public_post_feed-actor-name)\n\n  üöÄ Senior Software Engineer(5.6 Yrs Exp) |üêç Python, üåêDjango, üß†LangChain, üìäStreamlit ü§ñ Building GenAI & RAG Apps | üì¶ Vector DBs | MySQL| Node JS|‚öôÔ∏è AngularJS | LLMs Explorer | Building Scalable Web & AI Applications\n\n  + [Report this post](/uas/login?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fajeet-yadav-tech_ai-machinelearning-transferlearning-activity-7379547157965701120-9D--&trk=public_post_ellipsis-menu-semaphore-sign-in-redirect&guestReportContentType=POST&_f=guest-reporting)\n\n  üöÄ Transfer Learning in Action Why train from scratch when you can stand on the shoulders of giants? üí° Here‚Äôs how it works: 1Ô∏è‚É£ A model like GPT is pre-trained on massive internet data. 2Ô∏è‚É£ We transfer that knowledge to our task. 3Ô∏è‚É£ With fine-tuning, it adapts to a specific use case (like customer support). 4Ô∏è‚É£ The result? A specialized model trained with way less data & cost. ‚ú® That‚Äôs the power of Transfer Learning ‚Üí smarter AI, faster results. üëâ Have you tried fine-tuning a pre-trained model for your own project yet? [#AI](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fai&trk=public_post-text) [#MachineLearning](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fmachinelearning&trk=public_post-text) [#TransferLearning](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Ftransferlearning&trk=public_post-text) [#FineTuning](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Ffinetuning&trk=public_post-text) [#HuggingFace](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fhuggingface&trk=public_post-text) [#GenAI](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fgenai&trk=public_post-text) [#DeepLearning](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fdeeplearning&trk=public_post-text) [#LearningInPublic](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Flearninginpublic&trk=public_post-text)\n\n\n\n  [Like](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fajeet-yadav-tech_ai-machinelearning-transferlearning-activity-7379547157965701120-9D--&trk=public_post_like-cta)   [Comment](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fajeet-yadav-tech_ai-machinelearning-transferlearning-activity-7379547157965701120-9D--&trk=public_post_comment-cta)\n\n  To view or add a comment, [sign in](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fajeet-yadav-tech_ai-machinelearning-transferlearning-activity-7379547157965701120-9D--&trk=public_post_feed-cta-banner-cta)\n* [NICE Actimize](https://www.linkedin.com/company/actimize?trk=public_post_feed-actor-name)\n\n  51,395 followers\n\n  + [Report this post](/uas/login?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Factimize_ai-financialcrime-innovation-activity-7382466790712590337-pjg8&trk=public_post_ellipsis-menu-semaphore-sign-in-redirect&guestReportContentType=POST&_f=guest-reporting)\n\n  Financial institutions are shifting from traditional workflows with pre-built models to machine learning models developed by their own machine learning and AI experts. [Achi Hackmon](https://il.linkedin.com/in/achi-hackmon-7310311?trk=public_post-text), Vice President of AI and Analytics at NICE Actimize, highlights the advantages of building business-specific models tailored to unique use cases. [https://bit.ly/42ypj2r](https://www.linkedin.com/redir/redirect?url=https%3A%2F%2Fbit%2Ely%2F42ypj2r&urlhash=1iJo&trk=public_post-text) [#AI](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fai&trk=public_post-text) [#FinancialCrime](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Ffinancialcrime&trk=public_post-text) [#Innovation](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Finnovation&trk=public_post-text)\n\n  [9](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Factimize_ai-financialcrime-innovation-activity-7382466790712590337-pjg8&trk=public_post_social-actions-reactions)\n\n  [Like](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Factimize_ai-financialcrime-innovation-activity-7382466790712590337-pjg8&trk=public_post_like-cta)   [Comment](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Factimize_ai-financialcrime-innovation-activity-7382466790712590337-pjg8&trk=public_post_comment-cta)\n\n  To view or add a comment, [sign in](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Factimize_ai-financialcrime-innovation-activity-7382466790712590337-pjg8&trk=public_post_feed-cta-banner-cta)\n* [Md Sharique](https://in.linkedin.com/in/mdsharique77?trk=public_post_feed-actor-name)\n\n  AI Research Scientist\n\n  + [Report this post](/uas/login?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fmdsharique77_ai-machinelearning-finetuning-activity-7383019362481430528-gDzn&trk=public_post_ellipsis-menu-semaphore-sign-in-redirect&guestReportContentType=POST&_f=guest-reporting)\n\n  üöÄ Fine-Tuning in AI/ML ‚Äì The Game Changer! In today‚Äôs AI landscape, fine-tuning plays a key role in customizing pre-trained models for specific tasks. Instead of training from scratch, we adapt large models with domain-specific data‚Äîmaking them smarter, faster, and more efficient for real-world use cases. From chatbots to vision models, fine-tuning is what makes AI systems truly context-aware and application-ready. üîçüí° [#AI](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fai&trk=public_post-text) [#MachineLearning](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fmachinelearning&trk=public_post-text) [#FineTuning](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Ffinetuning&trk=public_post-text) [#DeepLearning](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fdeeplearning&trk=public_post-text) [#ArtificialIntelligence](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fartificialintelligence&trk=public_post-text) [#DataScience](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fdatascience&trk=public_post-text)\n\n\n\n  [12](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fmdsharique77_ai-machinelearning-finetuning-activity-7383019362481430528-gDzn&trk=public_post_social-actions-reactions)\n\n  [Like](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fmdsharique77_ai-machinelearning-finetuning-activity-7383019362481430528-gDzn&trk=public_post_like-cta)   [Comment](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fmdsharique77_ai-machinelearning-finetuning-activity-7383019362481430528-gDzn&trk=public_post_comment-cta)\n\n  To view or add a comment, [sign in](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fmdsharique77_ai-machinelearning-finetuning-activity-7383019362481430528-gDzn&trk=public_post_feed-cta-banner-cta)\n* [Lisa W.](https://ca.linkedin.com/in/lisawalkeryvr?trk=public_post_feed-actor-name)\n\n  Portfolio Manager dedicated to assisting clients with their compliance learning needs. Passionate about soccer (football) in my spare time.\n\n  + [Report this post](/uas/login?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Flisawalkeryvr_learningtransformation-aiinlearning-activity-7384632554525581312-LpJp&trk=public_post_ellipsis-menu-semaphore-sign-in-redirect&guestReportContentType=POST&_f=guest-reporting)\n\n  [https://lnkd.in/g\\_g3QN3p](https://www.linkedin.com/redir/redirect?url=https%3A%2F%2Flnkd%2Ein%2Fg_g3QN3p&urlhash=rneQ&trk=public_post-text) With nearly a third of organizations not using AI in Learning & Development and 25% yet to see benefits, now is the time to move from curiosity to confident experimentation. Learn how embracing AI can enable agility, personalize growth, and fuel continuous learning. [#LearningTransformation](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Flearningtransformation&trk=public_post-text) [#AIinLearning](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Faiinlearning&trk=public_post-text)\n\n\n\n  [Like](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Flisawalkeryvr_learningtransformation-aiinlearning-activity-7384632554525581312-LpJp&trk=public_post_like-cta)   [Comment](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Flisawalkeryvr_learningtransformation-aiinlearning-activity-7384632554525581312-LpJp&trk=public_post_comment-cta)\n\n  To view or add a comment, [sign in](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Flisawalkeryvr_learningtransformation-aiinlearning-activity-7384632554525581312-LpJp&trk=public_post_feed-cta-banner-cta)\n* [J√ºrgen E. Schuster](https://de.linkedin.com/in/j%C3%BCrgen-e-schuster-74313625?trk=public_post_feed-actor-name)\n\n  Digital & Remote Service Lead\n\n  + [Report this post](/uas/login?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fj%25C3%25BCrgen-e-schuster-74313625_ai-ml-hosokawaalpine-activity-7382514159470682112-cPP3&trk=public_post_ellipsis-menu-semaphore-sign-in-redirect&guestReportContentType=POST&_f=guest-reporting)\n\n  Day 3 at K-Fair ‚ÄúIs there AI in [isa.io](https://www.linkedin.com/redir/redirect?url=http%3A%2F%2Fisa%2Eio&urlhash=rKmC&trk=public_post-text)?‚Äù ‚Äî that‚Äôs what a customer asked me today. My answer: Well, it depends. If you consider a sophisticated algorithm that uses statistical methods (as many companies do üòâ), then yes ‚Äî we use that to automatically create optimized production recipes (the best adjustments during production). But when it comes to real AI ‚Äî actual machine learning models ‚Äî we use those for detecting optimized bubble contours. No idea what I‚Äôm talking about? Just reach out ‚Äî I‚Äôd be happy to explain! [#AI](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fai&trk=public_post-text) [#ML](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fml&trk=public_post-text) [#Hosokawaalpine](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fhosokawaalpine&trk=public_post-text) [#Blueserv](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fblueserv&trk=public_post-text) [#Blownfilm](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fblownfilm&trk=public_post-text) [#Kfair](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fkfair&trk=public_post-text) [#Predictivemaintenance](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fpredictivemaintenance&trk=public_post-text) [#Aftersales](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Faftersales&trk=public_post-text)\n\n\n\n  [8](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fj%25C3%25BCrgen-e-schuster-74313625_ai-ml-hosokawaalpine-activity-7382514159470682112-cPP3&trk=public_post_social-actions-reactions)   [1 Comment](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fj%25C3%25BCrgen-e-schuster-74313625_ai-ml-hosokawaalpine-activity-7382514159470682112-cPP3&trk=public_post_social-actions-comments)\n\n  [Like](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fj%25C3%25BCrgen-e-schuster-74313625_ai-ml-hosokawaalpine-activity-7382514159470682112-cPP3&trk=public_post_like-cta)   [Comment](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fj%25C3%25BCrgen-e-schuster-74313625_ai-ml-hosokawaalpine-activity-7382514159470682112-cPP3&trk=public_post_comment-cta)\n\n  To view or add a comment, [sign in](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fj%25C3%25BCrgen-e-schuster-74313625_ai-ml-hosokawaalpine-activity-7382514159470682112-cPP3&trk=public_post_feed-cta-banner-cta)\n* [Robert Mann](https://www.linkedin.com/in/rmann1?trk=public_post_feed-actor-name)\n\n  Senior Talent Sourcer | Product & Engineering Talent Acquisition | Building High-Impact Teams\n\n  + [Report this post](/uas/login?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Frmann1_ai-machinelearning-llms-activity-7387237303607386112-boSb&trk=public_post_ellipsis-menu-semaphore-sign-in-redirect&guestReportContentType=POST&_f=guest-reporting)\n\n  AI and ML continue to evolve faster than most teams can adapt from multimodal models that process text, images, and video simultaneously to smaller, fine-tuned LLMs that outperform larger ones in domain-specific tasks. It‚Äôs no longer just about scale it‚Äôs about efficiency, context, and responsible deployment. The companies getting it right are those integrating AI into existing workflows, not just building shiny new tools. I‚Äôm curious what recent AI/ML advancement do you think will have the biggest practical impact in the next year? [#AI](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fai&trk=public_post-text) [#MachineLearning](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fmachinelearning&trk=public_post-text) [#LLMs](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fllms&trk=public_post-text) [#TechTrends](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Ftechtrends&trk=public_post-text) [#DataScience](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fdatascience&trk=public_post-text)\n\n  [3](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Frmann1_ai-machinelearning-llms-activity-7387237303607386112-boSb&trk=public_post_social-actions-reactions)\n\n  [Like](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Frmann1_ai-machinelearning-llms-activity-7387237303607386112-boSb&trk=public_post_like-cta)   [Comment](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Frmann1_ai-machinelearning-llms-activity-7387237303607386112-boSb&trk=public_post_comment-cta)\n\n  To view or add a comment, [sign in](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Frmann1_ai-machinelearning-llms-activity-7387237303607386112-boSb&trk=public_post_feed-cta-banner-cta)\n* [Exlon tech](https://pk.linkedin.com/company/exlon-tech?trk=public_post_feed-actor-name)\n\n  1,098 followers\n\n  + [Report this post](/uas/login?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fexlon-tech_promptengineering-ai-machinelearning-activity-7381916664424132608-E4PC&trk=public_post_ellipsis-menu-semaphore-sign-in-redirect&guestReportContentType=POST&_f=guest-reporting)\n\n  üöÄ Mastering Prompt Engineering with the 3Cs Framework üöÄ If you're looking to get the most out of your AI models, it‚Äôs essential to master the art of prompt engineering. Here‚Äôs the 3Cs Framework to help guide you: 1Ô∏è‚É£ Clarity ‚Äì Provide specific details to ensure the model understands your intentions clearly. 2Ô∏è‚É£ Context ‚Äì Offer the necessary context for the model to gauge the complexity, while keeping it concise. 3Ô∏è‚É£ Constrains ‚Äì Limit the output in terms of length, style, and format to get exactly what you need. Mastering these elements will help you create more accurate and efficient prompts! üîçüí° [#PromptEngineering](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fpromptengineering&trk=public_post-text) [#AI](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fai&trk=public_post-text) [#MachineLearning](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fmachinelearning&trk=public_post-text) [#Exlontech](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fexlontech&trk=public_post-text) [#AIOptimization](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Faioptimization&trk=public_post-text) [#TechTips](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Ftechtips&trk=public_post-text) [#3CsFramework](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2F3csframework&trk=public_post-text)\n\n\n\n  [5](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fexlon-tech_promptengineering-ai-machinelearning-activity-7381916664424132608-E4PC&trk=public_post_social-actions-reactions)\n\n  [Like](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fexlon-tech_promptengineering-ai-machinelearning-activity-7381916664424132608-E4PC&trk=public_post_like-cta)   [Comment](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fexlon-tech_promptengineering-ai-machinelearning-activity-7381916664424132608-E4PC&trk=public_post_comment-cta)\n\n  To view or add a comment, [sign in](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fexlon-tech_promptengineering-ai-machinelearning-activity-7381916664424132608-E4PC&trk=public_post_feed-cta-banner-cta)\n* [Shriram Vasudevan (FIE, FIETE,SMIEEE)](https://in.linkedin.com/in/shriramkvasudevan?trk=public_post_feed-actor-name)\n\n  AI & GenAI Leader | TEDx Speaker | YouTuber | Former Intel | Ex-LTTS, Wipro & Aricent | Author | 50+ Hackthon winner\n\n  + [Report this post](/uas/login?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fshriramkvasudevan_50-ai-terms-explained-in-8-minutes-learn-activity-7387123739508994050-ppuP&trk=public_post_ellipsis-menu-semaphore-sign-in-redirect&guestReportContentType=POST&_f=guest-reporting)\n\n  üß† 50 AI Terms Explained - Simplified for Everyone! AI is everywhere - but the jargon can be overwhelming. In this short video, I break down 50 essential AI terms - from algorithms to transformers - in a way that‚Äôs simple, practical, and fun to learn. Whether you‚Äôre a student, developer, or business leader, this will help you speak the language of AI with confidence. üöÄ üé• Watch now to explore: ‚úÖ Key AI buzzwords, decoded ‚úÖ Real-world meaning behind technical terms ‚úÖ The bridge between AI theory and business use Let‚Äôs make AI knowledge accessible to all. üí° [https://lnkd.in/gjMq9CAw](https://www.linkedin.com/redir/redirect?url=https%3A%2F%2Flnkd%2Ein%2FgjMq9CAw&urlhash=vm8H&trk=public_post-text)\n\n  [### 50 AI Terms Explained in 8 Minutes ‚Äì Learn AI Fast!](https://www.linkedin.com/redir/redirect?url=https%3A%2F%2Fwww%2Eyoutube%2Ecom%2Fwatch%3Fv%3DEF0tpAPgP7A&urlhash=rC7n&trk=public_post_ingested-content-summary-external-video-content)\n\n  #### https://www.youtube.com/\n\n  [33](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fshriramkvasudevan_50-ai-terms-explained-in-8-minutes-learn-activity-7387123739508994050-ppuP&trk=public_post_social-actions-reactions)\n\n  [Like](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fshriramkvasudevan_50-ai-terms-explained-in-8-minutes-learn-activity-7387123739508994050-ppuP&trk=public_post_like-cta)   [Comment](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fshriramkvasudevan_50-ai-terms-explained-in-8-minutes-learn-activity-7387123739508994050-ppuP&trk=public_post_comment-cta)\n\n  To view or add a comment, [sign in](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fshriramkvasudevan_50-ai-terms-explained-in-8-minutes-learn-activity-7387123739508994050-ppuP&trk=public_post_feed-cta-banner-cta)\n* [TheNextGenTechInsider.com](https://www.linkedin.com/company/hirendave-thenextgentechinsider?trk=public_post_feed-actor-name)\n\n  180 followers\n\n  + [Report this post](/uas/login?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fhirendave-thenextgentechinsider_airoi-processorchestrati-aitobusinessvalue-activity-7382376746815471616-Z7RA&trk=public_post_ellipsis-menu-semaphore-sign-in-redirect&guestReportContentType=POST&_f=guest-reporting)\n\n  üåü New Blog Just Published! üåü üìå AI to ROI: Mastering Process Orchestration üöÄ ‚úçÔ∏è Author: Hiren Dave üìñ Enterprises are rapidly turning isolated machine-learning experiments into measurable business value. Yet the promise of AI often stalls at the prototype stage, leaving decision-makers questioning...... üïí Published: 2025-10-10 üìÇ Category: AI/ML üîó Read more: [https://lnkd.in/dZkZySvG](https://www.linkedin.com/redir/redirect?url=https%3A%2F%2Flnkd%2Ein%2FdZkZySvG&urlhash=lDv8&trk=public_post-text) üöÄ‚ú® [#airoi](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fairoi&trk=public_post-text) [#processorchestrati](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fprocessorchestrati&trk=public_post-text) [#aitobusinessvalue](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Faitobusinessvalue&trk=public_post-text)\n\n\n\n  [Like](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fhirendave-thenextgentechinsider_airoi-processorchestrati-aitobusinessvalue-activity-7382376746815471616-Z7RA&trk=public_post_like-cta)   [Comment](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fhirendave-thenextgentechinsider_airoi-processorchestrati-aitobusinessvalue-activity-7382376746815471616-Z7RA&trk=public_post_comment-cta)\n\n  To view or add a comment, [sign in](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fhirendave-thenextgentechinsider_airoi-processorchestrati-aitobusinessvalue-activity-7382376746815471616-Z7RA&trk=public_post_feed-cta-banner-cta)\n* [Nidhi Bansal](https://in.linkedin.com/in/nidhi-bansal-54099a8?trk=public_post_feed-actor-name)\n\n  Identity domain | LifeCycle Mgmt and Security SME | AI evangelist | IIT Roorkee Alumni\n\n  + [Report this post](/uas/login?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fnidhi-bansal-54099a8_artificialintelligence-machinelearning-activity-7380551084324392960-bI7q&trk=public_post_ellipsis-menu-semaphore-sign-in-redirect&guestReportContentType=POST&_f=guest-reporting)\n\n  ü§ñ \\*\\*Base Models vs. Foundation Models: What's the Difference?\\*\\* Many people use these terms interchangeably, but there's a subtle distinction worth understanding. \\*\\*\\*Base Models are pre-trained\\*\\*\\* AI models that haven't been fine-tuned for specific tasks. Think of them as raw, general-purpose models straight out of training‚Äîlike GPT-3 before any customization. \\*\\*\\*Foundation Models are large-scale base models\\*\\*\\* that serve as the \"foundation\" for multiple downstream applications. They're trained on vast, diverse datasets and can be adapted for various tasks‚Äîfrom chatbots to code generation to medical diagnosis. The key insight? All foundation models are base models, but not all base models qualify as foundation models. To be a foundation model, it needs scale, versatility, and the ability to power multiple use cases. Understanding this distinction helps us grasp how modern AI systems are built: start with a powerful foundation, then customize for your specific needs. [#ArtificialIntelligence](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fartificialintelligence&trk=public_post-text) [#MachineLearning](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fmachinelearning&trk=public_post-text) [#AI](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fai&trk=public_post-text) [#TechExplained](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Ftechexplained&trk=public_post-text) [#FoundationModels](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Ffoundationmodels&trk=public_post-text)\n\n  [Like](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fnidhi-bansal-54099a8_artificialintelligence-machinelearning-activity-7380551084324392960-bI7q&trk=public_post_like-cta)   [Comment](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fnidhi-bansal-54099a8_artificialintelligence-machinelearning-activity-7380551084324392960-bI7q&trk=public_post_comment-cta)\n\n  To view or add a comment, [sign in](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fnidhi-bansal-54099a8_artificialintelligence-machinelearning-activity-7380551084324392960-bI7q&trk=public_post_feed-cta-banner-cta)\n\n13,290 followers\n\n* [849 Posts](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww%2Elinkedin%2Ecom%2Fin%2Flucashendrich%2Frecent-activity%2F&trk=public_post_follow-posts)\n* [5 Articles](https://www.linkedin.com/today/author/lucashendrich?trk=public_post_follow-articles)\n\n[View Profile](https://www.linkedin.com/in/lucashendrich?trk=public_post_follow-view-profile)   [Follow](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww%2Elinkedin%2Ecom%2Ffeed%2Fupdate%2Furn%3Ali%3Aactivity%3A7301298120733196290&trk=public_post_follow)\n\n## More from this author\n\n* [### Product Thinking, Part 3: The Value Pattern\n\n  Lucas Hendrich   8y](https://www.linkedin.com/pulse/product-thinking-part-3-value-pattern-lucas-hendrich?trk=public_post)\n* [### Product Thinking, Part 2: Production\n\n  Lucas Hendrich   8y](https://www.linkedin.com/pulse/product-thinking-part-2-production-lucas-hendrich?trk=public_post)\n* [### Product Thinking, Part 1: Product vs. Project\n\n  Lucas Hendrich   8y](https://www.linkedin.com/pulse/product-thinking-part-1-vs-project-lucas-hendrich?trk=public_post)\n\n## Explore related topics\n\n* [How AI Models Are Trained for Reasoning Tasks](https://www.linkedin.com/top-content/artificial-intelligence/understanding-ai-systems/how-ai-models-are-trained-for-reasoning-tasks/)\n* [Importance of Inference in AI Success](https://www.linkedin.com/top-content/artificial-intelligence/understanding-ai-systems/importance-of-inference-in-ai-success/)\n* [How to Optimize Machine Learning Performance](https://www.linkedin.com/top-content/artificial-intelligence/machine-learning-model-tuning/how-to-optimize-machine-learning-performance/)\n* [Optimization Techniques for Artificial Intelligence](https://www.linkedin.com/top-content/artificial-intelligence/machine-learning-model-tuning/optimization-techniques-for-artificial-intelligence/)\n* [The Impact Of Data Quality On AI Model Performance](https://www.linkedin.com/top-content/artificial-intelligence/training-ai-models-with-limited-data/the-impact-of-data-quality-on-ai-model-performance/)\n* [Understanding Model Drift In Machine Learning Applications](https://www.linkedin.com/top-content/artificial-intelligence/machine-learning-models-for-predictive-analytics/understanding-model-drift-in-machine-learning-applications/)\n* [Understanding the End-to-End Machine Learning Process](https://www.linkedin.com/top-content/artificial-intelligence/understanding-ai-systems/understanding-the-end-to-end-machine-learning-process/)\n* [Overcoming Data Limitations In AI Model Development](https://www.linkedin.com/top-content/artificial-intelligence/training-ai-models-with-limited-data/overcoming-data-limitations-in-ai-model-development/)\n* [Best GPU Training Techniques](https://www.linkedin.com/top-content/artificial-intelligence/gpu-programming-insights/best-gpu-training-techniques/)\n* [Tips for Machine Learning Success](https://www.linkedin.com/top-content/artificial-intelligence/machine-learning-model-tuning/tips-for-machine-learning-success/)\n\n## Explore content categories\n\n* [Career](https://www.linkedin.com/top-content/career/)\n* [Productivity](https://www.linkedin.com/top-content/productivity/)\n* [Finance](https://www.linkedin.com/top-content/finance/)\n* [Soft Skills & Emotional Intelligence](https://www.linkedin.com/top-content/soft-skills-emotional-intelligence/)\n* [Project Management](https://www.linkedin.com/top-content/project-management/)\n* [Education](https://www.linkedin.com/top-content/education/)\n* [Technology](https://www.linkedin.com/top-content/technology/)\n* [Leadership](https://www.linkedin.com/top-content/leadership/)\n* [Ecommerce](https://www.linkedin.com/top-content/ecommerce/)\n* [User Experience](https://www.linkedin.com/top-content/user-experience/)\n\n## Sign in to view more content\n\nCreate your free account or sign in to continue your search\n\n## Welcome back\n\nBy clicking Continue to join or sign in, you agree to LinkedIn‚Äôs [User Agreement](/legal/user-agreement?trk=public_post_contextual-sign-in-modal_sign-in-modal_auth-button_user-agreement), [Privacy Policy](/legal/privacy-policy?trk=public_post_contextual-sign-in-modal_sign-in-modal_auth-button_privacy-policy), and [Cookie Policy](/legal/cookie-policy?trk=public_post_contextual-sign-in-modal_sign-in-modal_auth-button_cookie-policy).\n\nNew to LinkedIn? [Join now](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww%2Elinkedin%2Ecom%2Fposts%2Flucashendrich_ai-machinelearning-databricks-activity-7301298120733196290-wB_s&trk=public_post_contextual-sign-in-modal_sign-in-modal_join-link)\n\nor\n\nNew to LinkedIn? [Join now](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww%2Elinkedin%2Ecom%2Fposts%2Flucashendrich_ai-machinelearning-databricks-activity-7301298120733196290-wB_s&trk=public_post_contextual-sign-in-modal_join-link)\n\nBy clicking Continue to join or sign in, you agree to LinkedIn‚Äôs [User Agreement](/legal/user-agreement?trk=linkedin-tc_auth-button_user-agreement), [Privacy Policy](/legal/privacy-policy?trk=linkedin-tc_auth-button_privacy-policy), and [Cookie Policy](/legal/cookie-policy?trk=linkedin-tc_auth-button_cookie-policy).\n\nNever miss a beat on the app\n\nDon‚Äôt have the app? Get it in the Microsoft Store.\n\n [Open the app](ms-windows-store://pdp/?ProductId=9WZDNCRFJ4Q7&mode=mini&cid=guest_desktop_upsell_post2)\n\n "
    },
    {
      "url": "https://www.linkedin.com/posts/vsadhwani_if-youre-building-or-scaling-ai-systems-activity-7391151128039710721-jYf4",
      "title": "Choosing the right API protocol for AI systems",
      "content": "request/response patterns. 2. SOAP ‚Üí Enterprise-grade, schema-heavy, and XML-based. ‚Üí Rare in modern ML pipelines but still seen in regulated sectors ‚Äî finance, healthcare ‚Äî where strict data contracts and auditability matter. When to use: Legacy integrations or compliance-heavy AI systems that demand WSDL contracts. 3. gRPC ‚Üí Designed for speed and efficiency ‚Äî binary over HTTP/2, low latency, streaming supported. ‚Üí Ideal for real-time inference pipelines, model serving microservices, or cross-language communication (Python ‚Üî C++). ‚Üí For example: connecting an inference service written in Go with a data preprocessor in Python. When to use: High-performance internal APIs and microservice-to-microservice communication in AI infra. 4. GraphQL ‚Üí Shines in AI-powered dashboards or user [...] & scalability: handle large volumes of data 3) stability, complexity, control - libraries are evolving & experimenting -> APIs can be unstable - challenges to use Databricks products (managed services) 1) ùóôùóºùòÇùóªùó±ùóÆùòÅùó∂ùóºùóª ùó†ùóºùó±ùó≤ùóπ ùóîùó£ùóú - instant access to state-of-art LLMs - UNIFIED interface for deploying, governing, serving AI models 2) ùòÉùó≤ùó∞ùòÅùóºùóø ùòÄùó≤ùóÆùóøùó∞ùóµ (vector DB integrated with Lakehouse) - store VECTOR + METADATA on data inside UC (delta table, volume) - accessible via REST API / SDK 3) ùó†ùóüùó≥ùóπùóºùòÑ - Tracking Server: LOGGING pipelines during dev - Model Registry - Model Serving (deployment) - Evaluation 4) Lakehouse Monitoring ùóóùó≤ùó∫ùóº (using Databricks products & LangChain ùóüùóñùóòùóü ùòÄùòÜùóªùòÅùóÆùòÖ) 1) input: user question - response: answer + recommend youtube videos (based on CONTEXT from vector store) 2) code [...] If you‚Äôre building or scaling AI systems you should know these 6 API protocols and when to use each. In traditional systems, API choice was mostly about developer convenience. In the AI world, it‚Äôs about throughput, latency, and event flow. When your models, pipelines, and dashboards all need to talk to each other ~ the protocol becomes part of your architecture design. Here‚Äôs a breakdown : 1. REST ‚Üí Still the backbone of most public and internal APIs. ‚Üí Used to expose inference endpoints (think /predict or /classify) because it‚Äôs simple, stateless, and well supported across frameworks. ‚Üí Most AI service providers (OpenAI, Hugging Face, Vertex AI) still default to REST for ease of integration. When to use: Stable APIs with predictable request/response patterns. 2. SOAP ‚Üí Enterprise-grade,",
      "score": 0.38338786,
      "raw_content": "# Choosing the right API protocol for AI systems: REST, SOAP, gRPC, GraphQL, Webhooks, WebSockets\n\nThis title was summarized by AI from the post below.\n\n[Vishakha Sadhwani](https://www.linkedin.com/in/vsadhwani?trk=public_post_feed-actor-name)\n\nSr. Solutions Architect at Nvidia | Ex-Google, AWS | 100k+ Linkedin | EB1-A Recipient | Follow to explore your career path in Cloud | DevOps | \\*Opinions.. my own\\*\n\n* [Report this post](/uas/login?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fvsadhwani_if-youre-building-or-scaling-ai-systems-activity-7391151128039710721-jYf4&trk=public_post_ellipsis-menu-semaphore-sign-in-redirect&guestReportContentType=POST&_f=guest-reporting)\n\nIf you‚Äôre building or scaling AI systems you should know these 6 API protocols and when to use each. In traditional systems, API choice was mostly about developer convenience. In the AI world, it‚Äôs about throughput, latency, and event flow. When your models, pipelines, and dashboards all need to talk to each other ~ the protocol becomes part of your architecture design. Here‚Äôs a breakdown : 1. REST ‚Üí Still the backbone of most public and internal APIs. ‚Üí Used to expose inference endpoints (think /predict or /classify) because it‚Äôs simple, stateless, and well supported across frameworks. ‚Üí Most AI service providers (OpenAI, Hugging Face, Vertex AI) still default to REST for ease of integration. When to use: Stable APIs with predictable request/response patterns. 2. SOAP ‚Üí Enterprise-grade, schema-heavy, and XML-based. ‚Üí Rare in modern ML pipelines but still seen in regulated sectors ‚Äî finance, healthcare ‚Äî where strict data contracts and auditability matter. When to use: Legacy integrations or compliance-heavy AI systems that demand WSDL contracts. 3. gRPC ‚Üí Designed for speed and efficiency ‚Äî binary over HTTP/2, low latency, streaming supported. ‚Üí Ideal for real-time inference pipelines, model serving microservices, or cross-language communication (Python ‚Üî C++). ‚Üí For example: connecting an inference service written in Go with a data preprocessor in Python. When to use: High-performance internal APIs and microservice-to-microservice communication in AI infra. 4. GraphQL ‚Üí Shines in AI-powered dashboards or user personalization systems where the client defines the shape of data it needs. ‚Üí Works great for analytics UIs that query model performance metrics, experiment runs, or user recommendations in one call. When to use: Data-rich frontends or ML observability layers. 5. Webhooks ‚Üí Event-driven APIs ~ the silent backbone of MLOps automation. ‚Üí Used for model lifecycle events (model deployed, retrained, failed) or CI/CD triggers in AI pipelines. ‚Üí Example: A training job completes ‚Üí webhook notifies deployment service ‚Üí new model version goes live. When to use: Notifications, workflow chaining, and async triggers across your ML stack. 6. WebSockets ‚Üí Persistent connection between client and server ‚Äî perfect for real-time AI interactions. ‚Üí Think LLM chat interfaces, speech-to-text streams, or live inference feedback. ‚Üí Lets you stream responses token by token, instead of waiting for one big payload. When to use: Conversational AI, live dashboards, or streaming inference workloads. In AI architecture, the protocol layer is more than just a communication choice. So be ready to justify your choices:) Image Credits: ByteByteGo ‚Ä¢ ‚Ä¢ ‚Ä¢ If you found this useful: üîî Follow me ([Vishakha](https://www.linkedin.com/in/vsadhwani?trk=public_post-text)) for more Cloud & DevOps insights ‚ôªÔ∏è Share so others can learn too\n\n\n\n[257](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww%2Elinkedin%2Ecom%2Fposts%2Fvsadhwani_if-youre-building-or-scaling-ai-systems-activity-7391151128039710721-jYf4&trk=public_post_social-actions-reactions)   [23 Comments](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww%2Elinkedin%2Ecom%2Fposts%2Fvsadhwani_if-youre-building-or-scaling-ai-systems-activity-7391151128039710721-jYf4&trk=public_post_social-actions-comments)\n\n[Like](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww%2Elinkedin%2Ecom%2Fposts%2Fvsadhwani_if-youre-building-or-scaling-ai-systems-activity-7391151128039710721-jYf4&trk=public_post_like-cta)   [Comment](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww%2Elinkedin%2Ecom%2Fposts%2Fvsadhwani_if-youre-building-or-scaling-ai-systems-activity-7391151128039710721-jYf4&trk=public_post_comment-cta)\n\n[Mohammad Syed](https://www.linkedin.com/in/syedm3?trk=public_post_comment_actor-name) \n\nFounder & Principal Architect | AI/ML Architecture - AI Security - Cybersecurity | Securing AWS/Azure/GCP\n\n 1w \n\n* [Report this comment](/uas/login?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fvsadhwani_if-youre-building-or-scaling-ai-systems-activity-7391151128039710721-jYf4&trk=public_post_comment_ellipsis-menu-semaphore-sign-in-redirect&guestReportContentType=COMMENT&_f=guest-reporting)\n\n[Vishakha](https://www.linkedin.com/in/vsadhwani?trk=public_post_comment-text), Choosing the right API protocol is critical for robust and efficient AI architectures.\n\n[Like](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww%2Elinkedin%2Ecom%2Fposts%2Fvsadhwani_if-youre-building-or-scaling-ai-systems-activity-7391151128039710721-jYf4&trk=public_post_comment_like) [Reply](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww%2Elinkedin%2Ecom%2Fposts%2Fvsadhwani_if-youre-building-or-scaling-ai-systems-activity-7391151128039710721-jYf4&trk=public_post_comment_reply)  [2¬†Reactions](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww%2Elinkedin%2Ecom%2Fposts%2Fvsadhwani_if-youre-building-or-scaling-ai-systems-activity-7391151128039710721-jYf4&trk=public_post_comment_reactions)   3¬†Reactions\n\n[Sindhur Teja Dasari](https://in.linkedin.com/in/sindhur-teja-dasari-ab1b2a67?trk=public_post_comment_actor-name) \n\nConsultant @Genpact | AWS | Cloud Solutions | Kubernetes | IaC | AWS Certified Solutions Architect Associate\n\n 1w \n\n* [Report this comment](/uas/login?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fvsadhwani_if-youre-building-or-scaling-ai-systems-activity-7391151128039710721-jYf4&trk=public_post_comment_ellipsis-menu-semaphore-sign-in-redirect&guestReportContentType=COMMENT&_f=guest-reporting)\n\n[Vishakha Sadhwani](https://www.linkedin.com/in/vsadhwani?trk=public_post_comment-text) Those are some great Insights with cool diagrams to understand üëç Thanks for sharing üëç\n\n[Like](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww%2Elinkedin%2Ecom%2Fposts%2Fvsadhwani_if-youre-building-or-scaling-ai-systems-activity-7391151128039710721-jYf4&trk=public_post_comment_like) [Reply](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww%2Elinkedin%2Ecom%2Fposts%2Fvsadhwani_if-youre-building-or-scaling-ai-systems-activity-7391151128039710721-jYf4&trk=public_post_comment_reply)  [1¬†Reaction](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww%2Elinkedin%2Ecom%2Fposts%2Fvsadhwani_if-youre-building-or-scaling-ai-systems-activity-7391151128039710721-jYf4&trk=public_post_comment_reactions)   2¬†Reactions\n\n[Ana Pedra](https://ch.linkedin.com/in/anapedra?trk=public_post_comment_actor-name) \n\nAWSx13 ‚Ä¢ Azurex12 ‚Ä¢ GCPx7 ‚Ä¢ Red Hatx2 | Golden Kubestronaut üöÄ (CKA, CKAD, CKS, KCSA, KCNA) | AI Cloud DevSecOps Engineer @ Spitch | PMP | Terraform | Ansible | CI/CD | Prometheus | ArgoCD | Grafana | RHCSA | Sec+\n\n 1w \n\n* [Report this comment](/uas/login?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fvsadhwani_if-youre-building-or-scaling-ai-systems-activity-7391151128039710721-jYf4&trk=public_post_comment_ellipsis-menu-semaphore-sign-in-redirect&guestReportContentType=COMMENT&_f=guest-reporting)\n\nThis is one of the clearest summaries I‚Äôve seen on API protocols for AI systems. Love how you tied each protocol to real-world ML use cases, especially gRPC and WebSockets for streaming and low-latency inference\n\n[Like](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww%2Elinkedin%2Ecom%2Fposts%2Fvsadhwani_if-youre-building-or-scaling-ai-systems-activity-7391151128039710721-jYf4&trk=public_post_comment_like) [Reply](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww%2Elinkedin%2Ecom%2Fposts%2Fvsadhwani_if-youre-building-or-scaling-ai-systems-activity-7391151128039710721-jYf4&trk=public_post_comment_reply)  [1¬†Reaction](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww%2Elinkedin%2Ecom%2Fposts%2Fvsadhwani_if-youre-building-or-scaling-ai-systems-activity-7391151128039710721-jYf4&trk=public_post_comment_reactions)   2¬†Reactions\n\n[Dhanush Boopathi](https://in.linkedin.com/in/ab-dhanush?trk=public_post_comment_actor-name) \n\nAspiring Software Engineer | DevOps & Scalable Systems | System Optimization | Cloud & Big Data | Docker | Kubernetes | Git | CI/CD | Python | Java | IEEE Member | Vice President ‚Äì M.Tech CSE\n\n 1w \n\n* [Report this comment](/uas/login?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fvsadhwani_if-youre-building-or-scaling-ai-systems-activity-7391151128039710721-jYf4&trk=public_post_comment_ellipsis-menu-semaphore-sign-in-redirect&guestReportContentType=COMMENT&_f=guest-reporting)\n\nVery interesting insight\n\n[Like](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww%2Elinkedin%2Ecom%2Fposts%2Fvsadhwani_if-youre-building-or-scaling-ai-systems-activity-7391151128039710721-jYf4&trk=public_post_comment_like) [Reply](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww%2Elinkedin%2Ecom%2Fposts%2Fvsadhwani_if-youre-building-or-scaling-ai-systems-activity-7391151128039710721-jYf4&trk=public_post_comment_reply)  [1¬†Reaction](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww%2Elinkedin%2Ecom%2Fposts%2Fvsadhwani_if-youre-building-or-scaling-ai-systems-activity-7391151128039710721-jYf4&trk=public_post_comment_reactions)   2¬†Reactions\n\n[Dipin Kanojia](https://in.linkedin.com/in/dipin-kanojia?trk=public_post_comment_actor-name) \n\nAI Lead | Driving AI Solution | Product Strategy | NLP & Conversational AI | Building Intelligent, Ethical & Scalable AI Systems | MBA\n\n 1w \n\n* [Report this comment](/uas/login?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fvsadhwani_if-youre-building-or-scaling-ai-systems-activity-7391151128039710721-jYf4&trk=public_post_comment_ellipsis-menu-semaphore-sign-in-redirect&guestReportContentType=COMMENT&_f=guest-reporting)\n\nCompletely agree, [Vishakha](https://www.linkedin.com/in/vsadhwani?trk=public_post_comment-text)! protocol choice is architecture in AI systems.\n\n[Like](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww%2Elinkedin%2Ecom%2Fposts%2Fvsadhwani_if-youre-building-or-scaling-ai-systems-activity-7391151128039710721-jYf4&trk=public_post_comment_like) [Reply](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww%2Elinkedin%2Ecom%2Fposts%2Fvsadhwani_if-youre-building-or-scaling-ai-systems-activity-7391151128039710721-jYf4&trk=public_post_comment_reply)  [1¬†Reaction](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww%2Elinkedin%2Ecom%2Fposts%2Fvsadhwani_if-youre-building-or-scaling-ai-systems-activity-7391151128039710721-jYf4&trk=public_post_comment_reactions)   2¬†Reactions\n\n[Arshad Siddieque](https://in.linkedin.com/in/arshad-siddieque?trk=public_post_comment_actor-name) \n\nSenior DevSecOps Engineer | Simplifying DevSecOps, Cloud & AI | GenAI, MLOps, Kubernetes & AWS\n\n 1w \n\n* [Report this comment](/uas/login?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fvsadhwani_if-youre-building-or-scaling-ai-systems-activity-7391151128039710721-jYf4&trk=public_post_comment_ellipsis-menu-semaphore-sign-in-redirect&guestReportContentType=COMMENT&_f=guest-reporting)\n\nSpot on [Vishakha](https://www.linkedin.com/in/vsadhwani?trk=public_post_comment-text). REST still rules for simplicity, but as soon as streaming or cross-service communication enters the mix, gRPC and WebSockets become essential. Getting the protocol layer right early saves huge complexity later in infra.\n\n[Like](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww%2Elinkedin%2Ecom%2Fposts%2Fvsadhwani_if-youre-building-or-scaling-ai-systems-activity-7391151128039710721-jYf4&trk=public_post_comment_like) [Reply](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww%2Elinkedin%2Ecom%2Fposts%2Fvsadhwani_if-youre-building-or-scaling-ai-systems-activity-7391151128039710721-jYf4&trk=public_post_comment_reply)  [1¬†Reaction](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww%2Elinkedin%2Ecom%2Fposts%2Fvsadhwani_if-youre-building-or-scaling-ai-systems-activity-7391151128039710721-jYf4&trk=public_post_comment_reactions)   2¬†Reactions\n\n[Anton Martyniuk](https://ua.linkedin.com/in/anton-martyniuk?trk=public_post_comment_actor-name) \n\nHelping 60K+ Developers Improve .NET Skills and Craft Better Software | Microsoft MVP | Technical Lead\n\n 1w \n\n* [Report this comment](/uas/login?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fvsadhwani_if-youre-building-or-scaling-ai-systems-activity-7391151128039710721-jYf4&trk=public_post_comment_ellipsis-menu-semaphore-sign-in-redirect&guestReportContentType=COMMENT&_f=guest-reporting)\n\nNo matter what tech stack you use, the key to great systems is understanding why things work ‚Äî not just how to use them. Tools change fast, but solid design principles and clear communication between services will always stand the test of time.\n\n[Like](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww%2Elinkedin%2Ecom%2Fposts%2Fvsadhwani_if-youre-building-or-scaling-ai-systems-activity-7391151128039710721-jYf4&trk=public_post_comment_like) [Reply](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww%2Elinkedin%2Ecom%2Fposts%2Fvsadhwani_if-youre-building-or-scaling-ai-systems-activity-7391151128039710721-jYf4&trk=public_post_comment_reply)  [1¬†Reaction](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww%2Elinkedin%2Ecom%2Fposts%2Fvsadhwani_if-youre-building-or-scaling-ai-systems-activity-7391151128039710721-jYf4&trk=public_post_comment_reactions)   2¬†Reactions\n\n[Naveed Alam](https://pk.linkedin.com/in/naveed-alam-42b351375?trk=public_post_comment_actor-name) \n\nStudent at university of buner.\n\n 1w \n\n* [Report this comment](/uas/login?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fvsadhwani_if-youre-building-or-scaling-ai-systems-activity-7391151128039710721-jYf4&trk=public_post_comment_ellipsis-menu-semaphore-sign-in-redirect&guestReportContentType=COMMENT&_f=guest-reporting)\n\ngreat share\n\n[Like](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww%2Elinkedin%2Ecom%2Fposts%2Fvsadhwani_if-youre-building-or-scaling-ai-systems-activity-7391151128039710721-jYf4&trk=public_post_comment_like) [Reply](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww%2Elinkedin%2Ecom%2Fposts%2Fvsadhwani_if-youre-building-or-scaling-ai-systems-activity-7391151128039710721-jYf4&trk=public_post_comment_reply)  [1¬†Reaction](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww%2Elinkedin%2Ecom%2Fposts%2Fvsadhwani_if-youre-building-or-scaling-ai-systems-activity-7391151128039710721-jYf4&trk=public_post_comment_reactions)   2¬†Reactions\n\n[Gokul Thiagarajan](https://ae.linkedin.com/in/gokulthiagarajan?trk=public_post_comment_actor-name) \n\nLead Solution Architect | Cloud & Digital Banking Transformation | AWS, Azure, OCI | Program & Project Leadership (PMP, TOGAF)\n\n 1w \n\n* [Report this comment](/uas/login?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fvsadhwani_if-youre-building-or-scaling-ai-systems-activity-7391151128039710721-jYf4&trk=public_post_comment_ellipsis-menu-semaphore-sign-in-redirect&guestReportContentType=COMMENT&_f=guest-reporting)\n\nChoosing a protocol is really choosing how your system breathes.REST keeps it simple gRPC keeps it fast WebSockets keep it alive.The best setups blend them instead of betting on one. [Vishakha Sadhwani](https://www.linkedin.com/in/vsadhwani?trk=public_post_comment-text)\n\n[Like](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww%2Elinkedin%2Ecom%2Fposts%2Fvsadhwani_if-youre-building-or-scaling-ai-systems-activity-7391151128039710721-jYf4&trk=public_post_comment_like) [Reply](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww%2Elinkedin%2Ecom%2Fposts%2Fvsadhwani_if-youre-building-or-scaling-ai-systems-activity-7391151128039710721-jYf4&trk=public_post_comment_reply)  [1¬†Reaction](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww%2Elinkedin%2Ecom%2Fposts%2Fvsadhwani_if-youre-building-or-scaling-ai-systems-activity-7391151128039710721-jYf4&trk=public_post_comment_reactions)   2¬†Reactions\n\n[Muhammad Abdullah Abrar](https://pk.linkedin.com/in/muhammadabdullahabrar?trk=public_post_comment_actor-name) \n\nDevOps Engineer | Cloud Engineer | Deploying Scalable Production-ready Applications | CI/CD | Kubernetes | Python | Linux\n\n 1w \n\n* [Report this comment](/uas/login?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fvsadhwani_if-youre-building-or-scaling-ai-systems-activity-7391151128039710721-jYf4&trk=public_post_comment_ellipsis-menu-semaphore-sign-in-redirect&guestReportContentType=COMMENT&_f=guest-reporting)\n\nI have used 4 of these API Protocols, I think REST and Webhooks are widely used when you see how systems work. By the way, it was a great explanation.\n\n[Like](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww%2Elinkedin%2Ecom%2Fposts%2Fvsadhwani_if-youre-building-or-scaling-ai-systems-activity-7391151128039710721-jYf4&trk=public_post_comment_like) [Reply](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww%2Elinkedin%2Ecom%2Fposts%2Fvsadhwani_if-youre-building-or-scaling-ai-systems-activity-7391151128039710721-jYf4&trk=public_post_comment_reply)  [1¬†Reaction](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww%2Elinkedin%2Ecom%2Fposts%2Fvsadhwani_if-youre-building-or-scaling-ai-systems-activity-7391151128039710721-jYf4&trk=public_post_comment_reactions)   2¬†Reactions\n\n [See more comments](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww%2Elinkedin%2Ecom%2Fposts%2Fvsadhwani_if-youre-building-or-scaling-ai-systems-activity-7391151128039710721-jYf4&trk=public_post_see-more-comments) \n\nTo view or add a comment, [sign in](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww%2Elinkedin%2Ecom%2Fposts%2Fvsadhwani_if-youre-building-or-scaling-ai-systems-activity-7391151128039710721-jYf4&trk=public_post_feed-cta-banner-cta)\n\n## More Relevant Posts\n\n* [Anthony Alcaraz](https://fr.linkedin.com/in/anthony-alcaraz-b80763155?trk=public_post_feed-actor-name)\n\n  Senior AI/ML Strategist Startups @AWS | O‚ÄôReilly Author | Business Angel\n\n  + [Report this post](/uas/login?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fanthony-alcaraz-b80763155_most-ai-agents-fail-at-something-embarrassingly-activity-7391081012996239360-9qwX&trk=public_post_ellipsis-menu-semaphore-sign-in-redirect&guestReportContentType=POST&_f=guest-reporting)\n\n  Most AI agents fail at something embarrassingly simple. üí≠ Chaining 3 API calls together. NESTFUL benchmark shows even top models only achieve 41% success on nested API sequences. Here's the architectural reason why. The Two Orchestration Dimensions Internal orchestration = how agents organize reasoning. External orchestration = how agents execute in the world. AsyncThink solves internal orchestration with Fork-Join primitives. An organizer spawns concurrent workers (sub-query), then synchronizes results (). Learns optimal patterns through RL with rewards for accuracy + format compliance + concurrency. Result: 28% lower latency, 89% success vs 70% sequential. But internal reasoning ‚â† external execution. The core problem: probabilistic text generation vs deterministic API requirements. One syntax error breaks the chain. The Integration Architecture That Works Three layers solve this: üî∑ Knowledge graphs encode tool dependencies explicitly. Not just \"tools exist\" but \"Tool A's output type matches Tool B's input\" and \"CreateRequisition must precede CreatePurchaseOrder.\" üî∑ Declarative grammars constrain generation to valid formats. Context-free grammars (production-ready, sub-millisecond overhead) ensure syntactic correctness. LLM becomes an interpreter of formal specifications, not a free-form generator. üî∑ Runtime sandbox testing validates actual capabilities. Test components with 2-3 queries before selection, measuring real success rates vs trusting semantic similarity. This creates two-layer discovery: Semantic retrieval ‚Üí candidate operations Graph traversal ‚Üí dependencies + required sequences The Budget Optimization Problem Component selection is formally an online knapsack problem. You have N tools with costs c\\_i and unknown utilities v\\_i. Goal: maximize success within budget B. ZCL algorithm uses dynamic thresholds: Œ® = (U/L)^(BÃÇ/B) where BÃÇ = remaining budget. Achieved 60-97% cost reduction while maintaining performance. The Knapsack composer approach tested 120 tools across GAIA, SimpleQA, and MedQA benchmarks. Self-Evolution Across Both Dimensions The breakthrough: systems that modify their own capabilities. Knowledge graphs automatically extract missing mappings from execution failures ‚Üí generate RDF triples ‚Üí update via SPARQL INSERT ‚Üí subsequent queries leverage enriched knowledge. Ontology-based tool calling stores definitions IN the graph as queryable nodes. Domain experts add capabilities by inserting graph nodes, not writing code. System analyzes its own schema to suggest new tools. Why This Architecture Matters You're not choosing between workflows (predictable/rigid) and agents (flexible/unreliable). You're defining a behavioral envelope with formal structures while preserving adaptive capabilities within that envelope. The graph defines WHAT relationships exist. The grammar defines HOW to navigate them. The LLM interprets both in domain context.\n\n\n\n  [66](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fanthony-alcaraz-b80763155_most-ai-agents-fail-at-something-embarrassingly-activity-7391081012996239360-9qwX&trk=public_post_social-actions-reactions)   [25 Comments](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fanthony-alcaraz-b80763155_most-ai-agents-fail-at-something-embarrassingly-activity-7391081012996239360-9qwX&trk=public_post_social-actions-comments)\n\n  [Like](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fanthony-alcaraz-b80763155_most-ai-agents-fail-at-something-embarrassingly-activity-7391081012996239360-9qwX&trk=public_post_like-cta)   [Comment](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fanthony-alcaraz-b80763155_most-ai-agents-fail-at-something-embarrassingly-activity-7391081012996239360-9qwX&trk=public_post_comment-cta)\n\n  To view or add a comment, [sign in](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fanthony-alcaraz-b80763155_most-ai-agents-fail-at-something-embarrassingly-activity-7391081012996239360-9qwX&trk=public_post_feed-cta-banner-cta)\n* [Victor Donet Peris](https://es.linkedin.com/in/victor-donet-peris-%E2%9C%93-01629338/en?trk=public_post_feed-actor-name)\n\n  Data Engineer | Python, SQL, ETL, Cloud & Big Data | Data Pipelines & Analytics @ MB3gestion\n\n  + [Report this post](/uas/login?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fvictor-donet-peris-%25E2%259C%2593-01629338_building-real-world-ai-from-prototype-to-activity-7387377307943936000-Liov&trk=public_post_ellipsis-menu-semaphore-sign-in-redirect&guestReportContentType=POST&_f=guest-reporting)\n\n  Building Real-World AI: From Prototype to Production Artificial intelligence has become the buzzword of the decade. Every company wants to ‚Äúleverage AI,‚Äù but few manage to take it beyond the prototype phase. Between proof-of-concept demos and production-grade systems lies a gap that only engineering can bridge. 1. The Prototype Trap Most AI projects start strong: a promising model, a great dataset, and a motivated team. But when it‚Äôs time to deploy, reality hits ‚Äî the model doesn‚Äôt scale, the infrastructure is fragile, and the integration with existing systems is an afterthought. The real challenge isn‚Äôt training models. It‚Äôs turning models into maintainable, observable, and secure services that deliver consistent value. 2. Data Engineering Before Data Science No model can fix bad data. Clean, structured, and versioned data is the foundation of every successful AI system. Technologies like Airflow, Azure Data Factory, and Data Vault 2.0 allow teams to build reliable pipelines with proper lineage and auditing. Once the data ecosystem is healthy, model development becomes predictable instead of chaotic. 3. API-Driven AI Architecture The best AI models are invisible ‚Äî users interact with them through APIs, not dashboards. Modern frameworks like FastAPI, Flask, or Django REST Framework make it simple to expose models as services, while secure authentication (using OAuth2, JWT, or IAM) ensures they can be safely integrated across microservices or third-party systems. An AI model that can‚Äôt be consumed by others is just a local experiment. 4. Automation and Observability Deploying AI in production requires a DevOps mindset. CI/CD pipelines, containerization with Docker, and continuous monitoring aren‚Äôt ‚Äúnice-to-haves‚Äù; they‚Äôre survival tools. Observability ‚Äî logging, metrics, and tracing ‚Äî helps catch performance degradation and data drift before users notice. In production, AI doesn‚Äôt just predict ‚Äî it evolves. 5. Human Context, Always Technology alone isn‚Äôt intelligence. The best systems are those that augment human decision-making rather than replace it. In sectors like education, energy, or logistics, the most successful AI projects I‚Äôve seen were those designed around people ‚Äî their workflows, limitations, and goals. --- Conclusion Building real-world AI is not about stacking models; it‚Äôs about engineering trust, scalability, and clarity. Frameworks like LangChain, OpenAI APIs, and cloud ecosystems such as Azure or AWS have made the technology accessible. But the differentiator is still craftsmanship: how well we combine algorithms, data, and infrastructure into something that simply works ‚Äî day after day, at scale.\n\n  [1](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fvictor-donet-peris-%25E2%259C%2593-01629338_building-real-world-ai-from-prototype-to-activity-7387377307943936000-Liov&trk=public_post_social-actions-reactions)\n\n  [Like](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fvictor-donet-peris-%25E2%259C%2593-01629338_building-real-world-ai-from-prototype-to-activity-7387377307943936000-Liov&trk=public_post_like-cta)   [Comment](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fvictor-donet-peris-%25E2%259C%2593-01629338_building-real-world-ai-from-prototype-to-activity-7387377307943936000-Liov&trk=public_post_comment-cta)\n\n  To view or add a comment, [sign in](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fvictor-donet-peris-%25E2%259C%2593-01629338_building-real-world-ai-from-prototype-to-activity-7387377307943936000-Liov&trk=public_post_feed-cta-banner-cta)\n* [Ben Sam Oladoyin](https://ng.linkedin.com/in/ben-sam-oladoyin-527966233?trk=public_post_feed-actor-name)\n\n  Founder @ BTEHub Solutions || AI Solutions Architect || Chatbot Developer || AI Automation Agency (AAA) Builder || Trainer & Mentor || Live Audio Engineer\n\n  + [Report this post](/uas/login?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fben-sam-oladoyin-527966233_jsonprompting-ai-automation-activity-7392985512929751040-v6z1&trk=public_post_ellipsis-menu-semaphore-sign-in-redirect&guestReportContentType=POST&_f=guest-reporting)\n\n  üöÄ JSON Prompting Series ‚Äî Episode 7 ‚ÄúBuilding JSON Prompt Chains with Conditional Logic‚Äù Welcome back, Visionaries üëã You‚Äôve learned how to chain multiple JSON prompts together ‚Äî but what if you want your AI workflow to think, decide, and act based on context? That‚Äôs where conditional logic comes in. Conditional logic allows your AI prompts to follow ‚Äúif this ‚Üí then that‚Äù decisions, making your system smarter, adaptive, and automation-ready. üîπ What Is Conditional Logic in JSON Prompting? It‚Äôs simply embedding rules and conditions inside your JSON so the next action depends on data or user input. Example üëá { \"user\\_request\": \"Book a session\", \"conditions\": { \"if\\_intent\": \"book\\_session\", \"then\\_action\": \"collect\\_user\\_info\", \"else\\_action\": \"show\\_main\\_menu\" } } Here, if the detected intent equals \"book\\_session\", the system moves to collect user info. Otherwise, it redirects to the main menu. ‚öôÔ∏è Example: Smart Chatbot Flow üß© Step 1 ‚Äî Detect Intent { \"intent\": \"pricing\\_inquiry\", \"confidence\": 0.92 } üß© Step 2 ‚Äî Apply Logic { \"conditions\": { \"if\\_confidence\\_above\": 0.8, \"then\\_action\": \"show\\_pricing\", \"else\\_action\": \"ask\\_for\\_clarification\" } } üß© Step 3 ‚Äî Execute Decision { \"next\\_action\": \"show\\_pricing\", \"response\": \"Our AI Automation packages start at ‚Ç¶150,000, depending on project scope.\" } The AI checks the condition (confidence > 0.8)before deciding which JSON prompt chain to trigger next. üí° Where This Shines ‚úÖ AI Automation Agents: Handling complex decision trees. ‚úÖ Chatbots: Understanding user intent with fallback routes. ‚úÖ Workflows: Switching between tasks based on conditions (e.g., data thresholds, user type, or context). üß∞ Bonus Tip: Use logic\\_blocks for Complex Decisions If your workflow has multiple conditions, group them into logic blocks üëá { \"logic\\_blocks\": [ { \"condition\": \"user\\_type == 'new'\", \"action\": \"send\\_welcome\\_message\" }, { \"condition\": \"user\\_type == 'returning'\", \"action\": \"offer\\_loyalty\\_discount\" } ] } This structure scales beautifully for automation pipelines or chatbots that need to handle diverse user states. ‚úÖ In Episode 8, we‚Äôll go deeper into ‚ÄúIntegrating JSON Prompt Chains into Real AI Systems‚Äù ‚Äî connecting them with tools like LangChain, Make, Zapier, or APIs. üëâ If you could add one condition to your AI workflow today, what would it control? ‚Äî BTEHub Team [#JSONPrompting](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fjsonprompting&trk=public_post-text) [#AI](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fai&trk=public_post-text) [#Automation](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fautomation&trk=public_post-text) [#BTEHub](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fbtehub&trk=public_post-text)\n\n\n\n  [2](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fben-sam-oladoyin-527966233_jsonprompting-ai-automation-activity-7392985512929751040-v6z1&trk=public_post_social-actions-reactions)\n\n  [Like](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fben-sam-oladoyin-527966233_jsonprompting-ai-automation-activity-7392985512929751040-v6z1&trk=public_post_like-cta)   [Comment](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fben-sam-oladoyin-527966233_jsonprompting-ai-automation-activity-7392985512929751040-v6z1&trk=public_post_comment-cta)\n\n  To view or add a comment, [sign in](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fben-sam-oladoyin-527966233_jsonprompting-ai-automation-activity-7392985512929751040-v6z1&trk=public_post_feed-cta-banner-cta)\n* [Bobby Meindl](https://www.linkedin.com/in/bobby-meindl-905325193?trk=public_post_feed-actor-name)\n\n  Account Executive @ Elastic\n\n  + [Report this post](/uas/login?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fbobby-meindl-905325193_elastic-ai-agent-builder-for-context-engineering-activity-7386430616591835136-CO71&trk=public_post_ellipsis-menu-semaphore-sign-in-redirect&guestReportContentType=POST&_f=guest-reporting)\n\n  The hardest part of building AI agents isn't the large language model‚Äîit's providing the right context. Every enterprise is racing to deploy AI agents, yet many face a common challenge: managing messy internal data and ensuring agents deliver accurate, reliable answers. We have launched the Elastic AI Agent Builder (currently in tech preview) to address this issue. What sets it apart: ‚úì Instant chat with your data ‚Äì No setup required. Ask questions across all your Elasticsearch data immediately. ‚úì Built-in intelligence ‚Äì Agents automatically locate the right indexes, comprehend data structure, and optimize queries for relevance. ‚úì Custom tools & agents ‚Äì Create precise ES|QL queries for business logic and define agents with specific personas and security profiles. ‚úì Universal integration ‚Äì Full API support along with native MCP and A2A, allowing connections to any framework or application. Built on Elasticsearch's established search relevance and vector database capabilities, Agent Builder provides the context engineering foundation enterprises need for production-ready AI agents. Ready to advance beyond basic retrieval-augmented generation? Try it free with an Elastic Cloud trial. [#AI](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fai&trk=public_post-text) [#AIAgents](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Faiagents&trk=public_post-text) [#Elasticsearch](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Felasticsearch&trk=public_post-text) [#ContextEngineering](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fcontextengineering&trk=public_post-text) [#EnterpriseAI](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fenterpriseai&trk=public_post-text) [https://lnkd.in/eeJZ-YKp](https://www.linkedin.com/redir/redirect?url=https%3A%2F%2Flnkd%2Ein%2FeeJZ-YKp&urlhash=JoxN&trk=public_post-text)\n\n  [Elastic AI Agent Builder for context engineering - Elasticsearch Labs   elastic.co](https://www.linkedin.com/redir/redirect?url=https%3A%2F%2Fwww%2Eelastic%2Eco%2Fsearch-labs%2Fblog%2Felastic-ai-agent-builder-context-engineering-introduction&urlhash=ccEB&trk=public_post_feed-article-content)\n\n  [20](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fbobby-meindl-905325193_elastic-ai-agent-builder-for-context-engineering-activity-7386430616591835136-CO71&trk=public_post_social-actions-reactions)\n\n  [Like](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fbobby-meindl-905325193_elastic-ai-agent-builder-for-context-engineering-activity-7386430616591835136-CO71&trk=public_post_like-cta)   [Comment](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fbobby-meindl-905325193_elastic-ai-agent-builder-for-context-engineering-activity-7386430616591835136-CO71&trk=public_post_comment-cta)\n\n  To view or add a comment, [sign in](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fbobby-meindl-905325193_elastic-ai-agent-builder-for-context-engineering-activity-7386430616591835136-CO71&trk=public_post_feed-cta-banner-cta)\n* [Jaskirat Singh](https://in.linkedin.com/in/jaskiratai?trk=public_post_feed-actor-name)\n\n  AI for ALL | Data Scientist @Great Learning | Ex AI Engineer @avkalan.ai | Gdg Speaker l Agentic AI | Cloud (Azure/GCP)| Exploring how AI can make businesses more productive | 400K+ impressions | Open to Opportunities.\n\n  + [Report this post](/uas/login?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fjaskiratai_openai-agentkit-n8n-activity-7384120885584158720-zvsA&trk=public_post_ellipsis-menu-semaphore-sign-in-redirect&guestReportContentType=POST&_f=guest-reporting)\n\n  Everyone is asking the same question this week: Is [OpenAI](https://www.linkedin.com/company/openai?trk=public_post-text)‚Äôs new AgentKit better than [n8n](https://de.linkedin.com/company/n8n?trk=public_post-text)? ü§Øü§Ø Let‚Äôs break it down clearly. ‚úÖ 1. Core Purpose üí° n8n is an automation platform. ‚Üí It connects APIs, databases, and web apps to run workflows. ‚Üí It‚Äôs about execution, not intelligence. AgentKit is a reasoning framework. ‚Üí It‚Äôs about creating AI agents that can plan, decide, and act. ‚Üí If n8n is a switchboard, AgentKit is a brain factory. ‚úÖ 2. Architecture üí° n8n runs deterministic workflows ‚Äî every step is predefined. ‚Üí When X happens, do Y. ‚Üí Simple, predictable, linear. AgentKit is dynamic. ‚Üí Each ‚Äúnode‚Äù can be an autonomous agent powered by an LLM. ‚Üí Agents can call tools, evaluate outcomes, or even create sub-agents. ‚ÜíIt‚Äôs not linear‚Äîit‚Äôs adaptive. ‚úÖ 3. UI and Experience n8n‚Äôs UI is a visual workflow builder. ‚Üí You drag blocks like ‚ÄúHTTP Request ‚Üí Filter ‚Üí Database Insert.‚Äù ‚Üí It‚Äôs ideal for backend automation or business logic. AgentKit‚Äôs interface looks more like a control center. ‚Üí You define behaviors, version prompts, add safety layers, and monitor live reasoning traces. ‚Üí It‚Äôs designed for AI engineers, not operations teams. ‚úÖ 4. Evaluation & Learning n8n executes. If something breaks, you fix it manually. ‚Üí No feedback loop. AgentKit learns. ‚Üí It includes built-in evaluation datasets, grading, and reinforcement fine-tuning. ‚Üí Agents can improve reasoning over time. ‚úÖ 5. Integrations n8n connects to hundreds of apps‚ÄîSlack, Notion, Google Sheets, MySQL, anything REST. ‚Üí It wins on breadth. AgentKit focuses on depth. ‚Üí It integrates securely within OpenAI‚Äôs ecosystem‚ÄîChatGPT, OpenAI API, Teams, Enterprise setups. ‚Üí Quality and governance > quantity. ‚úÖ 6. Use Cases Use n8n if you want: ‚Üí Notifications, CRMs, database syncs, ETL tasks, backend automations. Use AgentKit if you want: ‚ÜíAgents that classify, reason, search, respond, and adapt. Example: üí°n8n = ‚ÄúWhen a new row is added to Google Sheets, send it to Slack.‚Äù üí°AgentKit = ‚ÄúWhen a user submits a support ticket, analyze intent, search docs, and draft a context-aware response.‚Äù ‚úÖ 7. Deployment n8n runs anywhere‚Äîyour own server, Docker, or cloud. ‚Üí It uses a standard [Node.js](http://Node.js?trk=public_post-text) runtime. AgentKit runs directly on OpenAI‚Äôs infrastructure. ‚Üí It integrates with Guardrails, the Agents SDK, and the Workflows API. ‚Üí You can embed live agents directly into your products through ChatKit. ‚Üí Final Verdict üéØIf your world is automation, n8n wins. üéØIf your world is intelligence, AgentKit dominates. ‚úÖn8n is for control. ‚úÖAgentKit is for cognition. Both will coexist‚Äîbut AgentKit signals where the future of software is heading. ‚ôªÔ∏è If you find it useful repost it in your network. Try it here: [https://n8n.io/](https://www.linkedin.com/redir/redirect?url=https%3A%2F%2Fn8n%2Eio%2F&urlhash=tqRc&trk=public_post-text) [https://lnkd.in/geH-NK8D](https://www.linkedin.com/redir/redirect?url=https%3A%2F%2Flnkd%2Ein%2FgeH-NK8D&urlhash=F12J&trk=public_post-text) [#OpenAI](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fopenai&trk=public_post-text) [#AgentKit](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fagentkit&trk=public_post-text) [#n8n](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fn8n&trk=public_post-text) [#Automation](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fautomation&trk=public_post-text) [#AIWorkflows](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Faiworkflows&trk=public_post-text) [#ArtificialIntelligence](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fartificialintelligence&trk=public_post-text) [#AIAgents](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Faiagents&trk=public_post-text) [#MachineLearning](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fmachinelearning&trk=public_post-text) [#TechInnovation](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Ftechinnovation&trk=public_post-text) [#SoftwareEngineering](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fsoftwareengineering&trk=public_post-text) [#AITools](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Faitools&trk=public_post-text) [#FutureOfWork](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Ffutureofwork&trk=public_post-text)\n\n\n\n  [25](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fjaskiratai_openai-agentkit-n8n-activity-7384120885584158720-zvsA&trk=public_post_social-actions-reactions)\n\n  [Like](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fjaskiratai_openai-agentkit-n8n-activity-7384120885584158720-zvsA&trk=public_post_like-cta)   [Comment](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fjaskiratai_openai-agentkit-n8n-activity-7384120885584158720-zvsA&trk=public_post_comment-cta)\n\n  To view or add a comment, [sign in](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fjaskiratai_openai-agentkit-n8n-activity-7384120885584158720-zvsA&trk=public_post_feed-cta-banner-cta)\n* [Shalini Goyal](https://uk.linkedin.com/in/goyalshalini?trk=public_post_feed-actor-name)\n\n  Engineering and AI Leader | Ex-Amazon, JP Morgan || Speaker, Author || TechWomen100 Award Finalist\n\n  + [Report this post](/uas/login?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fgoyalshalini_this-stack-brings-together-powerful-tools-activity-7391814428129648640-c7E3&trk=public_post_ellipsis-menu-semaphore-sign-in-redirect&guestReportContentType=POST&_f=guest-reporting)\n\n  This stack brings together powerful tools to transform raw data into context-rich intelligence. It integrates ingestion pipelines, embeddings, retrieval, and vector databases into one cohesive system. By layering these components with LLM frameworks and models, it enables scalable, trustworthy, and production-ready AI applications - turning data into meaningful, actionable outputs. Here‚Äôs how the stack comes together: - Ingest & Data Processing Kubeflow, Apache Airflow, Apache Nifi, LangChain loaders, Haystack pipelines, and OpenSearch handle data pipelines. - Retrieval & Ranking Elasticsearch, Weaviate, FAISS, JinaAI rerankers, and Haystack retrievers fetch and prioritize the most relevant context. - Embedding Models HuggingFace Transformers, Sentence Transformers, JinaAI, Cognita, Nomic, and LLMWare turn text into searchable vectors. - Vector Databases Milvus, Weaviate, PgVector, Chroma, and Qdrant store embeddings with speed and scale. - LLM Frameworks LangChain, Haystack, CrewAI, HuggingFace, and LlamaIndex orchestrate intelligent workflows and tool integration. - LLMs Models like LLaMA, Mistral, Phi-2, DeepSeek, Qwen, and Gemma power reasoning and response generation. - Frontend Frameworks NextJS, Streamlit, VueJS, and SvelteKit enable user-friendly, interactive AI experiences. The Open Source RAG Stack is the foundation behind smarter, scalable, and trustworthy AI systems. What would you add to this stack? Share with me in the comments.\n\n\n\n  [480](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fgoyalshalini_this-stack-brings-together-powerful-tools-activity-7391814428129648640-c7E3&trk=public_post_social-actions-reactions)   [41 Comments](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fgoyalshalini_this-stack-brings-together-powerful-tools-activity-7391814428129648640-c7E3&trk=public_post_social-actions-comments)\n\n  [Like](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fgoyalshalini_this-stack-brings-together-powerful-tools-activity-7391814428129648640-c7E3&trk=public_post_like-cta)   [Comment](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fgoyalshalini_this-stack-brings-together-powerful-tools-activity-7391814428129648640-c7E3&trk=public_post_comment-cta)\n\n  To view or add a comment, [sign in](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fgoyalshalini_this-stack-brings-together-powerful-tools-activity-7391814428129648640-c7E3&trk=public_post_feed-cta-banner-cta)\n* [Sai Sneha Chittiboyina](https://www.linkedin.com/in/sai-sneha-chittiboyina-478a5b2b7?trk=public_post_feed-actor-name)\n\n  Senior Big Data Engineer @Cigna Health | Azure-AWS & GCP Services | Snowflake | DataBricks-AWS |Informatica | Snowpipe | Python | SQL | Epic | Kafka | Palantir | Healthcare Data Expert |GENAI|RAG|LLMs|Langchain\n\n  + [Report this post](/uas/login?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fsai-sneha-chittiboyina-478a5b2b7_apacheflink-flinkagents-eventdrivenai-activity-7388609356138721280-L3C7&trk=public_post_ellipsis-menu-semaphore-sign-in-redirect&guestReportContentType=POST&_f=guest-reporting)\n\n  üöÄ Exciting times ahead for real-time, event-driven AI! I‚Äôm thrilled to highlight the recent announcement of Flink Agents ‚Äî a new sub-project of Apache Flink designed to build intelligent, autonomous agents within a streaming data framework. Here‚Äôs why this matters: üîç What is Flink Agents? Flink Agents is an open-source framework (proposal FLIP-531) that brings native support to build, test, and run AI agents within Flink‚Äôs runtime. Rather than just handling batch or prompt-driven AI, this framework empowers long-running, event-triggered agents that operate on live, streaming data. üìà Why now? Enterprise-AI Infrastructure Gap Traditional AI work often focuses on ‚Äúask a chatbot‚Äù or ‚Äúrun a batch model‚Äù. But many business challenges demand continuous, real-time decisioning (fraud detection, supply-chain alerts, real-time personalization). Building such agents today requires stitching together multiple tools (streaming engine + model inference + orchestration + state store). Flink Agents aims to unify this into a single runtime. The vision: every engineer becomes an ‚ÄúAI‚Äêengineer‚Äù ‚Äî using familiar stream APIs in Java or Python to build autonomous agents. üß† Key differentiators Event‚Äênative: Agents trigger on business events, not just prompts. Stateful memory: Flink‚Äôs state backend gives agents ‚Äúmemory‚Äù across streams of events. Replay ability & audit: Because agents operate on streams, you can replay events, test new logic, shadow launch, audit decisions. Native integrations: Using Flink‚Äôs APIs (DataStream/Table), plus connectors, model inference, tool invocation via protocols such as Model Context Protocol (MCP). üéØ For practitioners in data engineering & real-time analytics (that‚Äôs us!) If you‚Äôre working with streaming, event-driven architectures, LLMs or agentic AI workflows ‚Äî this is a framework worth watching. For those of us building scalable, fault-tolerant data-pipelines and real-time decision systems (especially in healthcare, retail, IoT) this offers a new paradigm: embed intelligence in the stream. Given my focus on Azure/Cloud, data engineering, AI/ML, building pipelines, microservices and real‚Äêtime analytics Flink Agents intersects strongly with these trends. üôå Final thought As organizations move from ‚Äúmodels‚Äù to ‚Äúagents‚Äù, the infrastructure to support that shift matters more than ever. Flink Agents is a leap in that direction enabling real-time, always-on, contextual intelligence embedded in your streaming backbone. I‚Äôm looking forward to seeing how the community adopts and extends this, and keen to explore how we might apply it in our projects. [#ApacheFlink](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fapacheflink&trk=public_post-text) [#FlinkAgents](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fflinkagents&trk=public_post-text) [#EventDrivenAI](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Feventdrivenai&trk=public_post-text) [#Streaming](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fstreaming&trk=public_post-text) [#RealTimeAnalytics](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Frealtimeanalytics&trk=public_post-text) [#DataEngineering](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fdataengineering&trk=public_post-text) [#AIEnablingInfrastructure](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Faienablinginfrastructure&trk=public_post-text)\n\n  [8](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fsai-sneha-chittiboyina-478a5b2b7_apacheflink-flinkagents-eventdrivenai-activity-7388609356138721280-L3C7&trk=public_post_social-actions-reactions)\n\n  [Like](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fsai-sneha-chittiboyina-478a5b2b7_apacheflink-flinkagents-eventdrivenai-activity-7388609356138721280-L3C7&trk=public_post_like-cta)   [Comment](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fsai-sneha-chittiboyina-478a5b2b7_apacheflink-flinkagents-eventdrivenai-activity-7388609356138721280-L3C7&trk=public_post_comment-cta)\n\n  To view or add a comment, [sign in](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fsai-sneha-chittiboyina-478a5b2b7_apacheflink-flinkagents-eventdrivenai-activity-7388609356138721280-L3C7&trk=public_post_feed-cta-banner-cta)\n* [Andrey Alekseenko](https://ua.linkedin.com/in/andreyalekseenko?trk=public_post_feed-actor-name)\n\n  Business Technology Consultant\n\n  + [Report this post](/uas/login?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fandreyalekseenko_cloud-cmdb-ai-activity-7383396738037866496-E5Sv&trk=public_post_ellipsis-menu-semaphore-sign-in-redirect&guestReportContentType=POST&_f=guest-reporting)\n\n  üß† AI-Powered CMDB Internal Operations Algorithm ( [https://lnkd.in/eS3KSe63](https://www.linkedin.com/redir/redirect?url=https%3A%2F%2Flnkd%2Ein%2FeS3KSe63&urlhash=Qsf4&trk=public_post-text) ) ü§ñ Stage 1: Data Ingestion & Enrichment ¬†üö® Problem: The Hidden Failure Point in Hybrid [#Cloud](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fcloud&trk=public_post-text) Migrations. It‚Äôs not the infrastructure‚Äîit‚Äôs the¬†stale, fragmented data¬†polluting your [#CMDB](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fcmdb&trk=public_post-text). Manual processes can‚Äôt keep pace with assets flowing from AWS, Azure, and on-prem simultaneously. ¬† ¬†üí° Stage 1 ‚Äì Data Ingestion & Enrichment ¬†Engine ingests all sources‚Äîincluding the ones most teams ignore:¬†unstructured data. [#AI](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fai&trk=public_post-text) Role: NLP-Powered CI Extraction The engine uses [#NaturalLanguageProcessing](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fnaturallanguageprocessing&trk=public_post-text) to extract key [#CI](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fci&trk=public_post-text) attributes (hostname, owner, IP) directly from human-entered change tickets. Goal: Attribute Normalization Structured or unstructured‚Äîevery attribute is instantly standardized and mapped across cloud and on-prem platforms. ¬† üõ†Ô∏è Component-Level Overview ¬†A. Structured Discovery Feeds Definition: Machine-generated reports from cloud platforms (AWS, Azure, GCP) and on-prem tools (SCCM, Tanium) that detail newly provisioned resources‚ÄîVMs, storage volumes, network services, and updated inventory lists. Characteristics: -Highly structured -Schema-aligned -Timestamped and auto-refreshed Strategic [#Value](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fvalue&trk=public_post-text): Provides reliable, scalable ingestion of infrastructure changes‚Äîideal for automated CI creation. ¬† B. [#ChangeManagement](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fchangemanagement&trk=public_post-text) Tickets Definition: Human-authored tickets linked to migration activities. These contain rich, descriptive text about new assets, configuration changes, and operational context‚Äîbut lack consistent formatting. Characteristics: -Semi-structured to unstructured -Freeform language, abbreviations, and embedded metadata -Often the only source of context for edge-case assets Strategic Value: Unlocks hidden CI data via [#NLP](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fnlp&trk=public_post-text)‚Äîcritical for completeness and context enrichment. ¬†C. AI Enrichment & Normalization Engine Definition: The AI/ [#ML](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fml&trk=public_post-text) engine serves as the real-time intelligence layer. It ingests both structured and unstructured inputs, applies NLP and entity extraction, and normalizes attributes for CMDB readiness. Core Functions: -NLP-based parsing of tickets and emails -Attribute standardization across platforms -Confidence scoring and relationship inference Strategic Value: Transforms fragmented inputs into unified, enriched CI records‚Äîready for automation, analysis, and governance. ¬† üìâ Impact [#Metrics](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fmetrics&trk=public_post-text) This process eliminates the biggest headaches in asset management: ¬†[#Data](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fdata&trk=public_post-text) Freshness:¬†Real-Time Updates ¬†Accuracy:¬†100% Asset Coverage ¬†Effort:¬†Zero Manual Entry This is Stage 1. Five more to go. Follow for the full breakdown. ¬© [https://lnkd.in/e4N88hP5](https://www.linkedin.com/redir/redirect?url=https%3A%2F%2Flnkd%2Ein%2Fe4N88hP5&urlhash=K1LD&trk=public_post-text)\n\n\n\n  [54](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fandreyalekseenko_cloud-cmdb-ai-activity-7383396738037866496-E5Sv&trk=public_post_social-actions-reactions)   [6 Comments](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fandreyalekseenko_cloud-cmdb-ai-activity-7383396738037866496-E5Sv&trk=public_post_social-actions-comments)\n\n  [Like](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fandreyalekseenko_cloud-cmdb-ai-activity-7383396738037866496-E5Sv&trk=public_post_like-cta)   [Comment](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fandreyalekseenko_cloud-cmdb-ai-activity-7383396738037866496-E5Sv&trk=public_post_comment-cta)\n\n  To view or add a comment, [sign in](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fandreyalekseenko_cloud-cmdb-ai-activity-7383396738037866496-E5Sv&trk=public_post_feed-cta-banner-cta)\n* [Ashwin Joshi](https://www.linkedin.com/in/ashjoresume?trk=public_post_feed-actor-name)\n\n  Applied AI | Building AI Solutions | MLOps | Cloud-Native DevOps | Network Automation Solutions Expert | ex-Microsoft, ex-Amazon\n\n  + [Report this post](/uas/login?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fashjoresume_100daysoflearninggenai-activity-7392649249748000768-_XTY&trk=public_post_ellipsis-menu-semaphore-sign-in-redirect&guestReportContentType=POST&_f=guest-reporting)\n\n  [#100DaysOfLearningGenAI](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2F100daysoflearninggenai&trk=public_post-text) - Day 79¬† - üî• JSON is Over-Costly in the LLM Era: Why TOON is the New Standard for AI Data Transfer The speed and cost of Large Language Model (LLM) applications are fundamentally tied to one metric: Token Count. As developers, we lean on JSON‚Äîit's the universal language of APIs and databases. But when passing application data to an LLM's system prompt, the traditional JSON format is an unoptimized, token-wasting bottleneck. The shift is here: We need to adopt TOON (Token-Oriented Object Notation) to maximize efficiency in our AI workflows. The Unseen Cost of JSON in Your Prompts: Every character you send to an LLM‚Äîcurly braces, double quotes, commas, and white space‚Äîconsumes a token, which directly impacts latency and API costs. JSON's verbose syntax, while ideal for programmatic parsing, is an \"over-kill\" for LLMs. When we serialize a complex JSON object and pass it as a raw string inside a system prompt, we are paying for pure overhead. The Solution: Introducing TOON TOON is an emerging data format specifically engineered for passing structured data to LLMs. It borrows the best features of established formats to create a highly optimized structure: > YAML Indentation: Ensures superior human readability for debugging, logging, and observability. > CSV Tabular Format: Provides clean, uniform data rows, making the structure immediately clear to an LLM. The Impact: 30-60% Token Savings & Increased Speed The core value of TOON is tangible: token efficiency. By stripping away unnecessary JSON syntax, TOON can reduce your input token count by 30% to 60% on average. Token Usage (Example Benchmark) Traditional JSON - 15,000 Tokens Simple YAML - 13,000 Tokens TOON- 8,700 Tokens (Significant Reduction) This reduction isn't just a saving on your API bill; it translates directly to faster LLM response times because the model processes a significantly smaller input payload. üí° Expert Insight: Mastering the Flattening Rule While TOON is a powerful solution, it requires an important optimization step for developers to avoid a hidden performance trap: TOON performs optimally only with flat data structures. If you attempt to encode highly nested JSON directly into TOON, you can actually end up using more tokens than the original JSON. The Best Practice for High-Efficiency AI Pipelines: > Flatten your JSON: Before sending data to the LLM, programmatically flatten your nested JSON objects (e.g., converting a nested address object into flat fields like address\\_street, address\\_city). > Encode to TOON: Convert the now-flat data structure into TOON format. Send to LLM: Pass the highly optimized TOON payload to the system prompt. By mastering this flattening technique, we can ensure that we are always sending the most compact, human-readable, and cost-efficient data to our LLMs, marking a key evolution in the AI application development lifecycle.\n\n  [5](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fashjoresume_100daysoflearninggenai-activity-7392649249748000768-_XTY&trk=public_post_social-actions-reactions)   [3 Comments](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fashjoresume_100daysoflearninggenai-activity-7392649249748000768-_XTY&trk=public_post_social-actions-comments)\n\n  [Like](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fashjoresume_100daysoflearninggenai-activity-7392649249748000768-_XTY&trk=public_post_like-cta)   [Comment](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fashjoresume_100daysoflearninggenai-activity-7392649249748000768-_XTY&trk=public_post_comment-cta)\n\n  To view or add a comment, [sign in](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fashjoresume_100daysoflearninggenai-activity-7392649249748000768-_XTY&trk=public_post_feed-cta-banner-cta)\n* [arun sundar sundararajan](https://in.linkedin.com/in/arun-sundar-sundararajan-2b30b917a?trk=public_post_feed-actor-name)\n\n  Gen AI Enthusiast | Data Engineer | Fabric Certified | Databricks Certified | AWS Certified | PySpark | Ex-CGI | Ex-Cognizant | BE CSE @ GCT Coimbatore\n\n  + [Report this post](/uas/login?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Farun-sundar-sundararajan-2b30b917a_databricks-langchain-llm-activity-7385583079492354048--SIt&trk=public_post_ellipsis-menu-semaphore-sign-in-redirect&guestReportContentType=POST&_f=guest-reporting)\n\n  ùó∫ùòÇùóπùòÅùó∂-ùòÄùòÅùóÆùó¥ùó≤ ùóøùó≤ùóÆùòÄùóºùóªùó∂ùóªùó¥ Gen AI ùóîùóΩùóΩùòÄ using LangChain in Databricks Gen AI Apps not only retrieve & synthesize info, but can also ùó•ùóòùóîùó¶ùó¢ùó° it building & managing multi-stage Apps require - composition frameworks - TOOLS (vector store, model serving) from platforms like Databricks dev steps - build each component (retriever, tools) - combine components into ùó∞ùóµùóÆùó∂ùóªùòÄ - combine chains into multi-stage AI system ùó∞ùóºùó∫ùóΩùóºùòÄùó∂ùòÅùó∂ùóºùóª ùó≥ùóøùóÆùó∫ùó≤ùòÑùóºùóøùó∏ùòÄ 1) types - composition: LangChain, LlamaIndex, Haystack, DSPy - agents: AutoGPT, AutoGen, LangChain-agents 2) each has different focus, opinions, best ways to solve different problems ùóüùóÆùóªùó¥ùóñùóµùóÆùó∂ùóª 1) ùóºùóøùó∞ùóµùó≤ùòÄùòÅùóøùóÆùòÅùó∂ùóºùóª framework to build Apps using LLMs, Tools, Agents, Chains - extend LLM to be context-aware, reason, interact with external env - provide ùòÄùòÅùóøùòÇùó∞ùòÅùòÇùóøùó≤ to create reusable workflow 2) provide building blocks - prompt: structure input & guide LLM (ùóΩùóøùóºùó∫ùóΩùòÅ ùó≤ùóªùó¥ùó∂ùóªùó≤ùó≤ùóøùó∂ùóªùó¥) - chain: connect prompt, tools, LLM together to control FLOW of data - ùóøùó≤ùòÅùóøùó∂ùó≤ùòÉùó≤ùóø: connect LLM with EXTERNAL data stores (wikipedia, vector store) - ùòÅùóºùóºùóπùòÄ: FUNCTIONS to connect LLM with EXTERNAL systems (APIs, DBs) ùóüùóπùóÆùó∫ùóÆùóúùóªùó±ùó≤ùòÖ - ùó±ùóÆùòÅùóÆ ùó≥ùóøùóÆùó∫ùó≤ùòÑùóºùóøùó∏ for creating data-to-LLM pipeline - ingestion, ùó∂ùóªùó±ùó≤ùòÖùó∂ùóªùó¥ (structuring), querying (retrieval + response synthesis) - components: indexes, engines (query, retriever) ùóóùó¶ùó£ùòÜ can generate best prompts DYNAMICALLY ùó≥ùóÆùó∞ùòÅùóºùóøùòÄ to consider choosing framework 1) library features (eg: LLM interfaces, integrations with external systems) 2) performance & scalability: handle large volumes of data 3) stability, complexity, control - libraries are evolving & experimenting -> APIs can be unstable - challenges to use Databricks products (managed services) 1) ùóôùóºùòÇùóªùó±ùóÆùòÅùó∂ùóºùóª ùó†ùóºùó±ùó≤ùóπ ùóîùó£ùóú - instant access to state-of-art LLMs - UNIFIED interface for deploying, governing, serving AI models 2) ùòÉùó≤ùó∞ùòÅùóºùóø ùòÄùó≤ùóÆùóøùó∞ùóµ (vector DB integrated with Lakehouse) - store VECTOR + METADATA on data inside UC (delta table, volume) - accessible via REST API / SDK 3) ùó†ùóüùó≥ùóπùóºùòÑ - Tracking Server: LOGGING pipelines during dev - Model Registry - Model Serving (deployment) - Evaluation 4) Lakehouse Monitoring ùóóùó≤ùó∫ùóº (using Databricks products & LangChain ùóüùóñùóòùóü ùòÄùòÜùóªùòÅùóÆùòÖ) 1) input: user question - response: answer + recommend youtube videos (based on CONTEXT from vector store) 2) code qa\\_chain = ({\"question\": RunnablePassthrough()} | prompt\\_template | llm) retriever\\_chain = RunnableLambda(ùòÄùó≤ùóÆùóøùó∞ùóµùó©ùó≤ùó∞ùòÅùóºùóøùó¶ùòÅùóºùóøùó≤) yt\\_chain = RunnableLambda(ùòÄùó≤ùóÆùóøùó∞ùóµùó¨ùóºùòÇùóßùòÇùóØùó≤) combine\\_chain = prompt\\_template2 | llm multi\\_chain = {\"answer\": qa\\_chain, \"ùó∞ùóºùóªùòÅùó≤ùòÖùòÅ\": retriever\\_chain} | ([RunnablePassthrough.assign](http://RunnablePassthrough.assign?trk=public_post-text)(videos=itemgetter(\"context\") | yt\\_chain)) | combine\\_chain multi\\_chain.ùó∂ùóªùòÉùóºùó∏ùó≤(question) ùóøùó≤ùó≥ùó≤ùóøùó≤ùóªùó∞ùó≤: databricks-academy [#databricks](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fdatabricks&trk=public_post-text) [#langchain](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Flangchain&trk=public_post-text) [#llm](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fllm&trk=public_post-text)\n\n\n\n  [Like](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Farun-sundar-sundararajan-2b30b917a_databricks-langchain-llm-activity-7385583079492354048--SIt&trk=public_post_like-cta)   [Comment](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Farun-sundar-sundararajan-2b30b917a_databricks-langchain-llm-activity-7385583079492354048--SIt&trk=public_post_comment-cta)\n\n  To view or add a comment, [sign in](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Farun-sundar-sundararajan-2b30b917a_databricks-langchain-llm-activity-7385583079492354048--SIt&trk=public_post_feed-cta-banner-cta)\n\n116,265 followers\n\n* [401 Posts](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww%2Elinkedin%2Ecom%2Fin%2Fvsadhwani%2Frecent-activity%2F&trk=public_post_follow-posts)\n\n[View Profile](https://www.linkedin.com/in/vsadhwani?trk=public_post_follow-view-profile)   [Connect](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww%2Elinkedin%2Ecom%2Ffeed%2Fupdate%2Furn%3Ali%3Aactivity%3A7391151128039710721&trk=public_post_follow)\n\n## Explore content categories\n\n* [Career](https://www.linkedin.com/top-content/career/)\n* [Productivity](https://www.linkedin.com/top-content/productivity/)\n* [Finance](https://www.linkedin.com/top-content/finance/)\n* [Soft Skills & Emotional Intelligence](https://www.linkedin.com/top-content/soft-skills-emotional-intelligence/)\n* [Project Management](https://www.linkedin.com/top-content/project-management/)\n* [Education](https://www.linkedin.com/top-content/education/)\n* [Technology](https://www.linkedin.com/top-content/technology/)\n* [Leadership](https://www.linkedin.com/top-content/leadership/)\n* [Ecommerce](https://www.linkedin.com/top-content/ecommerce/)\n* [User Experience](https://www.linkedin.com/top-content/user-experience/)\n\n## Sign in to view more content\n\nCreate your free account or sign in to continue your search\n\n## Welcome back\n\nBy clicking Continue to join or sign in, you agree to LinkedIn‚Äôs [User Agreement](/legal/user-agreement?trk=public_post_contextual-sign-in-modal_sign-in-modal_auth-button_user-agreement), [Privacy Policy](/legal/privacy-policy?trk=public_post_contextual-sign-in-modal_sign-in-modal_auth-button_privacy-policy), and [Cookie Policy](/legal/cookie-policy?trk=public_post_contextual-sign-in-modal_sign-in-modal_auth-button_cookie-policy).\n\nNew to LinkedIn? [Join now](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww%2Elinkedin%2Ecom%2Fposts%2Fvsadhwani_if-youre-building-or-scaling-ai-systems-activity-7391151128039710721-jYf4&trk=public_post_contextual-sign-in-modal_sign-in-modal_join-link)\n\nor\n\nNew to LinkedIn? [Join now](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww%2Elinkedin%2Ecom%2Fposts%2Fvsadhwani_if-youre-building-or-scaling-ai-systems-activity-7391151128039710721-jYf4&trk=public_post_contextual-sign-in-modal_join-link)\n\nBy clicking Continue to join or sign in, you agree to LinkedIn‚Äôs [User Agreement](/legal/user-agreement?trk=linkedin-tc_auth-button_user-agreement), [Privacy Policy](/legal/privacy-policy?trk=linkedin-tc_auth-button_privacy-policy), and [Cookie Policy](/legal/cookie-policy?trk=linkedin-tc_auth-button_cookie-policy).\n\nNever miss a beat on the app\n\nDon‚Äôt have the app? Get it in the Microsoft Store.\n\n [Open the app](ms-windows-store://pdp/?ProductId=9WZDNCRFJ4Q7&mode=mini&cid=guest_desktop_upsell_post2)\n\n "
    },
    {
      "url": "https://www.linkedin.com/posts/johnidouglas_kserve-models-format-activity-7386028135768539136-ARti",
      "title": "Deploying Models with KServe: A Scalable Solution",
      "content": "## LinkedIn respects your privacy\n\nLinkedIn and 3rd parties use essential and non-essential cookies to provide, secure, analyze and improve our Services, and to show you relevant ads (including professional and job ads) on and off LinkedIn. Learn more in our Cookie Policy.\n\nSelect Accept to consent or Reject to decline non-essential cookies for this use. You can update your choices at any time in your settings.\n\n# Deploying Models with KServe: A Scalable Solution\n\nThis title was summarized by AI from the post below.\n\nJohni Douglas Marangon\n\nSenior Backend Engineer | Python Expert | Django - FastAPI - Flask | GenAI (LLMs, RAGs) | GCP | Scalable Systems | 17+ YOE\n\n Report this post [...] 28\n\n  Like   Comment\n\n  To view or add a comment, sign in\n Vedavyas Viswanatham\n\n  Software Development Intern @ Parabola9 | BTech in Computer Science | IIITN CSE‚Äô25 | AI/ML Enthusiast | Tech Nerd\n\n  + Report this post [...] In short: uv = speed + simplicity conda = power + stability Big thanks to AI/ML creators like Krish Naik, CampusX, Codebasics, Marina Wyss for making complex AI and Python concepts easier to learn and apply. #Python #GenerativeAI #LangChain #FastAPI #pip #uv #MachineLearning",
      "score": 0.38151965,
      "raw_content": "## LinkedIn respects your privacy\n\nLinkedIn and 3rd parties use essential and non-essential cookies to provide, secure, analyze and improve our Services, and to show you relevant ads (including **professional and job ads**) on and off LinkedIn. Learn more in our [Cookie Policy](https://www.linkedin.com/legal/cookie-policy).\n\nSelect Accept to consent or Reject to decline non-essential cookies for this use. You can update your choices at any time in your [settings](https://www.linkedin.com/mypreferences/g/guest-cookies).\n\n\n\n\n# Deploying Models with KServe: A Scalable Solution\n\nThis title was summarized by AI from the post below.\n\n[Johni Douglas Marangon](https://br.linkedin.com/in/johnidouglas?trk=public_post_feed-actor-name)\n\nSenior Backend Engineer | Python Expert | Django - FastAPI - Flask | GenAI (LLMs, RAGs) | GCP | Scalable Systems | 17+ YOE\n\n* [Report this post](/uas/login?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fjohnidouglas_kserve-models-format-activity-7386028135768539136-ARti&trk=public_post_ellipsis-menu-semaphore-sign-in-redirect&guestReportContentType=POST&_f=guest-reporting)\n\nüöÄ Exploring Model Deployment Options: From FastAPI + Celery to KServe Recently, my team and I explored KServe, and I was really impressed with its capabilities for scalable and production-grade model serving. Our models are trained using spaCy, scikit-learn, Transformers + ONNX. In the end, we decided to go with a FastAPI + Celery (RabbitMQ) solution since we currently manage only four models. However, as our number of models grows, we plan to migrate to KServe for better scalability and management. I‚Äôve also shared a short gist summarizing some key points on how to use KServe to deploy models üëá üîó [https://lnkd.in/dVd7X3Bs](https://www.linkedin.com/redir/redirect?url=https%3A%2F%2Flnkd%2Ein%2FdVd7X3Bs&urlhash=ewpl&trk=public_post-text) [#KServe](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fkserve&trk=public_post-text) [#FastAPI](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Ffastapi&trk=public_post-text) [#Celery](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fcelery&trk=public_post-text) [#RabbitMQ](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Frabbitmq&trk=public_post-text) [#Python](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fpython&trk=public_post-text) [#OracleACEProgram](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Foracleaceprogram&trk=public_post-text) [#OracleACE](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Foracleace&trk=public_post-text)\n\n[KServe Models Format   gist.github.com](https://www.linkedin.com/redir/redirect?url=https%3A%2F%2Fgist%2Egithub%2Ecom%2Fjohnidm%2F27d9a642e3c67c8721459c0ab5197437&urlhash=Q4PN&trk=public_post_feed-article-content)\n\n[7](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww%2Elinkedin%2Ecom%2Fposts%2Fjohnidouglas_kserve-models-format-activity-7386028135768539136-ARti&trk=public_post_social-actions-reactions)\n\n[Like](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww%2Elinkedin%2Ecom%2Fposts%2Fjohnidouglas_kserve-models-format-activity-7386028135768539136-ARti&trk=public_post_like-cta)   [Comment](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww%2Elinkedin%2Ecom%2Fposts%2Fjohnidouglas_kserve-models-format-activity-7386028135768539136-ARti&trk=public_post_comment-cta)\n\nTo view or add a comment, [sign in](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww%2Elinkedin%2Ecom%2Fposts%2Fjohnidouglas_kserve-models-format-activity-7386028135768539136-ARti&trk=public_post_feed-cta-banner-cta)\n\n## More Relevant Posts\n\n* [Atharva Chavhan](https://in.linkedin.com/in/atharva-chavhan-b5742b259?trk=public_post_feed-actor-name)\n\n  Startup Enthusiast | Python developer | AIML | Flask | MySQL | MongoDB\n\n  + [Report this post](/uas/login?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fatharva-chavhan-b5742b259_deeplearning-ai-machinelearning-activity-7386627803791888384-5CJS&trk=public_post_ellipsis-menu-semaphore-sign-in-redirect&guestReportContentType=POST&_f=guest-reporting)\n\n  Excited to share my latest Deep Learning project! Project: CIFAR-10 ResNet18 Image Recognition Tech Stack: Python | Flask | PyTorch | TorchVision | HTML | CSS | JS I built a real-time image classification system using a pre-trained ResNet18 model that can recognize images from the CIFAR-10 dataset directly in your browser! Key Highlights: üîπ Real-time prediction using ResNet18 üîπ Upload & preview images instantly in the browser üîπ Displays 10 detailed insights about each predicted class üîπ Beautiful gradient-based responsive UI üîπ Modular & extensible architecture üîπ Built with Flask (backend) and HTML/CSS/JS (frontend) Future Enhancements: Add support for all CIFAR-10 classes Deploy on AWS / Heroku Add drag-and-drop uploads & confidence scores This project helped me deepen my understanding of deep learning, computer vision, and model deployment using Flask. [#DeepLearning](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fdeeplearning&trk=public_post-text) [#AI](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fai&trk=public_post-text) [#MachineLearning](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fmachinelearning&trk=public_post-text) [#Flask](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fflask&trk=public_post-text) [#PyTorch](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fpytorch&trk=public_post-text) [#ComputerVision](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fcomputervision&trk=public_post-text) [#Python](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fpython&trk=public_post-text) [#ImageRecognition](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fimagerecognition&trk=public_post-text) [#WebApp](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fwebapp&trk=public_post-text) [#ResNet](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fresnet&trk=public_post-text) [#CIFAR10](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fcifar10&trk=public_post-text) [#AtharvaChavhan](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fatharvachavhan&trk=public_post-text)\n\n  [44](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fatharva-chavhan-b5742b259_deeplearning-ai-machinelearning-activity-7386627803791888384-5CJS&trk=public_post_social-actions-reactions)   [4 Comments](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fatharva-chavhan-b5742b259_deeplearning-ai-machinelearning-activity-7386627803791888384-5CJS&trk=public_post_social-actions-comments)\n\n  [Like](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fatharva-chavhan-b5742b259_deeplearning-ai-machinelearning-activity-7386627803791888384-5CJS&trk=public_post_like-cta)   [Comment](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fatharva-chavhan-b5742b259_deeplearning-ai-machinelearning-activity-7386627803791888384-5CJS&trk=public_post_comment-cta)\n\n  To view or add a comment, [sign in](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fatharva-chavhan-b5742b259_deeplearning-ai-machinelearning-activity-7386627803791888384-5CJS&trk=public_post_feed-cta-banner-cta)\n* [Jimi Vaubien](https://ch.linkedin.com/in/jimi-vaubien?trk=public_post_feed-actor-name)\n\n  üèÑüèΩ‚ôÇÔ∏è Surfing the AI wave üé• YT @bitswired üßëüèΩüíªbitswired.com/blog | AI Engineer\n\n  + [Report this post](/uas/login?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fjimi-vaubien_python-ai-agi-activity-7385963190750298113-AXoY&trk=public_post_ellipsis-menu-semaphore-sign-in-redirect&guestReportContentType=POST&_f=guest-reporting)\n\n  FastEmbed is an amazing library for text embedding: light, support GPU, many diffrent kind of models Most embedding libraries force you to download GBs of PyTorch dependencies. FastEmbed? It uses ONNX Runtime instead. ùóßùóµùó≤ ùóøùó≤ùòÄùòÇùóπùòÅ üëâüèΩ Lighter than your average Python library üëâüèΩ No GPU needed (but supports it if you want) üëâüèΩ Faster than PyTorch for inference üëâüèΩ Perfect for serverless (hello AWS Lambda) üëâüèΩ Has a Rust version ùó™ùóµùóÆùòÅ ùó∫ùóÆùó∏ùó≤ùòÄ ùó∂ùòÅ ùó∞ùóºùóºùóπ FastEmbed supports: - Sense embeddings - Sparse embeddings (SPLADE++) - Late interaction models (ColBERT) - Image embeddings, - Even rerankers. All with the same clean API. The default model (Flag Embedding) sits at the top of the MTEB leaderboard and supports \"query\" and \"passage\" prefixes out of the box. Getting started takes 3 lines. The library handles model downloads automatically, uses data parallelism for large datasets, and keeps memory usage minimal. ùóïùó≤ùòÜùóºùóªùó± ùòÅùó≤ùòÖùòÅ Need image embeddings? ColBERT for retrieval? Reranking? FastEmbed has you covered. You can even extend it with custom models not in their supported list. If you're building RAG apps or vector search, this library deserves a look. It's maintained by Qdrant and gets regular updates. Have you tried FastEmbed yet? [#python](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fpython&trk=public_post-text) [#ai](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fai&trk=public_post-text) [#agi](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fagi&trk=public_post-text) [#rag](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Frag&trk=public_post-text) [#opensource](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fopensource&trk=public_post-text)\n\n\n\n  [56](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fjimi-vaubien_python-ai-agi-activity-7385963190750298113-AXoY&trk=public_post_social-actions-reactions)   [11 Comments](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fjimi-vaubien_python-ai-agi-activity-7385963190750298113-AXoY&trk=public_post_social-actions-comments)\n\n  [Like](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fjimi-vaubien_python-ai-agi-activity-7385963190750298113-AXoY&trk=public_post_like-cta)   [Comment](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fjimi-vaubien_python-ai-agi-activity-7385963190750298113-AXoY&trk=public_post_comment-cta)\n\n  To view or add a comment, [sign in](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fjimi-vaubien_python-ai-agi-activity-7385963190750298113-AXoY&trk=public_post_feed-cta-banner-cta)\n* [Nick Mitselos](https://gr.linkedin.com/in/mitselos?trk=public_post_feed-actor-name)\n\n  Frontend Developer\n\n  + [Report this post](/uas/login?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fmitselos_ai-mcp-python-activity-7388286324849426432-7Y4t&trk=public_post_ellipsis-menu-semaphore-sign-in-redirect&guestReportContentType=POST&_f=guest-reporting)\n\n  MCP server - and it's way cooler than I expected.. Model Context Protocol lets you give AI custom superpowers by writing simple Python functions. Server has 3 tools: ¬†- Web search (Tavily API) ¬†- Dice roller (because why not) ¬†- Instagram post fetcher (RapidAPI) The wild part? Each tool is literally just a function with [@mcp.tool](http://@mcp.tool?trk=public_post-text)() on top. That's it. Then hooked it up to LangGraph to build an AI agent that can use all three tools together. GitHub:[https://lnkd.in/dMiMENK5](https://www.linkedin.com/redir/redirect?url=https%3A%2F%2Flnkd%2Ein%2FdMiMENK5&urlhash=2otx&trk=public_post-text) Want to extend Claude or GPT with your own APIs? MCP is the move. Of course..naturally [AI Makerspace](https://www.linkedin.com/company/ai-maker-space?trk=public_post-text) is where experimentation like this thrives!! ¬†[#AI](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fai&trk=public_post-text) [#MCP](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fmcp&trk=public_post-text) [#Python](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fpython&trk=public_post-text) [#AIEngineering](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Faiengineering&trk=public_post-text)\n\n  [13](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fmitselos_ai-mcp-python-activity-7388286324849426432-7Y4t&trk=public_post_social-actions-reactions)   [1 Comment](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fmitselos_ai-mcp-python-activity-7388286324849426432-7Y4t&trk=public_post_social-actions-comments)\n\n  [Like](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fmitselos_ai-mcp-python-activity-7388286324849426432-7Y4t&trk=public_post_like-cta)   [Comment](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fmitselos_ai-mcp-python-activity-7388286324849426432-7Y4t&trk=public_post_comment-cta)\n\n  To view or add a comment, [sign in](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fmitselos_ai-mcp-python-activity-7388286324849426432-7Y4t&trk=public_post_feed-cta-banner-cta)\n* [Eric Fithian](https://www.linkedin.com/in/ericbfithian?trk=public_post_feed-actor-name)\n\n  AI Researcher | Research Professional @ UChicago Center for Applied AI\n\n  + [Report this post](/uas/login?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fericbfithian_delm-activity-7386798057893457920-VM_t&trk=public_post_ellipsis-menu-semaphore-sign-in-redirect&guestReportContentType=POST&_f=guest-reporting)\n\n  I‚Äôm excited to share DELM, a Python toolkit for Data Extraction with Language Models. If you‚Äôve ever tried using LLMs for information extraction, such as pulling market sentiment from earnings calls, parsing clinical notes for symptoms, or scanning materials science papers for new compounds, you‚Äôve probably hit the same frustrations I have. Building reliable extraction pipelines with LLMs turns out to be way harder than it looks. Ad hoc scripts break when APIs fail, waste tokens on redundant calls, produce inconsistent results, and make it nearly impossible to compare different approaches systematically. Together with [Kirill Skobelev](https://www.linkedin.com/in/skobelevkirill?trk=public_post-text) at the [Center for Applied Artificial Intelligence at Chicago Booth](https://www.linkedin.com/showcase/center-for-applied-artificial-intelligence-at-chicago-booth-/?trk=public_post-text) , we built DELM to fix that. It takes care of caching, custom extraction schemas, cost tracking, and flexible splitting and scoring strategies, so you can focus on more interesting stuff. Make your life easier with¬†'pip install delm'! arXiv preprint:¬†[https://lnkd.in/g-GxkjM3](https://www.linkedin.com/redir/redirect?url=https%3A%2F%2Flnkd%2Ein%2Fg-GxkjM3&urlhash=_t9o&trk=public_post-text) GitHub:¬†[https://lnkd.in/g-GzJ44b](https://www.linkedin.com/redir/redirect?url=https%3A%2F%2Flnkd%2Ein%2Fg-GzJ44b&urlhash=YpdA&trk=public_post-text) Docs:¬†[https://lnkd.in/ggJFTiSV](https://www.linkedin.com/redir/redirect?url=https%3A%2F%2Flnkd%2Ein%2FggJFTiSV&urlhash=zOxm&trk=public_post-text)\n\n  [DELM ¬∂   center-for-applied-ai.github.io](https://www.linkedin.com/redir/redirect?url=https%3A%2F%2Fcenter-for-applied-ai%2Egithub%2Eio%2Fdelm%2F&urlhash=gOBa&trk=public_post_feed-article-content)\n\n  [23](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fericbfithian_delm-activity-7386798057893457920-VM_t&trk=public_post_social-actions-reactions)\n\n  [Like](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fericbfithian_delm-activity-7386798057893457920-VM_t&trk=public_post_like-cta)   [Comment](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fericbfithian_delm-activity-7386798057893457920-VM_t&trk=public_post_comment-cta)\n\n  To view or add a comment, [sign in](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fericbfithian_delm-activity-7386798057893457920-VM_t&trk=public_post_feed-cta-banner-cta)\n* [Shadmehr Radmanesh](https://ca.linkedin.com/in/shadmehr-radmanesh-207505279?trk=public_post_feed-actor-name)\n\n  AI Inventor & Innovator | Co-founder at Universe AI and Maple Ai | International Achievements in AI\n\n  + [Report this post](/uas/login?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fshadmehr-radmanesh-207505279_silent-model-killer-activity-7390547948541173760-NyX-&trk=public_post_ellipsis-menu-semaphore-sign-in-redirect&guestReportContentType=POST&_f=guest-reporting)\n\n  99% accuracy in test, but 50% in production? You might have a \"Silent Model Killer\".¬† The problem? Data Leakage.¬† It's a subtle but dangerous mistake often made during preprocessing. If you use StandardScaler before train\\_test\\_split, you are \"cheating\" by leaking test set information into your training process.¬† I‚Äôve attached a quick guide showing the wrong way, the right way, and the professional fix using Pipeline.¬† Stop leaks, build trustworthy models. [#MachineLearning](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fmachinelearning&trk=public_post-text) [#Python](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fpython&trk=public_post-text) [#DataScience](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fdatascience&trk=public_post-text) [#DataLeakage](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fdataleakage&trk=public_post-text) [#ScikitLearn](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fscikitlearn&trk=public_post-text) [#AI](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fai&trk=public_post-text) [#MLOps](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fmlops&trk=public_post-text) [#Developer](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fdeveloper&trk=public_post-text)\n\n  [7](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fshadmehr-radmanesh-207505279_silent-model-killer-activity-7390547948541173760-NyX-&trk=public_post_social-actions-reactions)\n\n  [Like](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fshadmehr-radmanesh-207505279_silent-model-killer-activity-7390547948541173760-NyX-&trk=public_post_like-cta)   [Comment](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fshadmehr-radmanesh-207505279_silent-model-killer-activity-7390547948541173760-NyX-&trk=public_post_comment-cta)\n\n  To view or add a comment, [sign in](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fshadmehr-radmanesh-207505279_silent-model-killer-activity-7390547948541173760-NyX-&trk=public_post_feed-cta-banner-cta)\n* [Jayanthan Muralidharan](https://in.linkedin.com/in/jayanthan-muralidharan-8449771a0?trk=public_post_feed-actor-name)\n\n  Senior AI and automation Developer | Gen AI Agents | Python | C# | Azure | Microsoft Power Platform ( Power Automate , Power Apps , Power BI and Copilot agents ). RPA/ API / Hyper Automations\n\n  + [Report this post](/uas/login?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fjayanthan-muralidharan-8449771a0_ai-automation-python-activity-7388007488853483520-Cth8&trk=public_post_ellipsis-menu-semaphore-sign-in-redirect&guestReportContentType=POST&_f=guest-reporting)\n\n  ü§ñ Project DIA - I Prototype üé¨ I was all set to watch a series on Netflix‚Ä¶ but then the developer brain kicked in. One random thought turned into, ‚ÄúWhat if I build something that could actually help in back-office operations?‚Äù So instead of watching a series, I ended up creating a mini AI powerhouse. This tool can extract thousands of data points directly from documents into Excel simply by providing a prompt. You define the fields, and it auto-generates columns and fills the data ‚Äî all powered by Python, LangChain, Azure Form Recogniser, GPT-4.1, and Streamlit for the UI. Four hours later, I had a working prototype‚Ä¶ and honestly, that was way more satisfying than finishing a Netflix series. üòÑ [#AI](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fai&trk=public_post-text) [#Automation](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fautomation&trk=public_post-text) [#Python](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fpython&trk=public_post-text) [#LangChain](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Flangchain&trk=public_post-text) [#Azure](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fazure&trk=public_post-text) [#GPT4](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fgpt4&trk=public_post-text) .1#Streamlit [#Innovation](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Finnovation&trk=public_post-text) [#DataAutomation](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fdataautomation&trk=public_post-text) [#kbs](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fkbs&trk=public_post-text) [#kone](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fkone&trk=public_post-text) [#genai](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fgenai&trk=public_post-text)\n\n  [32](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fjayanthan-muralidharan-8449771a0_ai-automation-python-activity-7388007488853483520-Cth8&trk=public_post_social-actions-reactions)   [2 Comments](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fjayanthan-muralidharan-8449771a0_ai-automation-python-activity-7388007488853483520-Cth8&trk=public_post_social-actions-comments)\n\n  [Like](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fjayanthan-muralidharan-8449771a0_ai-automation-python-activity-7388007488853483520-Cth8&trk=public_post_like-cta)   [Comment](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fjayanthan-muralidharan-8449771a0_ai-automation-python-activity-7388007488853483520-Cth8&trk=public_post_comment-cta)\n\n  To view or add a comment, [sign in](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fjayanthan-muralidharan-8449771a0_ai-automation-python-activity-7388007488853483520-Cth8&trk=public_post_feed-cta-banner-cta)\n* [Mohammed Al Hashim](https://sa.linkedin.com/in/mohammed-al-hashim-9b12641a5?trk=public_post_feed-actor-name)\n\n  üí°AI & Data Science | Computer Vision | NLP | Azure Certified | Data Scientist at Artificial intelligence global company\n\n  + [Report this post](/uas/login?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fmohammed-al-hashim-9b12641a5_ai-llm-langchain-activity-7386319729625473024-nTQo&trk=public_post_ellipsis-menu-semaphore-sign-in-redirect&guestReportContentType=POST&_f=guest-reporting)\n\n  How to Get Structured Output from an LLM Many people think LLMs only return plain text, but they can also give structured results like JSON, tables, or lists ‚Äî if you ask them correctly. Here‚Äôs how üëá 1. Be clear about the format Tell the model exactly what you need. Example: ‚ÄúReturn your answer in JSON with keys: name, age, and skills.‚Äù 2. Use clear boundaries Add something like: ‚ÄúOnly output valid JSON between triple backticks.‚Äù This helps the model keep the output clean and easy to parse. 3. Check the output Always validate it using a parser (for example, [json.loads](http://json.loads?trk=public_post-text)() in Python). If it fails, add a simple retry or fallback. 4. Show examples Give the model one or two examples of what you expect. It helps the model understand your format better. 5. Use structured frameworks Tool like LangChain‚Äôs StructuredOutputParser can make sure the model always follows your schema. [#AI](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fai&trk=public_post-text) [#LLM](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fllm&trk=public_post-text) [#LangChain](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Flangchain&trk=public_post-text) [#PromptEngineering](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fpromptengineering&trk=public_post-text) [#GenerativeAI](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fgenerativeai&trk=public_post-text) [#LLM](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fllm&trk=public_post-text)\n\n  [21](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fmohammed-al-hashim-9b12641a5_ai-llm-langchain-activity-7386319729625473024-nTQo&trk=public_post_social-actions-reactions)\n\n  [Like](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fmohammed-al-hashim-9b12641a5_ai-llm-langchain-activity-7386319729625473024-nTQo&trk=public_post_like-cta)   [Comment](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fmohammed-al-hashim-9b12641a5_ai-llm-langchain-activity-7386319729625473024-nTQo&trk=public_post_comment-cta)\n\n  To view or add a comment, [sign in](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fmohammed-al-hashim-9b12641a5_ai-llm-langchain-activity-7386319729625473024-nTQo&trk=public_post_feed-cta-banner-cta)\n* [Shervin Khazaeli, PhD](https://ca.linkedin.com/in/shervinkh?trk=public_post_feed-actor-name)\n\n  Principal / Lead Data Scientist | AI Strategy & ML Engineering | Guiding Companies to AI Excellence\n\n  + [Report this post](/uas/login?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fshervinkh_mlengineering-pyhton-ai-activity-7392317369588572160-oRdk&trk=public_post_ellipsis-menu-semaphore-sign-in-redirect&guestReportContentType=POST&_f=guest-reporting)\n\n  Goodbye GIL. You will not be missed. üç∑üêç Python 3.14 is removing the Global Interpreter Lock (GIL)‚Ä¶ after 30 years of acting like that one coworker who must hold the whiteboard marker at all times. For decades, Python could technically run on multiple cores, but the GIL said: ‚ÄúNo. Only one thread at a time. Everyone else sit down.‚Äù But now‚Ä¶ ‚Ä¢ Real multi-core parallelism ‚Ä¢ Threads that actually thread ‚Ä¢ Async that doesn‚Äôt break down crying ‚Ä¢ AI pipelines that don‚Äôt require spiritual forgiveness and message queues For Data & ML folks, this means: ‚Ä¢ Faster data processing ‚Ä¢ More scalable inference + agents ‚Ä¢ CPU-heavy workflows without ‚Äúfine, I‚Äôll rewrite it in Rust‚Äù energy This is not just a performance upgrade. This is Python getting on steroid üèãÔ∏è (Note: Python 3.14 ships with both the standard build and the new free-threaded build ‚Äî so adoption will roll in gradually.) [#MLEngineering](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fmlengineering&trk=public_post-text) [#Pyhton](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fpyhton&trk=public_post-text) [#AI](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fai&trk=public_post-text) [#DataEngineering](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fdataengineering&trk=public_post-text)\n\n\n\n  [28](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fshervinkh_mlengineering-pyhton-ai-activity-7392317369588572160-oRdk&trk=public_post_social-actions-reactions)\n\n  [Like](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fshervinkh_mlengineering-pyhton-ai-activity-7392317369588572160-oRdk&trk=public_post_like-cta)   [Comment](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fshervinkh_mlengineering-pyhton-ai-activity-7392317369588572160-oRdk&trk=public_post_comment-cta)\n\n  To view or add a comment, [sign in](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fshervinkh_mlengineering-pyhton-ai-activity-7392317369588572160-oRdk&trk=public_post_feed-cta-banner-cta)\n* [Vedavyas Viswanatham](https://in.linkedin.com/in/vedavyas-viswanatham?trk=public_post_feed-actor-name)\n\n  Software Development Intern @ Parabola9 | BTech in Computer Science | IIITN CSE‚Äô25 | AI/ML Enthusiast | Tech Nerd\n\n  + [Report this post](/uas/login?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fvedavyas-viswanatham_llm-engineer-prerequisitesmodel-serialization-activity-7393505213132804096-KIqE&trk=public_post_ellipsis-menu-semaphore-sign-in-redirect&guestReportContentType=POST&_f=guest-reporting)\n\n  Building models is easy ‚Äî deploying them isn‚Äôt. This post is all about making ML production-ready: saving trained models, automating predictions, and logging runs. From Joblib serialization ‚Üí FastAPI-ready functions ‚Üí full pipelines, this is where machine learning turns into a usable product. üß† Covered: ‚öôÔ∏è Model & Scaler serialization (Joblib) üß© FastAPI-ready prediction function üîÅ Automated preprocessing & batch prediction üßæ Logging and CSV outputs for traceability The goal isn‚Äôt just accuracy ‚Äî it‚Äôs reliability at scale. üîó Full notebook: [https://lnkd.in/dzrH8gYH](https://www.linkedin.com/redir/redirect?url=https%3A%2F%2Flnkd%2Ein%2FdzrH8gYH&urlhash=Zq6m&trk=public_post-text) [#MLOps](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fmlops&trk=public_post-text) [#MachineLearning](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fmachinelearning&trk=public_post-text) [#Python](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fpython&trk=public_post-text) [#FastAPI](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Ffastapi&trk=public_post-text) [#ModelDeployment](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fmodeldeployment&trk=public_post-text) [#AIEngineering](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Faiengineering&trk=public_post-text) [#DataScience](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fdatascience&trk=public_post-text) [#Joblib](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fjoblib&trk=public_post-text) [#Automation](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fautomation&trk=public_post-text) [#ChurnPrediction](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fchurnprediction&trk=public_post-text) [#MLPipeline](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fmlpipeline&trk=public_post-text) [#RandomForest](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Frandomforest&trk=public_post-text) [#ProductionAI](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fproductionai&trk=public_post-text) [#OpenSource](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fopensource&trk=public_post-text)\n\n  [6](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fvedavyas-viswanatham_llm-engineer-prerequisitesmodel-serialization-activity-7393505213132804096-KIqE&trk=public_post_social-actions-reactions)\n\n  [Like](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fvedavyas-viswanatham_llm-engineer-prerequisitesmodel-serialization-activity-7393505213132804096-KIqE&trk=public_post_like-cta)   [Comment](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fvedavyas-viswanatham_llm-engineer-prerequisitesmodel-serialization-activity-7393505213132804096-KIqE&trk=public_post_comment-cta)\n\n  To view or add a comment, [sign in](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fvedavyas-viswanatham_llm-engineer-prerequisitesmodel-serialization-activity-7393505213132804096-KIqE&trk=public_post_feed-cta-banner-cta)\n* [Indrasis Datta](https://in.linkedin.com/in/indrasisd?trk=public_post_feed-actor-name)\n\n  Tech Lead | MERN | Generative AI | 3x AWS Certified\n\n  + [Report this post](/uas/login?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Findrasisd_python-generativeai-langchain-activity-7392415215402889216-txEX&trk=public_post_ellipsis-menu-semaphore-sign-in-redirect&guestReportContentType=POST&_f=guest-reporting)\n\n  Choosing Between uv and conda for Python and GenAI Projects Both tools solve environment headaches but they shine in different places. 1) Use uv when speed matters. - Ideal for web apps, FastAPI services or automation scripts where you want clean, fast setups without dependency bloat. - It‚Äôs lightweight, builds environments almost instantly and keeps dependency resolution simple. uv venv uv pip install -r [requirements.txt](http://requirements.txt?trk=public_post-text) 2) Use conda for ML or AI workloads. - When working on GenAI, LangChain or TensorFlow projects, dependency management can be tricky. - Conda handles packages like CUDA, OpenCV and PyTorch smoothly, making it a strong choice for AI-heavy workloads. conda create -n ml python=3.13 conda install pytorch -c pytorch In short: uv = speed + simplicity conda = power + stability Big thanks to AI/ML creators like [Krish Naik](https://in.linkedin.com/in/naikkrish?trk=public_post-text), [CampusX](https://in.linkedin.com/company/campusx-official?trk=public_post-text), [Codebasics](https://www.linkedin.com/company/codebasics?trk=public_post-text), [Marina Wyss](https://www.linkedin.com/in/marina-wyss?trk=public_post-text) for making complex AI and Python concepts easier to learn and apply. [#Python](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fpython&trk=public_post-text) [#GenerativeAI](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fgenerativeai&trk=public_post-text) [#LangChain](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Flangchain&trk=public_post-text) [#FastAPI](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Ffastapi&trk=public_post-text) [#pip](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fpip&trk=public_post-text) [#uv](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fuv&trk=public_post-text) [#MachineLearning](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fmachinelearning&trk=public_post-text)\n\n\n\n  [3](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Findrasisd_python-generativeai-langchain-activity-7392415215402889216-txEX&trk=public_post_social-actions-reactions)\n\n  [Like](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Findrasisd_python-generativeai-langchain-activity-7392415215402889216-txEX&trk=public_post_like-cta)   [Comment](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Findrasisd_python-generativeai-langchain-activity-7392415215402889216-txEX&trk=public_post_comment-cta)\n\n  To view or add a comment, [sign in](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Findrasisd_python-generativeai-langchain-activity-7392415215402889216-txEX&trk=public_post_feed-cta-banner-cta)\n\n5,510 followers\n\n* [597 Posts](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww%2Elinkedin%2Ecom%2Fin%2Fjohnidouglas%2Frecent-activity%2F&trk=public_post_follow-posts)\n\n[View Profile](https://br.linkedin.com/in/johnidouglas?trk=public_post_follow-view-profile)   [Follow](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww%2Elinkedin%2Ecom%2Ffeed%2Fupdate%2Furn%3Ali%3Aactivity%3A7386028135768539136&trk=public_post_follow)\n\n## Explore content categories\n\n* [Career](https://www.linkedin.com/top-content/career/)\n* [Productivity](https://www.linkedin.com/top-content/productivity/)\n* [Finance](https://www.linkedin.com/top-content/finance/)\n* [Soft Skills & Emotional Intelligence](https://www.linkedin.com/top-content/soft-skills-emotional-intelligence/)\n* [Project Management](https://www.linkedin.com/top-content/project-management/)\n* [Education](https://www.linkedin.com/top-content/education/)\n* [Technology](https://www.linkedin.com/top-content/technology/)\n* [Leadership](https://www.linkedin.com/top-content/leadership/)\n* [Ecommerce](https://www.linkedin.com/top-content/ecommerce/)\n* [User Experience](https://www.linkedin.com/top-content/user-experience/)\n\n## Sign in to view more content\n\nCreate your free account or sign in to continue your search\n\n## Welcome back\n\nBy clicking Continue to join or sign in, you agree to LinkedIn‚Äôs [User Agreement](/legal/user-agreement?trk=public_post_contextual-sign-in-modal_sign-in-modal_auth-button_user-agreement), [Privacy Policy](/legal/privacy-policy?trk=public_post_contextual-sign-in-modal_sign-in-modal_auth-button_privacy-policy), and [Cookie Policy](/legal/cookie-policy?trk=public_post_contextual-sign-in-modal_sign-in-modal_auth-button_cookie-policy).\n\nNew to LinkedIn? [Join now](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww%2Elinkedin%2Ecom%2Fposts%2Fjohnidouglas_kserve-models-format-activity-7386028135768539136-ARti&trk=public_post_contextual-sign-in-modal_sign-in-modal_join-link)\n\nor\n\nNew to LinkedIn? [Join now](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww%2Elinkedin%2Ecom%2Fposts%2Fjohnidouglas_kserve-models-format-activity-7386028135768539136-ARti&trk=public_post_contextual-sign-in-modal_join-link)\n\nBy clicking Continue to join or sign in, you agree to LinkedIn‚Äôs [User Agreement](/legal/user-agreement?trk=linkedin-tc_auth-button_user-agreement), [Privacy Policy](/legal/privacy-policy?trk=linkedin-tc_auth-button_privacy-policy), and [Cookie Policy](/legal/cookie-policy?trk=linkedin-tc_auth-button_cookie-policy).\n\nNever miss a beat on the app\n\nDon‚Äôt have the app? Get it in the Microsoft Store.\n\n [Open the app](ms-windows-store://pdp/?ProductId=9WZDNCRFJ4Q7&mode=mini&cid=guest_desktop_upsell_post2)\n\n "
    },
    {
      "url": "https://venturebeat.com/ai/lambda-launches-inference-as-a-service-api-claiming-lowest-costs",
      "title": "Lambda launches 'inference-as-a-service' API claiming ...",
      "content": "Brooks noted that its deep reservoir of GPU resources is one of Lambda‚Äôs distinguishing features, reiterating that ‚ÄúLambda has deployed tens of thousands of GPUs over the past decade, allowing us to offer cost-effective solutions and maximum utility for both older and newer AI chips.‚Äù\n\nThis GPU advantage enables the platform to support scaling to trillions of tokens monthly, providing flexibility for developers and enterprises alike.\n\n## Open and flexible\n\nLambda is positioning itself as a flexible alternative to cloud giants by offering unrestricted access to high-performance inference.\n\n‚ÄúWe want to give the machine learning community unrestricted access to inference APIs. You can plug and play, read the docs, and scale rapidly to trillions of tokens,‚Äù Brooks explained. [...] ‚ÄúOur platform is fully verticalized, meaning we can pass dramatic cost savings to end users compared to other providers like OpenAI,\" said Robert Brooks, Lambda‚Äôs vice president of revenue, in a video call interview with VentureBeat. \"Plus, there are no rate limits inhibiting scaling, and you don‚Äôt have to talk to a salesperson to get started.\"\n\nIn fact, as Brooks told VentureBeat, developers can head over to Lambda's new Inference API webpage, generate an API key, and get started in less than five minutes.\n\nLambda‚Äôs Inference API supports leading-edge models such as Meta's Llama 3.3 and 3.1, Nous's Hermes-3, and Alibaba's Qwen 2.5, making it one of the most accessible options for the machine learning community. The full list is available here and includes: [...] All Posts\n\n# Lambda launches 'inference-as-a-service' API claiming lowest costs in AI industry\n\nCarl Franzen\n\nLambda is a 12-year-old San Francisco company best known for offering graphics processing units (GPUs) on demand as a service to machine learning researchers and AI model builders and trainers.\n\nBut today it's taking its offerings a step further with the launch of the Lambda Inference API (application programming interface), which it claims to be the lowest-cost service of its kind on the market. The API allows enterprises to deploy AI models and applications into production for end users without worrying about procuring or maintaining compute.\n\nThe launch complements Lambda's existing focus on providing GPU clusters for training and fine-tuning machine learning models.",
      "score": 0.36977065,
      "raw_content": "[All Posts](/)\n\n# Lambda launches 'inference-as-a-service' API claiming lowest costs in AI industry\n\n[Carl Franzen](/author/carlfranzen)\n\n[Lambda](https://lambdalabs.com/) is a 12-year-old San Francisco company best known for offering graphics processing units (GPUs) on demand as a service to machine learning researchers and AI model builders and trainers.\n\nBut today it's taking its offerings a step further with the launch of the [Lambda](https://lambdalabs.com/inference) [Inference](https://lambdalabs.com/inference) [API](https://lambdalabs.com/inference) (application programming interface), which it claims to be the lowest-cost service of its kind on the market. The API allows enterprises to deploy AI models and applications into production for end users without worrying about procuring or maintaining compute.\n\nThe launch complements Lambda's existing focus on providing GPU clusters for training and fine-tuning machine learning models.\n\n‚ÄúOur platform is fully verticalized, meaning we can pass dramatic cost savings to end users compared to other providers like OpenAI,\" said Robert Brooks, Lambda‚Äôs vice president of revenue, in a video call interview with VentureBeat. \"Plus, there are no rate limits inhibiting scaling, and you don‚Äôt have to talk to a salesperson to get started.\"\n\nIn fact, as Brooks told VentureBeat, developers can head over to [Lambda's new Inference API](https://lambdalabs.com/inference) webpage, generate an API key, and get started in less than five minutes.\n\nLambda‚Äôs Inference API supports leading-edge models such as [Meta's Llama 3.3](https://venturebeat.com/ai/meta-launches-open-source-llama-3-3-shrinking-powerful-bigger-model-into-smaller-size/) and 3.1, [Nous's Hermes-3](https://venturebeat.com/ai/meet-hermes-3-the-powerful-new-open-source-ai-model-that-has-existential-crises/), and [Alibaba's Qwen 2.5](https://github.com/QwenLM/Qwen2.5), making it one of the most accessible options for the machine learning community. The [full list](https://docs.lambdalabs.com/public-cloud/lambda-inference-api/) is available here and includes:\n\n* deepseek-coder-v2-lite-instruct\n* dracarys2-72b-instruct\n* hermes3-405b\n* hermes3-405b-fp8-128k\n* hermes3-70b\n* hermes3-8b\n* lfm-40b\n* llama3.1-405b-instruct-fp8\n* llama3.1-70b-instruct-fp8\n* llama3.1-8b-instruct\n* llama3.2-3b-instruct\n* llama3.1-nemotron-70b-instruct\n* llama3.3-70b\n\nPricing begins at $0.02 per million tokens for smaller models like Llama-3.2-3B-Instruct, and scales up to $0.90 per million tokens for larger, state-of-the-art models such as Llama 3.1-405B-Instruct.\n\nAs Lambda cofounder and CEO Stephen Balaban put it recently on X, \"Stop wasting money and start using Lambda for LLM Inference.\" Balaban published a graph showing its per-token cost for serving up AI models through inference compared to rivals in the space.\n\nFurthermore, unlike many other services, Lambda‚Äôs pay-as-you-go model ensures customers pay only for the tokens they use, eliminating the need for subscriptions or rate-limited plans.\n\n## Closing the AI loop\n\nLambda has a decade-plus history of supporting AI advancements with its GPU-based infrastructure.\n\nFrom its hardware solutions to its training and fine-tuning capabilities, the company has built a reputation as a reliable partner for enterprises, research institutions, and startups.\n\n‚ÄúUnderstand that Lambda has been deploying GPUs for well over a decade to our user base, and so we're sitting on literally tens of thousands of Nvidia GPUs, and some of them can be from older life cycles and newer life cycles, allowing us to still get maximum utility out of those AI chips for the wider ML community, at reduced costs as well,\" Brooks explained. \"With the launch of Lambda Inference, we‚Äôre closing the loop on the full-stack AI development lifecycle. The new API formalizes what many engineers had already been doing on Lambda‚Äôs platform ‚Äî using it for inference ‚Äî but now with a dedicated service that simplifies deployment.\"\n\nBrooks noted that its deep reservoir of GPU resources is one of Lambda‚Äôs distinguishing features, reiterating that ‚ÄúLambda has deployed tens of thousands of GPUs over the past decade, allowing us to offer cost-effective solutions and maximum utility for both older and newer AI chips.‚Äù\n\nThis GPU advantage enables the platform to support scaling to trillions of tokens monthly, providing flexibility for developers and enterprises alike.\n\n## Open and flexible\n\nLambda is positioning itself as a flexible alternative to cloud giants by offering unrestricted access to high-performance inference.\n\n‚ÄúWe want to give the machine learning community unrestricted access to inference APIs. You can plug and play, read the docs, and scale rapidly to trillions of tokens,‚Äù Brooks explained.\n\nThe API supports a range of open-source and proprietary models, including popular instruction-tuned Llama models.\n\nThe company has also hinted at expanding to multimodal applications, including video and image generation, in the near future.\n\n‚ÄúInitially, we‚Äôre focused on text-based LLMs, but soon we‚Äôll expand to multimodal models,‚Äù Brooks said.\n\n## Serving devs and enterprises with privacy and security\n\nThe Lambda Inference API targets a wide range of users, from startups to large enterprises, in media, entertainment, and software development.\n\nThese industries are increasingly adopting AI to power applications like text summarization, code generation, and generative content creation.\n\n‚ÄúThere‚Äôs no retention or sharing of user data on our platform. We act as a conduit for serving data to end users, ensuring privacy,‚Äù Brooks emphasized, reinforcing Lambda‚Äôs commitment to security and user control.\n\nAs AI adoption continues to rise, Lambda‚Äôs new service is poised to attract attention from businesses seeking cost-effective solutions for deploying and maintaining AI models. By eliminating common barriers such as rate limits and high operating costs, Lambda hopes to empower more organizations to harness AI's potential.\n\nThe Lambda Inference API is available now, with detailed pricing and documentation accessible through [Lambda‚Äôs](https://lambdalabs.com/inference) [website.](https://lambdalabs.com/inference)\n\n## More"
    }
  ],
  "response_time": 1.57,
  "usage": {
    "credits": 2
  },
  "request_id": "6e1a9268-2446-444f-bef1-dffd154f9b9f"
}
